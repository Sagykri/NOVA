{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOMAPS_HOME: /home/labs/hornsteinlab/Collaboration/MOmaps_Sagy/MOmaps\n",
      "MOMAPS_HOME: /home/labs/hornsteinlab/Collaboration/MOmaps_Sagy/MOmaps\n",
      "MOMAPS_HOME: /home/labs/hornsteinlab/Collaboration/MOmaps_Sagy/MOmaps\n",
      "MOMAPS_HOME: /home/labs/hornsteinlab/Collaboration/MOmaps_Sagy/MOmaps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "os.environ['MOMAPS_HOME'] = '/home/labs/hornsteinlab/Collaboration/MOmaps_Sagy/MOmaps'\n",
    "os.environ['MOMAPS_DATA_HOME'] = '/home/labs/hornsteinlab/Collaboration/MOmaps/input'\n",
    "\n",
    "sys.path.insert(1, os.getenv(\"MOMAPS_HOME\"))\n",
    "print(f\"MOMAPS_HOME: {os.getenv('MOMAPS_HOME')}\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from src.common.lib.dataset import Dataset\n",
    "from src.datasets.dataset_spd import DatasetSPD\n",
    "from src.common.lib.utils import load_config_file\n",
    "from src.common.lib.data_loader import get_dataloader\n",
    "from sandbox.eval_new_arch.dino4cells.utils import utils\n",
    "from sandbox.eval_new_arch.dino4cells.main_dino import DataAugmentationDINO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data_path = './src/datasets/configs/training_data_config/B78NoDSTrainDatasetAugInPlaceSubsetConfig'\n",
    "\n",
    "config = {\n",
    "        'seed': 1,\n",
    "        'embedding': {\n",
    "            'image_size': 224\n",
    "        },\n",
    "        'patch_size': 16,\n",
    "        'num_channels': 2,\n",
    "        # 'out_dim': 2,\n",
    "        'use_bn_in_head': False,\n",
    "        'norm_last_layer': True,\n",
    "        \n",
    "        'local_crops_number': 8,\n",
    "        'warmup_teacher_temp': 0.02,\n",
    "        'teacher_temp': 0.05,\n",
    "        'warmup_teacher_temp_epochs': 1,\n",
    "        'epochs': 100,\n",
    "        'student_temp': 0.1,\n",
    "        'center_momentum': 0.9,\n",
    "        'momentum_teacher': 0.9,#6,#0.9,##0.996,\n",
    "        \n",
    "        'lr':0.0500,#0.05,# 1e-1,# 0.0005,# 1e-4,##,\n",
    "        'min_lr': 0.005000, #5e-2,#1e-5,#1e-6,\n",
    "        'warmup_epochs': 2,##0,#10,#1,\n",
    "        \n",
    "        'weight_decay': 0.01,#1e-7,#0.04,#0.04,\n",
    "        'weight_decay_end': 0.1,#1e-6,#0.4,#0.4,\n",
    "    \n",
    "        'freeze_last_layer': 1,#1,\n",
    "        \n",
    "        \n",
    "        'batch_size_per_gpu': 10,\n",
    "        'num_workers': 1,\n",
    "        \n",
    "        'accumulation_steps': 5,\n",
    "        \n",
    "        'logs_dir':\"/home/labs/hornsteinlab/Collaboration/MOmaps_Sagy/MOmaps/sandbox/eval_new_arch/dino4cells/logs\",\n",
    "        'tensorboard_root_folder': \"/home/labs/hornsteinlab/Collaboration/MOmaps_Sagy/MOmaps/sandbox/eval_new_arch/dino4cells/tensorboard\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m utils\u001b[38;5;241m.\u001b[39mfix_random_seeds(\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m)\n\u001b[1;32m      3\u001b[0m cudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# ============ preparing data ... ============\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'seed'"
     ]
    }
   ],
   "source": [
    "utils.fix_random_seeds(config.seed)\n",
    "\n",
    "cudnn.benchmark = False\n",
    "\n",
    "# ============ preparing data ... ============\n",
    "transform = DataAugmentationDINO(config=config)\n",
    "\n",
    "\n",
    "config_data = load_config_file(config_data_path)\n",
    "\n",
    "dataset_train = DatasetSPD(config_data, transform)\n",
    "config.out_dim = len(np.unique(dataset_train.label))\n",
    "train_indexes, val_indexes, test_indexes = None, None, None\n",
    "# dataset_val, dataset_test = None, None\n",
    "\n",
    "\n",
    "# if is_one_config_supplied:\n",
    "# dataset_val, dataset_test = deepcopy(dataset_train), deepcopy(dataset_train) # the deepcopy is important. do not change. \n",
    "# dataset_test.flip, dataset_test.rot = False, False\n",
    "if config_data.SPLIT_DATA:\n",
    "    logging.info(\"Split data...\")\n",
    "    train_indexes, val_indexes, test_indexes = dataset_train.split()\n",
    "# else:\n",
    "#     dataset_val, dataset_test = DatasetSPD(config_val), DatasetSPD(config_test)\n",
    "\n",
    "\n",
    "################# TAKING ONLY PART OF THE DATA ################\n",
    "quick_train_indices = train_indexes[:]\n",
    "quick_val_indices = val_indexes[:]\n",
    "# logging.info(f\"[WARNING!] TAKING ONLY PART OF THE DATA!! train: {len(quick_train_indices)} val: {len(quick_val_indices)}\")\n",
    "############################################################\n",
    "\n",
    "\n",
    "\n",
    "# quick_val_indices = val_indexes[:100]\n",
    "dataset_train_subset = Dataset.get_subset(dataset_train, quick_train_indices)\n",
    "dataset_val_subset = Dataset.get_subset(dataset_train, quick_val_indices)\n",
    "dataset = dataset_train_subset\n",
    "dataset_val = dataset_val_subset\n",
    "\n",
    "data_loader = get_dataloader(dataset, config.batch_size_per_gpu, num_workers=config.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "momapsD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
