{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Params ###############\n",
    "\n",
    "NOVA_HOME = '/home/projects/hornsteinlab/Collaboration/NOVA_GAL/NOVA'\n",
    "preprocessing_path = \"/home/projects/hornsteinlab/Collaboration/MOmaps/outputs/preprocessing/iAstrocytes/brenner\"\n",
    "csv_name = f'raw_metrics110625.csv'\n",
    "mappings_filepath = f\"/home/projects/hornsteinlab/Collaboration/NOVA_GAL/NOVA/manuscript/markers_focus_boundries/markers_focus_boundries_iAstrocytes.csv\"\n",
    "imgs_path = '/home/projects/hornsteinlab/Collaboration/MOmaps/input/images/raw/John/iAstrocytes/ordered/'\n",
    "\n",
    "metric_name = 'Target_Sharpness_Brenner'\n",
    "img_shape = 1024\n",
    "percentiles_resolution = 0.0001\n",
    "# percentile_ranges_for_reports = [0, 0.1, 0.2, 0.3, 0.5, 0.7, 1, 2, 5, 10, 15, 20, 30, 40, 60, 75, 80, 85, 90, 95, 98, 99, 99.5, 99.7, 99.8,99.9,100]\n",
    "percentile_ranges_for_reports = [0, 5, 10, 15, 20, 30, 40, 60, 75, 80, 85, 90, 95, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import concurrent.futures\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "os.environ['NOVA_HOME'] = NOVA_HOME\n",
    "sys.path.insert(1, os.getenv(\"NOVA_HOME\"))\n",
    "print(f\"NOVA_HOME: {os.getenv('NOVA_HOME')}\")\n",
    "\n",
    "from src.preprocessing.preprocessing_utils import get_image_focus_quality \n",
    "from src.preprocessing.preprocessing_utils import rescale_intensity, fit_image_shape\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(tile, as_string=False):\n",
    "    sharpness_brenner = get_image_focus_quality(tile)    \n",
    "    if as_string:\n",
    "        return f\"Brenner: {round(sharpness_brenner, 3)}\"\n",
    "    return sharpness_brenner\n",
    "\n",
    "def show_images(df, max_samples = 10):\n",
    "    for ind, path in enumerate(df.Path.values):\n",
    "        print(ind)\n",
    "        if max_samples is not None and ind >= max_samples:\n",
    "            print(f\"Stopping at {ind}. There are {len(df.Path.values)} images in total\")\n",
    "            break\n",
    "        \n",
    "        # Target\n",
    "        target_path = os.path.join(imgs_path, path)\n",
    "        show_processed_tif(target_path)\n",
    "        # His DAPI\n",
    "        # path_l = target_path.split(\"/\")\n",
    "        # path_l[-2] = 'DAPI'\n",
    "        \n",
    "        # file_name = path_l[-1].split(\"_\")\n",
    "        # dapi_file_name = \"_\".join([file_name[0], 'w1confDAPI', file_name[-1]])\n",
    "        # dapi_file_name = \"/\".join([*path_l[:-1], dapi_file_name])\n",
    "        # print(dapi_file_name)\n",
    "\n",
    "        # show_processed_tif(dapi_file_name)\n",
    "        print('--------------------------------')\n",
    "        \n",
    "def init_mappings(markers=[], filepath=None):\n",
    "    if filepath is not None:     \n",
    "        if os.path.exists(filepath):\n",
    "            mappings = pd.read_csv(filepath, index_col=0)\n",
    "            return mappings\n",
    "        \n",
    "    mappings = pd.DataFrame(columns=['Lower_bound', 'Upper_bound'], index=markers)\n",
    "\n",
    "    return mappings\n",
    "        \n",
    "def save_to_mapping(filepath, mappings, marker, value, is_upper_bound):\n",
    "    col = 'Upper_bound' if is_upper_bound else 'Lower_bound' \n",
    "    mappings.loc[marker, col] = value\n",
    "    \n",
    "    mappings.to_csv(filepath)\n",
    "    print(f\"File saved to {filepath}\")\n",
    "\n",
    "def show_label(path):\n",
    "    path_l = path.split(\"/\")\n",
    "    return path_l[-7:]\n",
    "\n",
    "def process_tif(path):\n",
    "    \"\"\"\n",
    "    Read and process the image.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Processed image.\n",
    "    \"\"\"\n",
    "    # read the image stack\n",
    "    img = cv2.imread(path, cv2.IMREAD_ANYDEPTH)\n",
    "    img = fit_image_shape(img, (img_shape, img_shape))\n",
    "    # rescale pixel intensities\n",
    "    img = rescale_intensity(img)\n",
    "    return img\n",
    "    \n",
    "def show_processed_tif(path):\n",
    "    img = process_tif(path)\n",
    "    print(get_metrics(img, True))\n",
    "    # show the image with grid \n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    put_tiles_grid(image=img, ax=ax)\n",
    "    plt.axis('off')\n",
    "    plt.title(show_label(path), color='purple')\n",
    "    print(f\"Img shape: {img.shape}\")\n",
    "    plt.show()\n",
    "\n",
    "def put_tiles_grid(image, ax):\n",
    "    # assumes 1000x1000 image\n",
    "    import matplotlib.patches as patches\n",
    "\n",
    "    # Add dashed grid lines for 64 blocks\n",
    "    num_blocks = 10\n",
    "    block_size = 100\n",
    "\n",
    "    for i in range(1, num_blocks):\n",
    "        # Draw horizontal dashed lines\n",
    "        ax.plot([0, 1000], [i * block_size, i * block_size], linestyle='--', lw=1, alpha=0.5, color='pink')\n",
    "\n",
    "        # Draw vertical dashed lines\n",
    "        ax.plot([i * block_size, i * block_size], [0, 1000], linestyle='--', lw=1, alpha=0.5, color='pink')\n",
    "\n",
    "    # Remove x and y axis labels\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Add a title\n",
    "    plt.title('Image with Dashed Grid of 64 Blocks')\n",
    "\n",
    "def update_all_mappings(mappings, thresholds, df):\n",
    "    # Iterate over the rows and fill the thresholds\n",
    "    for marker in mappings.index:\n",
    "        if marker in thresholds and thresholds[marker] is not None:\n",
    "            df_marker = df.loc[df['Marker'] == marker]\n",
    "            percentiles = df_marker[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "            mappings.loc[marker, \"Lower_bound\"] = round(percentiles[f'{thresholds[marker][0]}%'], 2)\n",
    "            mappings.loc[marker, \"Upper_bound\"] = round(percentiles[f'{thresholds[marker][1]}%'], 2)\n",
    "    return mappings\n",
    "\n",
    "def create_histogram_report_by_batch(df: pd.DataFrame, all_markers: list) -> None:\n",
    "    \"\"\"\n",
    "    Generate a PDF report with histograms for each marker.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the images data.\n",
    "        all_markers (list): List of unique markers.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"    \n",
    "    with PdfPages('Marker_histogram_by_batch.pdf') as pdf:\n",
    "        for marker in all_markers:\n",
    "            print(marker)\n",
    "            df_marker = df.loc[df['Marker'] == marker]\n",
    "            percentiles = df_marker[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "            create_histogram(\n",
    "                df_marker, percentiles, \n",
    "                low_perc=thresholds[marker][0], \n",
    "                high_perc=thresholds[marker][1], \n",
    "                overlay_group=['Batch'], \n",
    "                x_min=0.1, x_max=99.9\n",
    "            )\n",
    "            plt.title(marker)\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "            \n",
    "def create_histogram(\n",
    "    df_marker: pd.DataFrame, \n",
    "    percentiles: pd.Series, \n",
    "    low_perc: float = 0.5, \n",
    "    high_perc: float = 99.9, \n",
    "    x_min: float = None, \n",
    "    x_max: float = None, \n",
    "    overlay_group: list = None,\n",
    "    plot_base: bool = True,\n",
    "    actual_x_limits: tuple = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create a histogram of the Brenner values of a certain marker.\n",
    "\n",
    "    Parameters:\n",
    "        df_marker (pd.DataFrame): Marker's data.\n",
    "        percentiles (pd.Series): Percentile values for annotations.\n",
    "        low_perc (float): Low percentile threshold for annotations.\n",
    "        high_perc (float): High percentile threshold for annotations.\n",
    "        x_min (float, optional): Minimum x-axis value for the histogram.\n",
    "        x_max (float, optional): Maximum x-axis value for the histogram.\n",
    "        overlay_group (list, optional): Columns to group and overlay histograms.\n",
    "        plot_base (bool): Whether to plot the base histogram.\n",
    "        actual_x_limits (tuple, optional): Tuple specifying actual x_min and x_max values.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    assert low_perc < high_perc, \"'low_perc' must be less than 'high_perc'\"\n",
    "    \n",
    "    # Determine histogram range\n",
    "    if actual_x_limits:\n",
    "        hist_range = actual_x_limits  # Use passed x_min and x_max\n",
    "    else:\n",
    "        hist_range = (percentiles[f'{x_min}%'], percentiles[f'{x_max}%']) if x_min is not None and x_max is not None else None\n",
    "    \n",
    "    # Plot base histogram\n",
    "    if plot_base:\n",
    "        plt.hist(df_marker[metric_name].values, bins=100, range=hist_range, color=plt.cm.tab10(range(1))[0], \n",
    "                 alpha=0.3, label='Brenner scores')\n",
    "    \n",
    "    # Plot overlays\n",
    "    if overlay_group is not None:\n",
    "        grouped_data = df_marker.groupby(overlay_group)\n",
    "        unique_groups = grouped_data.groups.keys()\n",
    "        colors = plt.cm.tab10(range(len(unique_groups)))\n",
    "\n",
    "        for color, group in zip(colors, unique_groups):\n",
    "            group_data = grouped_data.get_group(group)\n",
    "            group_label = ' - '.join(map(str, group)) if isinstance(group, tuple) else group\n",
    "            plt.hist(group_data[metric_name].values, bins=100, range=hist_range, alpha=0.4, label=group_label, color=color)\n",
    "\n",
    "    # Add percentile markers\n",
    "    plt.scatter(percentiles['50%'], 0.5, color='yellow', s=12, label='50th percentile')\n",
    "    plt.scatter(percentiles[f'{high_perc}%'], 0.5, color='orange', s=12, label=f'{high_perc}th percentile')\n",
    "    plt.scatter(percentiles[f'{low_perc}%'], 0.5, color='red', s=12, label=f'{low_perc}th percentile')\n",
    "\n",
    "    # Remove duplicate legend entries\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "def generate_marker_reports(\n",
    "    df: pd.DataFrame, \n",
    "    all_markers: list, \n",
    "    output_folder: str, \n",
    "    percentiles_to_describe: list, \n",
    "    percentile_ranges: list, \n",
    "    max_samples: int\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generate a detailed report for each marker, including histograms and filtered images.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "        all_markers (list): List of unique markers.\n",
    "        output_folder (str): Path to save the output PDFs.\n",
    "        percentiles_to_describe (list): List of percentiles to describe the metric.\n",
    "        percentile_ranges (list or dict): Either:\n",
    "            - A single list of percentiles (e.g., [0, 5, 10, ..., 100]) to be used for all markers\n",
    "            - A dictionary mapping each marker to its own list of percentiles (e.g., {'DAPI': [...], 'PML': [...]})\n",
    "        max_samples (int): Maximum number of images to display per range.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for marker in all_markers:\n",
    "        print(marker)\n",
    "        df_marker = df.loc[df['Marker'] == marker]\n",
    "        percentiles = df_marker[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "\n",
    "        # Define the actual x-axis limits for consistent base and overlay histograms\n",
    "        actual_x_limits = (percentiles['0%'], percentiles['97%'])\n",
    "\n",
    "        pdf_path = os.path.join(output_folder, f'output_report_{marker}.pdf')\n",
    "        with PdfPages(pdf_path) as pdf:\n",
    "            # Generate histograms with overlays for different groups\n",
    "            groups = ['Condition', 'Batch', 'Rep', 'CellLine']\n",
    "            for group in groups:\n",
    "                create_histogram(\n",
    "                    df_marker,\n",
    "                    percentiles,\n",
    "                    low_perc=0,\n",
    "                    high_perc=97,\n",
    "                    actual_x_limits=actual_x_limits,\n",
    "                    overlay_group=[group]\n",
    "                )\n",
    "                plt.title(f\"Histogram with Overlay by {group}\")\n",
    "                pdf.savefig()  # Save current figure to the PDF\n",
    "                plt.close()\n",
    "\n",
    "            # Combined base histogram and overlay for each cell line\n",
    "            for CL in np.unique(df_marker['CellLine']):\n",
    "                create_histogram(\n",
    "                    df_marker,\n",
    "                    percentiles,\n",
    "                    low_perc=0,\n",
    "                    high_perc=97,\n",
    "                    actual_x_limits=actual_x_limits,\n",
    "                )\n",
    "                \n",
    "                # Filter and overlay the specific cell line\n",
    "                df_tmp = df_marker.loc[df_marker['CellLine'] == CL]\n",
    "                percentiles_tmp = df_tmp[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "                create_histogram(\n",
    "                    df_tmp,\n",
    "                    percentiles,\n",
    "                    low_perc=0,\n",
    "                    high_perc=97,\n",
    "                    actual_x_limits=actual_x_limits,\n",
    "                    overlay_group=['CellLine', 'Condition'], plot_base = False\n",
    "                )\n",
    "                plt.title(f\"Histogram for (Cell Line: {CL})\")\n",
    "                # Save the combined plot to the PDF\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "\n",
    "            if isinstance(percentile_ranges, dict):\n",
    "                marker_ranges = percentile_ranges.get(marker, [])\n",
    "            else:\n",
    "                marker_ranges = percentile_ranges\n",
    "            # Remaining parts of the function (filtered images, percentile ranges, etc.)\n",
    "            for i in range(len(marker_ranges) - 1):\n",
    "                per_min = np.round(marker_ranges[i], 2)\n",
    "                per_max = np.round(marker_ranges[i + 1], 2)\n",
    "                assert per_min < per_max, \"Percentile range minimum must be less than the maximum.\"\n",
    "                threshold = percentiles[f'{per_min}%']\n",
    "                threshold_second = percentiles[f'{per_max}%']\n",
    "\n",
    "                c = (df_marker[metric_name] >= threshold) & (df_marker[metric_name] <= threshold_second)\n",
    "                df_marker_filtered = df_marker[c].sample(frac=1, random_state=1)\n",
    "\n",
    "                text_output = (f'Images between %{per_min} - {per_max}%\\n'\n",
    "                               f\"Number of {marker} images in threshold {threshold} \"\n",
    "                               f\"({per_min}%) and {threshold_second} ({per_max}%): \"\n",
    "                               f\"{len(df_marker_filtered)}\\n\\n\"\n",
    "                               f\"{df_marker_filtered['CellLine'].value_counts().to_string()}\\n\\n\"\n",
    "                               f\"{df_marker_filtered['Condition'].value_counts().to_string()}\\n\\n\")\n",
    "\n",
    "                fig = plt.figure(figsize=(12, 8))\n",
    "                gs = GridSpec(3, 1, figure=fig, height_ratios=[1, 2, 0.1])\n",
    "                text_ax = fig.add_subplot(gs[0, :])\n",
    "                text_ax.axis('off')\n",
    "                text_ax.text(0.01, 0.99, text_output, ha='left', va='top', fontsize=12, wrap=True)\n",
    "\n",
    "                filtered_paths = df_marker_filtered['Path'].values\n",
    "                num_images = min(max_samples, len(filtered_paths))\n",
    "                img_gs = gs[1].subgridspec(1, num_images, wspace=0.1)\n",
    "\n",
    "                for ind, path in enumerate(filtered_paths[:num_images]):\n",
    "                    target_path = os.path.join(output_folder, path)\n",
    "                    img = process_tif(target_path)\n",
    "\n",
    "                    ax = fig.add_subplot(img_gs[0, ind])\n",
    "                    ax.imshow(img, cmap='gray')\n",
    "                    put_tiles_grid(image=img, ax=ax)\n",
    "                    ax.axis('off')\n",
    "\n",
    "                    labels = show_label(path)\n",
    "                    perc_brenner = abs(percentiles[[per for per in percentiles.keys() if '%' in per]] - get_image_focus_quality(img)).idxmin()\n",
    "                    ax.set_title(f\"{labels[1]}, {labels[3]}, {get_metrics(img, True)}, {perc_brenner}\", color='purple', fontsize=10)\n",
    "\n",
    "                plt.tight_layout()\n",
    "                pdf.savefig(fig)\n",
    "                plt.close(fig)\n",
    "\n",
    "def compute_dynamic_percentiles(marker_counts, base_percentiles, edge_range=5, samples_per_step=3):\n",
    "    result = {}\n",
    "\n",
    "    for marker, total in marker_counts.items():\n",
    "        percentiles = set(base_percentiles)\n",
    "\n",
    "        # Number of samples in [0–edge_range] and [100–edge_range]\n",
    "        edge_samples = edge_range / 100 * total\n",
    "\n",
    "        # How many intermediate percentiles to add\n",
    "        n_steps = int(edge_samples // samples_per_step)\n",
    "\n",
    "        if n_steps >= 2:\n",
    "            # Add left edge percentiles (excluding 0)\n",
    "            step = edge_range / n_steps\n",
    "            left_extra = [round(i * step, 1) for i in range(1, n_steps)]\n",
    "            percentiles.update(left_extra)\n",
    "\n",
    "            # Add right edge percentiles (excluding 100)\n",
    "            right_extra = [round(100 - i * step, 1) for i in range(n_steps, 0, -1)]\n",
    "            percentiles.update(right_extra)\n",
    "\n",
    "        result[marker] = sorted(int(p) if p == int(p) else p for p in percentiles)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(preprocessing_path, csv_name))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Marker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df['Marker'].value_counts()\n",
    "all_markers = df['Marker'].unique()\n",
    "print(len(all_markers), \"Markers:\")\n",
    "print(all_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = init_mappings(markers=all_markers, filepath=mappings_filepath)\n",
    "mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles_to_describe = np.arange(0, 1+percentiles_resolution, percentiles_resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Brenner reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this block if you want to generate Brenner reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use when marker sample counts vary, especially when some have very few images. \n",
    "# Set a minimal base of percentiles in percentile_ranges_for_reports and this function will add finer resolution only where enough samples exist.\n",
    "dynamic_percentiles = compute_dynamic_percentiles(df['Marker'].value_counts(), percentile_ranges_for_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = f\"{preprocessing_path}/brenner_reports_{datetime.now().strftime('%Y-%m-%d')}\"\n",
    "print('output_folder is', output_folder)\n",
    "generate_marker_reports(df, all_markers, output_folder, percentiles_to_describe, dynamic_percentiles, max_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine and set Brenner one by one (Option 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### SAFE ZONE TO CHANGE ###############\n",
    "\n",
    "marker = 'DAPI' # MAKRENAME\n",
    "# [marker] Options:\n",
    "# 'Autophagy' 'DAPI' 'impaired_Autophagosome' 'UPR_ATF4' 'UPR_ATF6'\n",
    "#  'UPR_IRE1a' 'Ubiquitin_levels' 'DNA_damage_P53BP1' 'Neuronal_activity'\n",
    "#  'Necroptosis_HMGB1' 'Necrosis' 'DNA_damage_pH2Ax' 'Parthanatos_early'\n",
    "#  'Cytoskeleton' 'Stress_initiation' 'mature_Autophagosome'\n",
    "#  'Nuclear_speckles_SON' 'TDP-43' 'Nuclear_speckles_SC35'\n",
    "#  'Splicing_factories' 'Aberrant_splicing' 'Parthanatos_late'\n",
    "#  'Protein_degradation' 'Senescence_signaling' 'Apoptosis'\n",
    "#  'Necroptosis_pMLKL'\n",
    "\n",
    "\n",
    "# [per] Options: 0-100\n",
    "per = 98 # percentile threshold \n",
    "\n",
    "# [per] Options: 0-100\n",
    "# *Optional! if you want to view images between per and another threshold\n",
    "per_second_bound = None\n",
    "\n",
    "max_samples = 3 # set max number of images (in threshold) to show\n",
    "\n",
    "# [is_upper_bound] Options:\n",
    "# True: upper bound\n",
    "# False: lower bound\n",
    "is_upper_bound = True \n",
    "\n",
    "show_percentile_plot = False\n",
    "\n",
    "###################### END OF SAFE ZONE ###################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "\n",
    "if per_second_bound is None:\n",
    "    per_second_bound = 100 if is_upper_bound else 0\n",
    "\n",
    "        \n",
    "print(f\"marker = {marker}, per: {per}% (per_second_bound={per_second_bound}%), max_samples = {max_samples}, is upper bound: {is_upper_bound}\")\n",
    "\n",
    "\n",
    "df_marker = df.loc[df['Marker'] == marker]\n",
    "percentiles = df_marker[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "\n",
    "threshold = percentiles[f'{per}%']\n",
    "threshold_second = percentiles[f'{per_second_bound}%']\n",
    "\n",
    "if is_upper_bound:\n",
    "    c = (df_marker[metric_name]>=threshold) & (df_marker[metric_name]<=threshold_second)\n",
    "else:\n",
    "    c = (df_marker[metric_name]<=threshold) & (df_marker[metric_name]>=threshold_second) \n",
    "\n",
    "# threshold\n",
    "df_marker_filtered = df_marker[c]\n",
    "# shuffle\n",
    "df_marker_filtered = df_marker_filtered.sample(frac=1, random_state=1)\n",
    "\n",
    "print(f\"Number of {marker} images in threshold {threshold} ({per}%) (and {threshold_second} ({per_second_bound}%)): {len(df_marker_filtered)}\")\n",
    "print(\"\\n\\n\")\n",
    "print(df_marker_filtered['CellLine'].value_counts().to_string())\n",
    "print(df_marker_filtered['Condition'].value_counts().to_string())\n",
    "\n",
    "if show_percentile_plot:\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(percentiles.keys().to_numpy()[4:-1], percentiles.values[4:-1])\n",
    "    plt.ylabel('value')\n",
    "    plt.xlabel('percentile')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "show_images(df_marker_filtered, max_samples=max_samples)    \n",
    "\n",
    "save_to_mapping(mappings_filepath, mappings, marker, round(threshold,2), is_upper_bound)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Brenners and set the threshold in the next block (option 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Examine Brenners (write the thresholds in the next block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### SAFE ZONE TO CHANGE ###############\n",
    "\n",
    "marker = 'Neuronal-activity' # MAKRENAME\n",
    "# [marker] Options:\n",
    "# ['Autophagy' 'DAPI' 'impaired-Autophagosome' 'UPR-ATF4' 'UPR-ATF6'\n",
    "#  'UPR-IRE1a' 'Ubiquitin-levels' 'DNA-damage-P53BP1' 'Neuronal-activity'\n",
    "#  'Necroptosis-HMGB1' 'Necrosis' 'DNA-damage-pH2Ax' 'Parthanatos-early'\n",
    "#  'Cytoskeleton' 'Stress-initiation' 'mature-Autophagosome'\n",
    "#  'Nuclear-speckles-SON' 'TDP-43' 'Nuclear-speckles-SC35'\n",
    "#  'Splicing-factories' 'Aberrant-splicing' 'Parthanatos-late'\n",
    "#  'Protein-degradation' 'Senescence-signaling' 'Apoptosis'\n",
    "#  'Necroptosis-pMLKL']\n",
    "\n",
    "per_min = 89\n",
    "per_max = 90\n",
    "max_samples = 20\n",
    "\n",
    "###################### END OF SAFE ZONE ###################\n",
    "\n",
    "\n",
    "\n",
    "df_marker = df.loc[df['Marker'] == marker]\n",
    "percentiles = df_marker[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "\n",
    "print(f'Showing images between %{per_min} - {per_max}')\n",
    "threshold = percentiles[f'{per_min}%']\n",
    "threshold_second = percentiles[f'{per_max}%']\n",
    "\n",
    "c = (df_marker[metric_name]>=threshold) & (df_marker[metric_name]<=threshold_second) \n",
    "\n",
    "# threshold\n",
    "df_marker_filtered = df_marker[c]\n",
    "# shuffle\n",
    "df_marker_filtered = df_marker_filtered.sample(frac=1, random_state=1)\n",
    "# df_marker_filtered.index = range(len(df_marker_filtered))\n",
    "\n",
    "print(f\"Number of {marker} images in threshold {threshold} ({per_min}%) (and {threshold_second} ({per_max}%)): {len(df_marker_filtered)}\")\n",
    "print(\"\\n\")\n",
    "print(df_marker_filtered['CellLine'].value_counts().to_string())\n",
    "print(\"\\n\")\n",
    "print(df_marker_filtered['Condition'].value_counts().to_string())\n",
    "print(\"\\n\")\n",
    "show_images(df_marker_filtered, max_samples=max_samples)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Setting Brenners in the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {\n",
    "    \"DAPI\": (2, 100),\n",
    "    'ARL13B': (0.5, 100),\n",
    "    'Vimentin': (1, 100),\n",
    "    'WDR49': (2, 100),\n",
    "    'Calreticulin': (0, 100),\n",
    "    'PML': (1, 100),\n",
    "    'TDP43': (15, 100)\n",
    "}\n",
    "\n",
    "mappings = update_all_mappings(mappings, thresholds, df)\n",
    "mappings.to_csv(mappings_filepath)\n",
    "mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print top brenners per marker\n",
    "max_samples = 5\n",
    "df_path = \"/home/projects/hornsteinlab/Collaboration/MOmaps/outputs/preprocessing/Opera/brenner/raw_metrics250324.csv\"\n",
    "\n",
    "print(f\"max_samples = {max_samples}\")\n",
    "\n",
    "df = pd.read_csv(df_path)\n",
    "print(df.shape)\n",
    "\n",
    "markers = df['Marker'].unique()\n",
    "print(markers.shape)\n",
    "\n",
    "for marker in markers:\n",
    "    print(marker)\n",
    "    df_marker = df.loc[df['Marker'] == marker]\n",
    "    print(f\"df_marker shape: {df_marker.shape}\")\n",
    "    df_marker.sort_values('Target_Sharpness_Brenner', ascending=False, inplace=True)\n",
    "    df_marker_subset = df_marker.iloc[:max_samples]\n",
    "    show_images(df_marker_subset, max_samples=max_samples)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug differences by cell lines in Brenner scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"panel\"] = df[\"Path\"].str.extract(r\"/(panel[^/]+)/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC = df[df[\"panel\"] == \"panelC\"]\n",
    "for marker in all_markers:\n",
    "    print(marker)\n",
    "    if marker in dfC.Marker.unique():\n",
    "        df_marker = dfC.loc[dfC['Marker'] == marker]\n",
    "        percentiles = df_marker[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "        actual_x_limits = (percentiles['0%'], percentiles['97%'])\n",
    "        create_histogram(\n",
    "                        df_marker,\n",
    "                        percentiles,\n",
    "                        low_perc=0,\n",
    "                        high_perc=97,\n",
    "                        actual_x_limits=actual_x_limits,\n",
    "                        overlay_group=['CellLine']\n",
    "                    )\n",
    "        plt.title(marker)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for marker in all_markers:\n",
    "    df_marker = df[df[\"Marker\"] == marker]\n",
    "    print(marker)\n",
    "    for panel in dfDAPI.panel.unique():\n",
    "        print(panel)\n",
    "        df_panel = df_marker.loc[df_marker['panel'] == panel]\n",
    "        if marker in df_panel.Marker.unique():\n",
    "            percentiles = df_panel[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "            actual_x_limits = (percentiles['0%'], percentiles['97%'])\n",
    "            create_histogram(\n",
    "                            df_panel,\n",
    "                            percentiles,\n",
    "                            low_perc=0,\n",
    "                            high_perc=97,\n",
    "                            actual_x_limits=actual_x_limits,\n",
    "                            overlay_group=['CellLine']\n",
    "                        )\n",
    "            plt.title(f'Marker {marker} Panel {panel}')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(\"histogram_report.pdf\") as pdf:\n",
    "    for marker in all_markers:\n",
    "        df_marker = df[df[\"Marker\"] == marker]\n",
    "        panels = sorted(df_marker[\"panel\"].unique())\n",
    "        n = len(panels)\n",
    "\n",
    "        fig, axes = plt.subplots(1, n, figsize=(5 * n, 4))\n",
    "        if n == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for i, panel in enumerate(panels):\n",
    "            df_panel = df_marker[df_marker[\"panel\"] == panel]\n",
    "            if df_panel.empty:\n",
    "                continue\n",
    "\n",
    "            percentiles = df_panel[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "            actual_x_limits = (percentiles['0%'], percentiles['97%'])\n",
    "\n",
    "            plt.sca(axes[i])\n",
    "            create_histogram(\n",
    "                df_panel,\n",
    "                percentiles,\n",
    "                low_perc=0,\n",
    "                high_perc=97,\n",
    "                actual_x_limits=actual_x_limits,\n",
    "                overlay_group=['CellLine']\n",
    "            )\n",
    "            \n",
    "            # Split by CellLine\n",
    "#             wt_vals = df_panel[df_panel[\"CellLine\"] == \"WT\"][metric_name]\n",
    "#             c9_vals = df_panel[df_panel[\"CellLine\"] == \"C9\"][metric_name]\n",
    "\n",
    "#             stat, p_val = mannwhitneyu(wt_vals, c9_vals, alternative=\"two-sided\")\n",
    "#             comparison = \"WT < C9\" if wt_vals.mean() < c9_vals.mean() else \"WT ≥ C9\"\n",
    "#             title = f\"Panel {panel}\\n{comparison}, p = {p_val:.1e}\"\n",
    "            axes[i].set_title(f\"Panel {panel}\")\n",
    "\n",
    "        fig.suptitle(f\"Marker: {marker}\", fontsize=16)\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.92])\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(\"representative_images.pdf\") as pdf:\n",
    "    for marker in all_markers:\n",
    "        df_marker = df[df[\"Marker\"] == marker]\n",
    "        panels = sorted(df_marker[\"panel\"].unique())\n",
    "        cell_lines = ['WT', 'C9']\n",
    "\n",
    "        nrows = len(cell_lines)\n",
    "        ncols = len(panels)\n",
    "        fig, axes = plt.subplots(\n",
    "            nrows, ncols,\n",
    "            figsize=(3 * ncols, 2.1 * nrows),\n",
    "            constrained_layout=True\n",
    "        )\n",
    "\n",
    "        if nrows == 1:\n",
    "            axes = [axes]\n",
    "        if ncols == 1:\n",
    "            axes = [[ax] for ax in axes]\n",
    "\n",
    "        for i, cl in enumerate(cell_lines):\n",
    "            for j, panel in enumerate(panels):\n",
    "                ax = axes[i][j]\n",
    "                df_sub = df_marker[(df_marker[\"panel\"] == panel) & (df_marker[\"CellLine\"] == cl)]\n",
    "                if not df_sub.empty:\n",
    "                    paths = df_sub.sample(min(3, len(df_sub)), random_state=42)[\"Path\"].values\n",
    "                    imgs = [process_tif(p) for p in paths]\n",
    "\n",
    "                    # Match image heights\n",
    "                    min_height = min(img.shape[0] for img in imgs)\n",
    "                    imgs_resized = [img[:min_height, :] for img in imgs]\n",
    "\n",
    "                    # Insert white spacer (10 pixels) between images\n",
    "                    dtype = imgs_resized[0].dtype\n",
    "                    spacer = np.full((min_height, 10), fill_value=imgs_resized[0].max(), dtype=dtype)\n",
    "                    combined = imgs_resized[0]\n",
    "                    for img in imgs_resized[1:]:\n",
    "                        combined = np.concatenate([combined, spacer, img], axis=1)\n",
    "#                     ax.set_title([path.split('batch1')[1] for path in paths][0])\n",
    "                    ax.imshow(combined, cmap=\"gray\")\n",
    "                else:\n",
    "                    ax.text(0.5, 0.5, \"No image\", ha=\"center\", va=\"center\")\n",
    "\n",
    "                if i == 0:\n",
    "                    ax.set_title(panel, fontsize=10)\n",
    "                if j == 0:\n",
    "                    ax.text(-0.1, 0.5, cl, va='center', ha='right', fontsize=10, transform=ax.transAxes)\n",
    "\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "        fig.suptitle(f\"Marker: {marker}\", fontsize=18)\n",
    "        fig.subplots_adjust(left=0.12, right=0.98, top=0.90, bottom=0.08, wspace=0.1, hspace=0.05)\n",
    "        pdf.savefig(fig, dpi=300)\n",
    "        plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nova",
   "language": "python",
   "name": "nova"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
