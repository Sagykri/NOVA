{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOVA_HOME: /home/labs/hornsteinlab/Collaboration/NOVA_GAL/NOVA\n",
      "Modules to reload:\n",
      "all-except-skipped\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import sklearn\n",
    "import os\n",
    "import os\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image\n",
    "import sys\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "os.environ['NOVA_HOME'] = '/home/labs/hornsteinlab/Collaboration/NOVA_GAL/NOVA'\n",
    "\n",
    "sys.path.insert(1, os.getenv('NOVA_HOME'))\n",
    "sys.path.insert(1, os.getenv(\"NOVA_HOME\"))\n",
    "print(f\"NOVA_HOME: {os.getenv('NOVA_HOME')}\")\n",
    "\n",
    "from src.preprocessing.preprocessing_utils import get_image_focus_quality \n",
    "from src.preprocessing.preprocessing_utils import rescale_intensity, fit_image_shape\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "def get_npy_files(path):\n",
    "    npy_files = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('.npy'):\n",
    "                npy_files.append(os.path.join(root, file))\n",
    "    return npy_files\n",
    "\n",
    "import skimage\n",
    "\n",
    "\n",
    "def get_metrics_processed(tile):\n",
    "  metrics = ()\n",
    "  for c in range(tile.shape[-1]):\n",
    "    metrics += get_metrics(tile[...,c])\n",
    "    \n",
    "  return metrics\n",
    "\n",
    "def get_metrics(tile, as_string=False):\n",
    "    sharpness_brenner = get_image_focus_quality(tile)    \n",
    "    if as_string:\n",
    "        return f\"Brenner: {round(sharpness_brenner, 3)}\"\n",
    "    return sharpness_brenner\n",
    "\n",
    "# def get_metrics_columns():\n",
    "#   return [\"Path\", \"Quality\", \"Target_SNR\", \"Target_Sharpness_Laplacian\", \"Target_Var\",\n",
    "#            'Target_Sharpness_Brenner', \"Target_Entropy\", \"Target_Sigma\", \"Target_HighFreq\", \"DAPI_SNR\", \"DAPI_Sharpness_Laplacian\",\n",
    "#             \"DAPI_Var\", 'DAPI_Sharpness_Brenner', \"DAPI_Entropy\", \"DAPI_Sigma\", \"DAPI_HighFreq\"]\n",
    "\n",
    "\n",
    "def run_dim_reduction(dim_red, images, labels=None, show=True):\n",
    "  # Perform PCA\n",
    "  images = images.reshape(images.shape[0], -1)\n",
    "  reduced = dim_red.fit_transform(images)\n",
    "  \n",
    "  if not show:\n",
    "    return reduced\n",
    "  \n",
    "  if labels is None:\n",
    "    plt.scatter(reduced[:,0], reduced[:,1])\n",
    "    plt.show()\n",
    "    return reduced\n",
    "  \n",
    "  \n",
    "  labels_unique = np.unique(labels)\n",
    "  \n",
    "  for l in labels_unique:\n",
    "    indexes = labels == l\n",
    "    plt.scatter(reduced[indexes,0], reduced[indexes,1], alpha=0.5)\n",
    "  plt.legend(labels_unique)\n",
    "  plt.show()\n",
    "  \n",
    "  return reduced \n",
    "\n",
    "def plot_images(images, vmin=0,vmax=1000):\n",
    "    for i in range(len(images)):\n",
    "        fig, ax = plt.subplots(1, 2)\n",
    "        ax[0].imshow(images[i,...,0])#, vmin=vmin,vmax=vmax)\n",
    "        ax[0].set_title(\"Target\")\n",
    "        ax[1].imshow(images[i,...,1])#, vmin=vmin,vmax=vmax)\n",
    "        ax[1].set_title(\"Nucleus\")\n",
    "        plt.show()\n",
    "        \n",
    "def load_tiles(paths):\n",
    "  paths_split = map(lambda x: (x.rsplit('_',1)[0], int(x.rsplit('_',1)[1])), paths.reshape(-1,))\n",
    "  tiles = []\n",
    "  for filename, tile_number in paths_split:\n",
    "    t = np.load(filename)[tile_number, ...]\n",
    "    tiles.append(t)\n",
    "    \n",
    "  tiles = np.stack(tiles)\n",
    "  return tiles\n",
    "\n",
    "\n",
    "\n",
    "def get_outliers(df, feature, split=False, iqrs=1.5):\n",
    "    # Calculate Q1, Q3, and IQR\n",
    "    Q1 = df[feature].quantile(0.25)\n",
    "    Q3 = df[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower = df[feature] < Q1 - iqrs* IQR\n",
    "    higher = df[feature] > Q3 + iqrs*IQR\n",
    "    if split:\n",
    "        # Determine outliers using IQR\n",
    "        outliers_lower = df[lower]\n",
    "        outliers_higher = df[higher]\n",
    "        return outliers_lower, outliers_higher\n",
    "    \n",
    "    # Determine outliers using IQR\n",
    "    outliers = df[(lower ) | (higher)]\n",
    "    \n",
    "    return outliers\n",
    "\n",
    "def show_images(df, max_samples = 10):\n",
    "    for ind, path in enumerate(df.Path.values):\n",
    "        print(ind)\n",
    "        if max_samples is not None and ind >= max_samples:\n",
    "            print(f\"Stopping at {ind}. There are {len(df.Path.values)} images in total\")\n",
    "            break\n",
    "        \n",
    "        # Target\n",
    "        target_path = os.path.join(d, path)\n",
    "        show_processed_tif(target_path)\n",
    "        # His DAPI\n",
    "        # path_l = target_path.split(\"/\")\n",
    "        # path_l[-2] = 'DAPI'\n",
    "        \n",
    "        # file_name = path_l[-1].split(\"_\")\n",
    "        # dapi_file_name = \"_\".join([file_name[0], 'w1confDAPI', file_name[-1]])\n",
    "        # dapi_file_name = \"/\".join([*path_l[:-1], dapi_file_name])\n",
    "        # print(dapi_file_name)\n",
    "\n",
    "        # show_processed_tif(dapi_file_name)\n",
    "        print('--------------------------------')\n",
    "        \n",
    "def get_dapi_file_name(path):\n",
    "    site_path, tile_number = path.rsplit('_',1)\n",
    "    path_l = site_path.split(\"/\")\n",
    "    path_l[-2] = 'DAPI'\n",
    "\n",
    "    file_name = path_l[-1].split(\"_\")\n",
    "    dapi_file_name = \"_\".join([file_name[0], 'w1confDAPI', file_name[-1]])\n",
    "    dapi_file_name = \"/\".join([*path_l[:-1], f'{dapi_file_name}_{tile_number}'])\n",
    "    \n",
    "    return dapi_file_name\n",
    "        \n",
    "def show_tiles(df, max_samples=10, rescale_tile=False):\n",
    "    for ind, path in enumerate(df.Path.values):\n",
    "        site_path, tile_number = path.rsplit('_',1)\n",
    "        tile_number = int(tile_number)\n",
    "        print(ind)\n",
    "        if max_samples is not None and ind >= max_samples:\n",
    "            print(f\"Stopping at {ind}. There are {len(df.Path.values)} images in total\")\n",
    "            break\n",
    "        \n",
    "        # Target\n",
    "        show_tile(site_path, tile_number, rescale_tile)\n",
    "        # His DAPI\n",
    "        path_l = site_path.split(\"/\")\n",
    "        path_l[-2] = 'DAPI'\n",
    "        \n",
    "        file_name = path_l[-1].split(\"_\")\n",
    "        dapi_file_name = \"_\".join([file_name[0], 'w1confDAPI', file_name[-1]])\n",
    "        dapi_file_name = \"/\".join([*path_l[:-1], dapi_file_name])\n",
    "        print(dapi_file_name)\n",
    "\n",
    "        show_tile(dapi_file_name, tile_number, rescale_tile)\n",
    "        print('--------------------------------')\n",
    "        \n",
    "# def save_to_mapping(mappings, marker, metric_name, low_threshold, high_threshold):\n",
    "#     mappings[marker] = {\n",
    "#         metric_name: {\n",
    "#             'low_threshold': low_threshold,\n",
    "#             'high_threshold': high_threshold\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "def init_mappings(markers=[], filepath=None):\n",
    "    if filepath is not None:     \n",
    "        if os.path.exists(filepath):\n",
    "            mappings = pd.read_csv(filepath, index_col=0)\n",
    "            return mappings\n",
    "        \n",
    "    mappings = pd.DataFrame(columns=['Lower_bound', 'Upper_bound'], index=markers)\n",
    "\n",
    "    return mappings\n",
    "        \n",
    "def save_to_mapping(filepath, mappings, marker, value, is_upper_bound):\n",
    "    col = 'Upper_bound' if is_upper_bound else 'Lower_bound' \n",
    "    mappings.loc[marker, col] = value\n",
    "    \n",
    "    mappings.to_csv(filepath)\n",
    "    print(f\"File saved to {filepath}\")\n",
    "    \n",
    "    \n",
    "def processed_path_to_raw_paths(path):\n",
    "    path_splited = path.split(os.sep)\n",
    "    filename = path_splited[-1]\n",
    "    filename_split = filename.split('_')\n",
    "    rep = filename_split[0]\n",
    "    panel = filename_split[4]\n",
    "    line = filename_split[5]\n",
    "    filename_new = '_'.join(filename_split[1:4])\n",
    "    batch = path_splited[-5]\n",
    "    batch = batch.split('_')[0]\n",
    "    cond = path_splited[-3]\n",
    "    marker = path_splited[-2]\n",
    "    \n",
    "    ret = os.path.join(\"/home/labs/hornsteinlab/Collaboration/MOmaps/input/images/raw/Cory/indi-image-pilot-20241128\", batch, line, panel, cond, rep, marker, f'{filename_new}.tif')\n",
    "    return ret\n",
    "\n",
    "def raw_path_to_processed_path(path):\n",
    "    path_splited = path.split(os.sep)\n",
    "    filename = os.path.splitext(path_splited[-1])[0]\n",
    "    rep = path_splited[-3]\n",
    "    panel = path_splited[-5]\n",
    "    line = path_splited[-6]\n",
    "    batch = path_splited[-7]\n",
    "    batch = f\"{batch}_16bit_no_downsample\"\n",
    "    cond = path_splited[-4]\n",
    "    marker = path_splited[-2]\n",
    "    \n",
    "    ret = os.path.join(\"/home/labs/hornsteinlab/Collaboration/MOmaps/input/images/processed/spd2/SpinningDisk/\", batch, line, cond, marker, f'{rep}_{filename}_{panel}_{line}_processed.npy')\n",
    "    return ret\n",
    "\n",
    "\n",
    "d = '/home/labs/hornsteinlab/Collaboration/MOmaps/input/images/raw/Cory/indi-image-pilot-20241128/'\n",
    "\n",
    "def show_label(path):\n",
    "    path_l = path.split(\"/\")\n",
    "    return path_l[-7:]\n",
    "    \n",
    "def show_processed_tif(path):\n",
    "    # read the image stack\n",
    "    img = cv2.imread(path, cv2.IMREAD_ANYDEPTH) \n",
    "    img = fit_image_shape(img, (1024, 1024))\n",
    "    # rescale pixel intensities\n",
    "    img = rescale_intensity(img)\n",
    "    \n",
    "    # show the image with grid \n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    put_tiles_grid(image=img, ax=ax)\n",
    "    plt.axis('off')\n",
    "    plt.title(show_label(path), color='purple')\n",
    "    print(get_metrics(img, True))\n",
    "    print(f\"Img shape: {img.shape}\")\n",
    "    plt.show()\n",
    "    \n",
    "def show_tile(site_path, tile_number, rescale_tile=False):\n",
    "    # read the image stack\n",
    "    img = cv2.imread(site_path, cv2.IMREAD_ANYDEPTH) \n",
    "    img = fit_image_shape(img, (1024, 1024))\n",
    "    # rescale pixel intensities\n",
    "    img = rescale_intensity(img)\n",
    "    \n",
    "    row_ind = tile_number // 10\n",
    "    col_ind = tile_number % 10\n",
    "    img = img[row_ind * 100 : (row_ind + 1) * 100, col_ind * 100 : (col_ind + 1) * 100]\n",
    "    \n",
    "    print(f\"img shape: {np.asarray(img).shape}\")\n",
    "    \n",
    "#     # Check dead cells?\n",
    "#     img_uint8 = img.astype(np.uint8)\n",
    "#     # Apply Gaussian blur\n",
    "# #     gray_blurred = cv2.GaussianBlur(img_uint8, (9, 9), 0)\n",
    "\n",
    "#     # Apply Hough Circle Transform\n",
    "#     # Adjust the parameters, especially minRadius and maxRadius, to detect small circles\n",
    "#     circles = cv2.HoughCircles(img_uint8, cv2.HOUGH_GRADIENT, 1, 20, param1=50, param2=30, minRadius=0, maxRadius=0)\n",
    "   \n",
    "    \n",
    "    if rescale_tile:\n",
    "        print(\"NOTICE! Rescaling also the tile!!!!!\")\n",
    "        img = rescale_intensity(img)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    plt.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "    \n",
    "#     if circles is not None:\n",
    "#         print(f\"circles count: {len(circles)}\")\n",
    "#         circles = np.uint16(np.around(circles))\n",
    "#         for i in circles[0, :]:\n",
    "#             center = (i[0], i[1])  # circle center\n",
    "#             radius = i[2]  # circle radius\n",
    "#             cv2.circle(image, center, radius, (0, 255, 0), 2)\n",
    "    \n",
    "#     put_tiles_grid(image=img, ax=ax)\n",
    "    plt.axis('off')\n",
    "    plt.title(show_label(site_path), color='purple')\n",
    "    print(get_metrics(img, True))\n",
    "    plt.show()\n",
    "    \n",
    "def crop_frame(original_image):\n",
    "    # Crop the image by removing a 12-pixel frame from each side\n",
    "    cropped_image = original_image[12:1012, 12:1012]  \n",
    "    return cropped_image\n",
    "\n",
    "def crop_site_to_tiles(img):\n",
    "    from skimage.util import view_as_blocks\n",
    "    # Break the cropped image into 64 tiles of size 100x100\n",
    "    tile_size = 100\n",
    "    num_tiles = 64\n",
    "\n",
    "    # Reshape the image into tiles using view_as_blocks from skimage\n",
    "    tiles = view_as_blocks(img, block_shape=(tile_size, tile_size, 3))\n",
    "\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            tile = tiles[i, j]\n",
    "    return \n",
    "\n",
    "def put_tiles_grid(image, ax):\n",
    "    # assumes 1000x1000 image\n",
    "    import matplotlib.patches as patches\n",
    "\n",
    "    # Add dashed grid lines for 64 blocks\n",
    "    num_blocks = 10\n",
    "    block_size = 100\n",
    "\n",
    "    for i in range(1, num_blocks):\n",
    "        # Draw horizontal dashed lines\n",
    "        ax.plot([0, 1000], [i * block_size, i * block_size], linestyle='--', lw=1, alpha=0.5, color='pink')\n",
    "\n",
    "        # Draw vertical dashed lines\n",
    "        ax.plot([i * block_size, i * block_size], [0, 1000], linestyle='--', lw=1, alpha=0.5, color='pink')\n",
    "\n",
    "    # Remove x and y axis labels\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Add a title\n",
    "    plt.title('Image with Dashed Grid of 64 Blocks')\n",
    "\n",
    "def create_histogram(df_marker_brenner, percentiles, low_perc = 0.5, high_perc = 99.9, x_min=None, x_max=None, overlay_Cellline = False):\n",
    "    hist_range = (percentiles[f'{x_min}%'], percentiles[f'{x_max}%']) if x_min is not None and x_max is not None else None\n",
    "    plt.hist(df_marker_brenner.values, bins = 100, range=hist_range, color=plt.cm.tab10(range(1))[0], alpha=0.6, label = 'Brenner scores')\n",
    "    if overlay_Cellline:\n",
    "        # Overlay histograms for each CellLine\n",
    "        unique_celllines = df_marker['CellLine'].unique()\n",
    "        colors = plt.cm.tab10(range(len(unique_celllines)+1))[1:]  # Use a colormap for distinct colors\n",
    "\n",
    "        for color, cellline in zip(colors, unique_celllines):\n",
    "            # Filter data for the current CellLine\n",
    "            cellline_data = df_marker[metric_name][df_marker['CellLine'] == cellline]\n",
    "            # Plot histogram for the current CellLine with transparency\n",
    "            plt.hist(cellline_data.values, bins=100, range=hist_range, alpha=0.4, label=f'{cellline}', color=color)\n",
    "\n",
    "    plt.scatter(percentiles['50%'], 0.5, color='yellow', s=12, label='50th percentile')\n",
    "    plt.scatter(percentiles[f'{high_perc}%'], 0.5, color='orange', s=12, label=f'{high_perc}th percentile')\n",
    "    plt.scatter(percentiles[f'{low_perc}%'], 0.5, color='r', s=12, label=f'{low_perc}th percentile')\n",
    "    plt.legend()\n",
    "    # plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/labs/hornsteinlab/Collaboration/MOmaps/outputs/preprocessing/NIH/brenner/raw_metrics021224_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Marker\n",
       "DAPI            32750\n",
       "TUJ1            23825\n",
       "ANAX11           3000\n",
       "SNCA             3000\n",
       "TDP43            3000\n",
       "P54              3000\n",
       "CD41             3000\n",
       "KIF5A            3000\n",
       "FMRP             3000\n",
       "G3BP1            3000\n",
       "SQSTM1           3000\n",
       "MitoTracker      2975\n",
       "NCL              2975\n",
       "PSD95            2975\n",
       "CLTC             2975\n",
       "LAMP1            2975\n",
       "FUS              2975\n",
       "PURA             2975\n",
       "Calreticulin     2975\n",
       "TIA1             2975\n",
       "NEMO             2950\n",
       "DCP1A            2950\n",
       "TOMM20           2950\n",
       "Phalloidin       2950\n",
       "GM130            2950\n",
       "PML              2950\n",
       "PEX14            2950\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Marker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "['ANAX11' 'DAPI' 'SNCA' 'TUJ1' 'DCP1A' 'NEMO' 'CLTC' 'PSD95' 'CD41' 'P54'\n",
      " 'TDP43' 'GM130' 'Phalloidin' 'TOMM20' 'Calreticulin' 'LAMP1' 'FMRP'\n",
      " 'SQSTM1' 'G3BP1' 'KIF5A' 'PEX14' 'PML' 'PURA' 'TIA1' 'FUS' 'MitoTracker'\n",
      " 'NCL']\n"
     ]
    }
   ],
   "source": [
    "counts = df['Marker'].value_counts()\n",
    "all_markers = df['Marker'].unique()\n",
    "print(len(all_markers))\n",
    "print(all_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Brenner report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_samples = 3\n",
    "metric_name = 'Target_Sharpness_Brenner'\n",
    "percentiles_to_describe = np.arange(0, 1.001, 0.001)\n",
    "percentile_ranges = [0, 0.1, 0.2, 0.3, 0.5, 0.7, 1, 2, 5, 10, 15, 20, 30, 40, 60, 75, 80, 85, 90, 95, 98, 99, 99.5, 99.7, 99.8,99.9,100]\n",
    "output_folder = \"brenner_reports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANAX11\n",
      "DAPI\n",
      "SNCA\n",
      "TUJ1\n",
      "DCP1A\n",
      "NEMO\n",
      "CLTC\n",
      "PSD95\n",
      "CD41\n",
      "P54\n",
      "TDP43\n",
      "GM130\n",
      "Phalloidin\n",
      "TOMM20\n",
      "Calreticulin\n",
      "LAMP1\n",
      "FMRP\n",
      "SQSTM1\n",
      "G3BP1\n",
      "KIF5A\n",
      "PEX14\n",
      "PML\n",
      "PURA\n",
      "TIA1\n",
      "FUS\n",
      "MitoTracker\n",
      "NCL\n"
     ]
    }
   ],
   "source": [
    "# Ensure the folder exists\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for marker in all_markers:\n",
    "    print(marker)\n",
    "    df_marker = df.loc[df['Marker'] == marker]\n",
    "    percentiles = df_marker[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "\n",
    "    pdf_path = os.path.join(output_folder, f'output_report_{marker}.pdf')\n",
    "    with PdfPages(pdf_path) as pdf:    \n",
    "        \n",
    "        fig = plt.figure(figsize=(12, 8))  \n",
    "        gs = GridSpec(2, 2, figure=fig, height_ratios=[4, 1])  \n",
    "        fig.suptitle(f\"Marker: {marker}\", fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Histogram 1: Full Range\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        create_histogram(df_marker[metric_name], percentiles, low_perc=1, high_perc=99)\n",
    "        ax1.set_title(\"Histogram 1 - Full Range\")\n",
    "        \n",
    "        # Histogram 2: Limited Range\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        create_histogram(df_marker[metric_name], percentiles, low_perc=1, high_perc=99, x_min=1, x_max=99, overlay_Cellline=True)\n",
    "        ax2.set_title(\"Histogram 2 - Limited Range\")\n",
    "        \n",
    "        pdf.savefig(fig) \n",
    "        plt.close(fig) \n",
    "\n",
    "        for i in range(len(percentile_ranges) - 1):\n",
    "            per_min = np.round(percentile_ranges[i],2)\n",
    "            per_max = np.round(percentile_ranges[i + 1],2)\n",
    "            text_output = f'Images between %{per_min} - {per_max}%\\n'\n",
    "            threshold = percentiles[f'{per_min}%']\n",
    "            threshold_second = percentiles[f'{per_max}%']\n",
    "\n",
    "            c = (df_marker[metric_name] >= threshold) & (df_marker[metric_name] <= threshold_second)\n",
    "\n",
    "            df_marker_filtered = df_marker[c]\n",
    "            df_marker_filtered = df_marker_filtered.sample(frac=1, random_state=1)\n",
    "\n",
    "            text_output += (f\"Number of {marker} images in threshold {threshold} \"\n",
    "                            f\"({per_min}%) (and {threshold_second} ({per_max}%)): \"\n",
    "                            f\"{len(df_marker_filtered)}\\n\\n\")\n",
    "            text_output += df_marker_filtered['CellLine'].value_counts().to_string() + \"\\n\\n\"\n",
    "            text_output += df_marker_filtered['Condition'].value_counts().to_string() + \"\\n\\n\"\n",
    "\n",
    "            fig = plt.figure(figsize=(12, 8))\n",
    "            gs = GridSpec(3, 1, figure=fig, height_ratios=[1, 2, 0.1]) \n",
    "            text_ax = fig.add_subplot(gs[0, :]) \n",
    "\n",
    "            text_ax.axis('off') \n",
    "            text_ax.text(0.01, 0.99, text_output, ha='left', va='top', fontsize=12, wrap=True)\n",
    "\n",
    "            filtered_paths = df_marker_filtered['Path'].values\n",
    "            num_images = min(max_samples, len(filtered_paths))\n",
    "\n",
    "            img_gs = gs[1].subgridspec(1, num_images, wspace=0.1)  \n",
    "            for ind, path in enumerate(filtered_paths[:num_images]):\n",
    "                # Read and process the image\n",
    "                target_path = os.path.join(d, path)\n",
    "                img = cv2.imread(target_path, cv2.IMREAD_ANYDEPTH)\n",
    "                img = fit_image_shape(img, (1024, 1024))\n",
    "                img = rescale_intensity(img)\n",
    "\n",
    "                # Add image subplot\n",
    "                ax = fig.add_subplot(img_gs[0, ind])\n",
    "                ax.imshow(img, cmap='gray')\n",
    "                put_tiles_grid(image=img, ax=ax)\n",
    "                ax.axis('off')\n",
    "                labels = show_label(path)\n",
    "                perc_brenner = abs(percentiles[[per for per in percentiles.keys() if '%' in per]] - get_image_focus_quality(img)).idxmin()\n",
    "                ax.set_title(f\"{labels[1]}, {labels[3]}, {get_metrics(img, True)}, {perc_brenner}\", color='purple', fontsize=10)\n",
    "\n",
    "            # Save the current page\n",
    "            plt.tight_layout()\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)  # Free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nova",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
