{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import sklearn\n",
    "import os\n",
    "import os\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "\n",
    "os.environ['NOVA_HOME'] = '/home/labs/hornsteinlab/Collaboration/MOmaps'\n",
    "\n",
    "sys.path.insert(1, os.getenv('NOVA_HOME'))\n",
    "sys.path.insert(1, os.getenv(\"NOVA_HOME\"))\n",
    "print(f\"NOVA_HOME: {os.getenv('NOVA_HOME')}\")\n",
    "\n",
    "from src.preprocessing.preprocessing_utils import get_image_focus_quality \n",
    "from src.preprocessing.preprocessing_utils import rescale_intensity, fit_image_shape\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "def get_npy_files(path):\n",
    "    npy_files = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('.npy'):\n",
    "                npy_files.append(os.path.join(root, file))\n",
    "    return npy_files\n",
    "\n",
    "import skimage\n",
    "\n",
    "\n",
    "def get_metrics_processed(tile):\n",
    "  metrics = ()\n",
    "  for c in range(tile.shape[-1]):\n",
    "    metrics += get_metrics(tile[...,c])\n",
    "    \n",
    "  return metrics\n",
    "\n",
    "def get_metrics(tile, as_string=False):\n",
    "    sharpness_brenner = get_image_focus_quality(tile)    \n",
    "    if as_string:\n",
    "        return f\"Brenner: {round(sharpness_brenner, 3)}\"\n",
    "    return sharpness_brenner\n",
    "\n",
    "# def get_metrics_columns():\n",
    "#   return [\"Path\", \"Quality\", \"Target_SNR\", \"Target_Sharpness_Laplacian\", \"Target_Var\",\n",
    "#            'Target_Sharpness_Brenner', \"Target_Entropy\", \"Target_Sigma\", \"Target_HighFreq\", \"DAPI_SNR\", \"DAPI_Sharpness_Laplacian\",\n",
    "#             \"DAPI_Var\", 'DAPI_Sharpness_Brenner', \"DAPI_Entropy\", \"DAPI_Sigma\", \"DAPI_HighFreq\"]\n",
    "\n",
    "\n",
    "def run_dim_reduction(dim_red, images, labels=None, show=True):\n",
    "  # Perform PCA\n",
    "  images = images.reshape(images.shape[0], -1)\n",
    "  reduced = dim_red.fit_transform(images)\n",
    "  \n",
    "  if not show:\n",
    "    return reduced\n",
    "  \n",
    "  if labels is None:\n",
    "    plt.scatter(reduced[:,0], reduced[:,1])\n",
    "    plt.show()\n",
    "    return reduced\n",
    "  \n",
    "  \n",
    "  labels_unique = np.unique(labels)\n",
    "  \n",
    "  for l in labels_unique:\n",
    "    indexes = labels == l\n",
    "    plt.scatter(reduced[indexes,0], reduced[indexes,1], alpha=0.5)\n",
    "  plt.legend(labels_unique)\n",
    "  plt.show()\n",
    "  \n",
    "  return reduced \n",
    "\n",
    "def plot_images(images, vmin=0,vmax=1000):\n",
    "    for i in range(len(images)):\n",
    "        fig, ax = plt.subplots(1, 2)\n",
    "        ax[0].imshow(images[i,...,0])#, vmin=vmin,vmax=vmax)\n",
    "        ax[0].set_title(\"Target\")\n",
    "        ax[1].imshow(images[i,...,1])#, vmin=vmin,vmax=vmax)\n",
    "        ax[1].set_title(\"Nucleus\")\n",
    "        plt.show()\n",
    "        \n",
    "def load_tiles(paths):\n",
    "  paths_split = map(lambda x: (x.rsplit('_',1)[0], int(x.rsplit('_',1)[1])), paths.reshape(-1,))\n",
    "  tiles = []\n",
    "  for filename, tile_number in paths_split:\n",
    "    t = np.load(filename)[tile_number, ...]\n",
    "    tiles.append(t)\n",
    "    \n",
    "  tiles = np.stack(tiles)\n",
    "  return tiles\n",
    "\n",
    "\n",
    "\n",
    "def get_outliers(df, feature, split=False, iqrs=1.5):\n",
    "    # Calculate Q1, Q3, and IQR\n",
    "    Q1 = df[feature].quantile(0.25)\n",
    "    Q3 = df[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower = df[feature] < Q1 - iqrs* IQR\n",
    "    higher = df[feature] > Q3 + iqrs*IQR\n",
    "    if split:\n",
    "        # Determine outliers using IQR\n",
    "        outliers_lower = df[lower]\n",
    "        outliers_higher = df[higher]\n",
    "        return outliers_lower, outliers_higher\n",
    "    \n",
    "    # Determine outliers using IQR\n",
    "    outliers = df[(lower ) | (higher)]\n",
    "    \n",
    "    return outliers\n",
    "\n",
    "def show_images(df, max_samples = 10):\n",
    "    for ind, path in enumerate(df.Path.values):\n",
    "        print(ind)\n",
    "        if max_samples is not None and ind >= max_samples:\n",
    "            print(f\"Stopping at {ind}. There are {len(df.Path.values)} images in total\")\n",
    "            break\n",
    "        \n",
    "        # Target\n",
    "        target_path = os.path.join(d, path)\n",
    "        show_processed_tif(target_path)\n",
    "        # His DAPI\n",
    "        # path_l = target_path.split(\"/\")\n",
    "        # path_l[-2] = 'DAPI'\n",
    "        \n",
    "        # file_name = path_l[-1].split(\"_\")\n",
    "        # dapi_file_name = \"_\".join([file_name[0], 'w1confDAPI', file_name[-1]])\n",
    "        # dapi_file_name = \"/\".join([*path_l[:-1], dapi_file_name])\n",
    "        # print(dapi_file_name)\n",
    "\n",
    "        # show_processed_tif(dapi_file_name)\n",
    "        print('--------------------------------')\n",
    "        \n",
    "def get_dapi_file_name(path):\n",
    "    site_path, tile_number = path.rsplit('_',1)\n",
    "    path_l = site_path.split(\"/\")\n",
    "    path_l[-2] = 'DAPI'\n",
    "\n",
    "    file_name = path_l[-1].split(\"_\")\n",
    "    dapi_file_name = \"_\".join([file_name[0], 'w1confDAPI', file_name[-1]])\n",
    "    dapi_file_name = \"/\".join([*path_l[:-1], f'{dapi_file_name}_{tile_number}'])\n",
    "    \n",
    "    return dapi_file_name\n",
    "        \n",
    "def show_tiles(df, max_samples=10, rescale_tile=False):\n",
    "    for ind, path in enumerate(df.Path.values):\n",
    "        site_path, tile_number = path.rsplit('_',1)\n",
    "        tile_number = int(tile_number)\n",
    "        print(ind)\n",
    "        if max_samples is not None and ind >= max_samples:\n",
    "            print(f\"Stopping at {ind}. There are {len(df.Path.values)} images in total\")\n",
    "            break\n",
    "        \n",
    "        # Target\n",
    "        show_tile(site_path, tile_number, rescale_tile)\n",
    "        # His DAPI\n",
    "        path_l = site_path.split(\"/\")\n",
    "        path_l[-2] = 'DAPI'\n",
    "        \n",
    "        file_name = path_l[-1].split(\"_\")\n",
    "        dapi_file_name = \"_\".join([file_name[0], 'w1confDAPI', file_name[-1]])\n",
    "        dapi_file_name = \"/\".join([*path_l[:-1], dapi_file_name])\n",
    "        print(dapi_file_name)\n",
    "\n",
    "        show_tile(dapi_file_name, tile_number, rescale_tile)\n",
    "        print('--------------------------------')\n",
    "        \n",
    "# def save_to_mapping(mappings, marker, metric_name, low_threshold, high_threshold):\n",
    "#     mappings[marker] = {\n",
    "#         metric_name: {\n",
    "#             'low_threshold': low_threshold,\n",
    "#             'high_threshold': high_threshold\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "def init_mappings(markers=[], filepath=None):\n",
    "    if filepath is not None:     \n",
    "        if os.path.exists(filepath):\n",
    "            mappings = pd.read_csv(filepath, index_col=0)\n",
    "            return mappings\n",
    "        \n",
    "    mappings = pd.DataFrame(columns=['Lower_bound', 'Upper_bound'], index=markers)\n",
    "\n",
    "    return mappings\n",
    "        \n",
    "def save_to_mapping(filepath, mappings, marker, value, is_upper_bound):\n",
    "    col = 'Upper_bound' if is_upper_bound else 'Lower_bound' \n",
    "    mappings.loc[marker, col] = value\n",
    "    \n",
    "    mappings.to_csv(filepath)\n",
    "    print(f\"File saved to {filepath}\")\n",
    "    \n",
    "    \n",
    "def processed_path_to_raw_paths(path):\n",
    "    path_splited = path.split(os.sep)\n",
    "    filename = path_splited[-1]\n",
    "    filename_split = filename.split('_')\n",
    "    rep = filename_split[0]\n",
    "    panel = filename_split[4]\n",
    "    line = filename_split[5]\n",
    "    filename_new = '_'.join(filename_split[1:4])\n",
    "    batch = path_splited[-5]\n",
    "    batch = batch.split('_')[0]\n",
    "    cond = path_splited[-3]\n",
    "    marker = path_splited[-2]\n",
    "    \n",
    "    ret = os.path.join(\"/home/labs/hornsteinlab/Collaboration/MOmaps/input/images/raw/SpinningDisk\", batch, line, panel, cond, rep, marker, f'{filename_new}.tif')\n",
    "    return ret\n",
    "\n",
    "def raw_path_to_processed_path(path):\n",
    "    path_splited = path.split(os.sep)\n",
    "    filename = os.path.splitext(path_splited[-1])[0]\n",
    "    rep = path_splited[-3]\n",
    "    panel = path_splited[-5]\n",
    "    line = path_splited[-6]\n",
    "    batch = path_splited[-7]\n",
    "    batch = f\"{batch}_16bit_no_downsample\"\n",
    "    cond = path_splited[-4]\n",
    "    marker = path_splited[-2]\n",
    "    \n",
    "    ret = os.path.join(\"/home/labs/hornsteinlab/Collaboration/MOmaps/input/images/processed/spd2/SpinningDisk/\", batch, line, cond, marker, f'{rep}_{filename}_{panel}_{line}_processed.npy')\n",
    "    return ret\n",
    "\n",
    "\n",
    "d = '/home/labs/hornsteinlab/Collaboration/MOmaps/input/images/raw/SpinningDisk/'\n",
    "\n",
    "def show_label(path):\n",
    "    path_l = path.split(\"/\")\n",
    "    return path_l[-7:]\n",
    "    \n",
    "def show_processed_tif(path):\n",
    "    # read the image stack\n",
    "    img = cv2.imread(path, cv2.IMREAD_ANYDEPTH) \n",
    "    img = fit_image_shape(img, (1024, 1024))\n",
    "    # rescale pixel intensities\n",
    "    img = rescale_intensity(img)\n",
    "    \n",
    "    # show the image with grid \n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    put_tiles_grid(image=img, ax=ax)\n",
    "    plt.axis('off')\n",
    "    plt.title(show_label(path), color='purple')\n",
    "    print(get_metrics(img, True))\n",
    "    print(f\"Img shape: {img.shape}\")\n",
    "    plt.show()\n",
    "    \n",
    "def show_tile(site_path, tile_number, rescale_tile=False):\n",
    "    # read the image stack\n",
    "    img = cv2.imread(site_path, cv2.IMREAD_ANYDEPTH) \n",
    "    img = fit_image_shape(img, (1024, 1024))\n",
    "    # rescale pixel intensities\n",
    "    img = rescale_intensity(img)\n",
    "    \n",
    "    row_ind = tile_number // 10\n",
    "    col_ind = tile_number % 10\n",
    "    img = img[row_ind * 100 : (row_ind + 1) * 100, col_ind * 100 : (col_ind + 1) * 100]\n",
    "    \n",
    "    print(f\"img shape: {np.asarray(img).shape}\")\n",
    "    \n",
    "#     # Check dead cells?\n",
    "#     img_uint8 = img.astype(np.uint8)\n",
    "#     # Apply Gaussian blur\n",
    "# #     gray_blurred = cv2.GaussianBlur(img_uint8, (9, 9), 0)\n",
    "\n",
    "#     # Apply Hough Circle Transform\n",
    "#     # Adjust the parameters, especially minRadius and maxRadius, to detect small circles\n",
    "#     circles = cv2.HoughCircles(img_uint8, cv2.HOUGH_GRADIENT, 1, 20, param1=50, param2=30, minRadius=0, maxRadius=0)\n",
    "   \n",
    "    \n",
    "    if rescale_tile:\n",
    "        print(\"NOTICE! Rescaling also the tile!!!!!\")\n",
    "        img = rescale_intensity(img)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    plt.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "    \n",
    "#     if circles is not None:\n",
    "#         print(f\"circles count: {len(circles)}\")\n",
    "#         circles = np.uint16(np.around(circles))\n",
    "#         for i in circles[0, :]:\n",
    "#             center = (i[0], i[1])  # circle center\n",
    "#             radius = i[2]  # circle radius\n",
    "#             cv2.circle(image, center, radius, (0, 255, 0), 2)\n",
    "    \n",
    "#     put_tiles_grid(image=img, ax=ax)\n",
    "    plt.axis('off')\n",
    "    plt.title(show_label(site_path), color='purple')\n",
    "    print(get_metrics(img, True))\n",
    "    plt.show()\n",
    "    \n",
    "def crop_frame(original_image):\n",
    "    # Crop the image by removing a 12-pixel frame from each side\n",
    "    cropped_image = original_image[12:1012, 12:1012]  \n",
    "    return cropped_image\n",
    "\n",
    "def crop_site_to_tiles(img):\n",
    "    from skimage.util import view_as_blocks\n",
    "    # Break the cropped image into 64 tiles of size 100x100\n",
    "    tile_size = 100\n",
    "    num_tiles = 64\n",
    "\n",
    "    # Reshape the image into tiles using view_as_blocks from skimage\n",
    "    tiles = view_as_blocks(img, block_shape=(tile_size, tile_size, 3))\n",
    "\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            tile = tiles[i, j]\n",
    "    return \n",
    "\n",
    "def put_tiles_grid(image, ax):\n",
    "    # assumes 1000x1000 image\n",
    "    import matplotlib.patches as patches\n",
    "\n",
    "    # Add dashed grid lines for 64 blocks\n",
    "    num_blocks = 10\n",
    "    block_size = 100\n",
    "\n",
    "    for i in range(1, num_blocks):\n",
    "        # Draw horizontal dashed lines\n",
    "        ax.plot([0, 1000], [i * block_size, i * block_size], linestyle='--', lw=1, alpha=0.5, color='pink')\n",
    "\n",
    "        # Draw vertical dashed lines\n",
    "        ax.plot([i * block_size, i * block_size], [0, 1000], linestyle='--', lw=1, alpha=0.5, color='pink')\n",
    "\n",
    "    # Remove x and y axis labels\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Add a title\n",
    "    plt.title('Image with Dashed Grid of 64 Blocks')\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"/home/labs/hornsteinlab/Collaboration/MOmaps_Sagy/MOmaps/sandbox/outliers_detection/raw_metrics_all_batches_all_metrics_site_fix.csv\")\n",
    "# df = pd.read_csv(\"/home/labs/hornsteinlab/Collaboration/MOmaps_Sagy/MOmaps/sandbox/outliers_detection/raw_metrics_all_batches_brenner_site_dNLS.csv\")\n",
    "# df = pd.read_csv(\"/home/labs/hornsteinlab/Collaboration/MOmaps/sandbox/outliers_detection/brenner_values/raw_metrics_fus_fixed200224_2.csv\")\n",
    "\n",
    "# df = pd.read_csv(\"/home/labs/hornsteinlab/Collaboration/MOmaps/outputs/preprocessing/spd/brenner/raw_metrics250324.csv\")\n",
    "# df = pd.read_csv(\"/home/labs/hornsteinlab/Collaboration/MOmaps/outputs/preprocessing/Opera/brenner/raw_metrics250324.csv\")\n",
    "\n",
    "df = pd.read_csv(\"/home/labs/hornsteinlab/Collaboration/MOmaps/outputs/preprocessing/Opera18Days/brenner/raw_metrics210524.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Marker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mappings = {}\n",
    "counts = df['Marker'].value_counts()\n",
    "all_markers = df['Marker'].unique()\n",
    "print(len(all_markers))\n",
    "print(all_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings_filepath = \"/home/labs/hornsteinlab/Collaboration/MOmaps/manuscript/markers_focus_boundries/markers_focus_boundries_opera18days.csv\"\n",
    "mappings = init_mappings(markers=all_markers, filepath=mappings_filepath)\n",
    "mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# table_data = {\n",
    "#     'CLTC': (1500, 20000),\n",
    "#     'DAPI': (200, 7500),\n",
    "#     'PSD95': (9771, 35041),\n",
    "#     'FMRP': (1500, 10000),\n",
    "#     'Phalloidin': (1702, 16000),\n",
    "#     'SQSTM1': (2870, 17930),\n",
    "#     'CD41': (4962, 20000),\n",
    "#     'NONO': (0, 10000), #None to 0\n",
    "#     'TDP43': (823, 14039),\n",
    "#     'Calreticulin': (2000, 28313),\n",
    "#     'LAMP1': (2171, 11318),\n",
    "#     'ANXA11': (0, 14633),#None to 0\n",
    "#     'SNCA': (3529, 23953),  \n",
    "#     'G3BP1': (0, 9945),#None to 0\n",
    "#     'KIF5A': (2118, 13717),  \n",
    "#     'PURA': (2248, 7703),  \n",
    "#     'FUS': (421, 7748), \n",
    "#     'NCL': (544, 4067),  \n",
    "#     'GM130': (0, 4284),#None to 0\n",
    "#     'TOMM20': (4042, 44385),\n",
    "#     'DCP1A': (0, 14931),  #None to 0\n",
    "#     'NEMO': (15491, 44143),  \n",
    "#     'PEX14': (3353, 20000), \n",
    "#     'PML': (2000, 21338), \n",
    "#     'mitotracker': (5270, 20000) \n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(20,8))\n",
    "# sns.boxplot(x='Marker', y='Target_Sharpness_Brenner', data=df)\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.title('Brenner Values per marker')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Brenner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### SAFE ZONE TO CHANGE ###############\n",
    "\n",
    "marker = 'G3BP1' # MAKRENAME\n",
    "# [marker] Options:\n",
    "# ['CLTC', 'DAPI', 'PSD95', 'FMRP', 'Phalloidin', 'SQSTM1', 'AGO2',\n",
    "#        'CD41', 'TDP43', 'HNRNPA1', 'PSPC1', 'Tubulin', 'Calreticulin',\n",
    "#        'LAMP1', 'ANXA11', 'SNCA', 'G3BP1', 'PURA', 'TOMM20', 'FUS', 'NCL',\n",
    "#        'GM130', 'KIF5A', 'DCP1A', 'NEMO', 'PEX14', 'PML', 'mitotracker',\n",
    "#        'NONO', 'VDAC1']\n",
    "\n",
    "\n",
    "# [per] Options: 0-100\n",
    "per = 6 # percentile threshold \n",
    "\n",
    "# [per] Options: 0-100\n",
    "# *Optional! if you want to view images between per and another threshold\n",
    "per_second_bound = None\n",
    "\n",
    "max_samples = 10 # set max number of images (in threshold) to show\n",
    "\n",
    "# [is_upper_bound] Options:\n",
    "# True: upper bound\n",
    "# False: lower bound\n",
    "is_upper_bound = True \n",
    "\n",
    "show_percentile_plot = False\n",
    "\n",
    "###################### END OF SAFE ZONE ###################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "\n",
    "if per_second_bound is None:\n",
    "    per_second_bound = 100 if is_upper_bound else 0\n",
    "\n",
    "        \n",
    "print(f\"marker = {marker}, per: {per}% (per_second_bound={per_second_bound}%), max_samples = {max_samples}, is upper bound: {is_upper_bound}\")\n",
    "\n",
    "metric_name = 'Target_Sharpness_Brenner'\n",
    "percentiles_to_describe = np.arange(0, 1.01, 0.01)\n",
    "df_marker = df.loc[df['Marker'] == marker]\n",
    "percentiles = df_marker[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "\n",
    "threshold = percentiles[f'{per}%']\n",
    "threshold_second = percentiles[f'{per_second_bound}%']\n",
    "\n",
    "if is_upper_bound:\n",
    "    c = (df_marker[metric_name]>=threshold) & (df_marker[metric_name]<=threshold_second)\n",
    "else:\n",
    "    c = (df_marker[metric_name]<=threshold) & (df_marker[metric_name]>=threshold_second) \n",
    "\n",
    "# threshold\n",
    "df_marker_filtered = df_marker[c]\n",
    "# shuffle\n",
    "df_marker_filtered = df_marker_filtered.sample(frac=1, random_state=1)\n",
    "\n",
    "print(f\"Number of {marker} images in threshold {threshold} ({per}%) (and {threshold_second} ({per_second_bound}%)): {len(df_marker_filtered)}\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "if show_percentile_plot:\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(percentiles.keys().to_numpy()[4:-1], percentiles.values[4:-1])\n",
    "    plt.ylabel('value')\n",
    "    plt.xlabel('percentile')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "show_images(df_marker_filtered, max_samples=max_samples)    \n",
    "\n",
    "save_to_mapping(mappings_filepath, mappings, marker, round(threshold,2), is_upper_bound)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "# percentiles_to_describe=[0,.003,0.005,0.01,0.02,0.03,0.04,0.05,.06,0.07,.08,.09,0.1,.11,.12,.13,.14,.15]\n",
    "percentiles_to_describe=[.16,.17,.18,.19,.20,.28,.29,.3,.31,.32,.33,.49,.5,.51,.60,.61,.62,.63,.64,.65,.66,.67,.68,.69,.70,.71,.72,.73,.75,.76,.77,.78,.79,.80,.81,.85,.86,.87,.88,.89,.90,.91,.92,.93,.94,.95,.955,.96,.965,.97,.975, .98,.985,.99,1]\n",
    "marker = 'NONO'\n",
    "metric_name = 'Target_Sharpness_Brenner'\n",
    "percentiles = df.loc[df['Marker']==marker, metric_name].describe(percentiles=percentiles_to_describe)\n",
    "per = 98\n",
    "\n",
    "# box_plot_percentile = df.loc[df['Marker']==marker, metric_name].describe(percentiles=[.25,.75])\n",
    "# boxplot_upper_bound = box_plot_percentile[\"75%\"] + 1.5 * scipy.stats.iqr(df.loc[df['Marker']==marker, metric_name])\n",
    "# boxplot_lower_bound = box_plot_percentile[\"25%\"] - 1.5 * scipy.stats.iqr(df.loc[df['Marker']==marker, metric_name])\n",
    "\n",
    "# print(f\"boxplot_lower_bound = {boxplot_lower_bound}, boxplot_upper_bound = {boxplot_upper_bound},\")\n",
    "\n",
    "# low_threshold = table_data[marker][0]#percentiles[f'{per}%'] # for cellular debris\n",
    "# high_threshold = table_data[marker][1] #15000#percentiles[f'{per}%'] # for out of focus\n",
    "\n",
    "\n",
    "# low_threshold =percentiles[f'{per}%'] # for cellular debris\n",
    "high_threshold = percentiles[f'{per}%'] # for out of focus\n",
    "\n",
    "# low_threshold = boxplot_lower_bound\n",
    "# high_threshold = 14000.0#2572.455155#23015.740327#boxplot_upper_bound#30000#table_data[marker][1] #15000#percentiles[f'{per}%'] # for out of focus\n",
    "\n",
    "\n",
    "# per = 1\n",
    "# low_threshold = percentiles[f'{per}%'] # for cellular debris\n",
    "# high_threshold = percentiles[f'{per}%']#table_data[marker][1] #15000#percentiles[f'{per}%'] # for out of focus\n",
    "\n",
    "\n",
    "# per = \"From Mapping\"\n",
    "# low_threshold = markers_dict[marker]['lower_bound'] # debris\n",
    "# high_threshold = markers_dict[marker]['upper_bound'] # out of focus\n",
    "\n",
    "max_samples =10\n",
    "\n",
    "# print(marker, metric_name, low_threshold, high_threshold, f'({per}%)')\n",
    "# print()\n",
    "# print(marker, '\\n', percentiles)\n",
    "\n",
    "\n",
    "# c = (df[metric_name]<=low_threshold) #& (df[metric_name]>=percentiles[f'20%'])  \n",
    "c = (df[metric_name]>=high_threshold) #& (df[metric_name]<=percentiles[f'{per+1}%'] ) #& (df[metric_name]<=25000) # & (df[metric_name]<=percentiles[f'{per+1}%'] )\n",
    "\n",
    "# c = (df[metric_name]<=9771) & (df[metric_name]>=low_threshold)  \n",
    "# c = (df[metric_name]>=high_threshold) & (df[metric_name]<=30000 ) #& (df[metric_name]<=25000) # & (df[metric_name]<=percentiles[f'{per+1}%'] )\n",
    "\n",
    "\n",
    "tmp = df[c]\n",
    "# print(tmp.shape)\n",
    "tmp = tmp[(tmp.Marker==marker)]\n",
    "\n",
    "tmp = tmp.sample(frac=1, random_state=1)\n",
    "\n",
    "print(tmp.shape, round(tmp.shape[0] * 100.0/counts[marker], 3), 100-round(tmp.shape[0] * 100.0/counts[marker], 3))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(percentiles.keys().to_numpy()[4:-1], percentiles.values[4:-1])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "show_images(tmp, max_samples=max_samples)    \n",
    "\n",
    "save_to_mapping(mappings, marker, metric_name, low_threshold, high_threshold)\n",
    "\n",
    "print(\"The thresholds map:\")\n",
    "mappings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print top brenners per marker\n",
    "max_samples = 5\n",
    "df_path = \"/home/labs/hornsteinlab/Collaboration/MOmaps/outputs/preprocessing/Opera/brenner/raw_metrics250324.csv\"\n",
    "\n",
    "print(f\"max_samples = {max_samples}\")\n",
    "\n",
    "df = pd.read_csv(df_path)\n",
    "print(df.shape)\n",
    "\n",
    "markers = df['Marker'].unique()\n",
    "print(markers.shape)\n",
    "\n",
    "for marker in markers:\n",
    "    print(marker)\n",
    "    df_marker = df.loc[df['Marker'] == marker]\n",
    "    print(f\"df_marker shape: {df_marker.shape}\")\n",
    "    df_marker.sort_values('Target_Sharpness_Brenner', ascending=False, inplace=True)\n",
    "    df_marker_subset = df_marker.iloc[:max_samples]\n",
    "    show_images(df_marker_subset, max_samples=max_samples)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
