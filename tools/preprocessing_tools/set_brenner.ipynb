{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Params ###############\n",
    "\n",
    "NOVA_HOME = '/home/labs/hornsteinlab/Collaboration/NOVA_GAL/NOVA'\n",
    "preprocessing_path = \"/home/labs/hornsteinlab/Collaboration/FUNOVA/outputs/preprocessing/brenner\"\n",
    "exp = '_exp4'\n",
    "csv_name = f'raw_metrics110225{exp}.csv'\n",
    "mappings_filepath = f\"/home/labs/hornsteinlab/Collaboration/NOVA_GAL/NOVA/manuscript/markers_focus_boundries/markers_focus_boundries_funova{exp}_25.2.25.csv\"\n",
    "imgs_path = '/home/labs/hornsteinlab/Collaboration/FUNOVA/input/images/raw/'\n",
    "\n",
    "metric_name = 'Target_Sharpness_Brenner'\n",
    "img_shape = 1024\n",
    "percentiles_resolution = 0.0001\n",
    "percentile_ranges_for_reports = [0, 0.1, 0.2, 0.3, 0.5, 0.7, 1, 2, 5, 10, 15, 20, 30, 40, 60, 75, 80, 85, 90, 95, 98, 99, 99.5, 99.7, 99.8,99.9,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import concurrent.futures\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "\n",
    "os.environ['NOVA_HOME'] = '/home/projects/hornsteinlab/Collaboration/MOmaps'\n",
    "\n",
    "sys.path.insert(1, os.getenv('NOVA_HOME'))\n",
    "sys.path.insert(1, os.getenv(\"NOVA_HOME\"))\n",
    "print(f\"NOVA_HOME: {os.getenv('NOVA_HOME')}\")\n",
    "\n",
    "from src.preprocessing.preprocessing_utils import get_image_focus_quality \n",
    "from src.preprocessing.preprocessing_utils import rescale_intensity, fit_image_shape\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(tile, as_string=False):\n",
    "    sharpness_brenner = get_image_focus_quality(tile)    \n",
    "    if as_string:\n",
    "        return f\"Brenner: {round(sharpness_brenner, 3)}\"\n",
    "    return sharpness_brenner\n",
    "\n",
    "def show_images(df, max_samples = 10):\n",
    "    for ind, path in enumerate(df.Path.values):\n",
    "        print(ind)\n",
    "        if max_samples is not None and ind >= max_samples:\n",
    "            print(f\"Stopping at {ind}. There are {len(df.Path.values)} images in total\")\n",
    "            break\n",
    "        \n",
    "        # Target\n",
    "        target_path = os.path.join(imgs_path, path)\n",
    "        show_processed_tif(target_path)\n",
    "        # His DAPI\n",
    "        # path_l = target_path.split(\"/\")\n",
    "        # path_l[-2] = 'DAPI'\n",
    "        \n",
    "        # file_name = path_l[-1].split(\"_\")\n",
    "        # dapi_file_name = \"_\".join([file_name[0], 'w1confDAPI', file_name[-1]])\n",
    "        # dapi_file_name = \"/\".join([*path_l[:-1], dapi_file_name])\n",
    "        # print(dapi_file_name)\n",
    "\n",
    "        # show_processed_tif(dapi_file_name)\n",
    "        print('--------------------------------')\n",
    "        \n",
    "def init_mappings(markers=[], filepath=None):\n",
    "    if filepath is not None:     \n",
    "        if os.path.exists(filepath):\n",
    "            mappings = pd.read_csv(filepath, index_col=0)\n",
    "            return mappings\n",
    "        \n",
    "    mappings = pd.DataFrame(columns=['Lower_bound', 'Upper_bound'], index=markers)\n",
    "\n",
    "    return mappings\n",
    "        \n",
    "def save_to_mapping(filepath, mappings, marker, value, is_upper_bound):\n",
    "    col = 'Upper_bound' if is_upper_bound else 'Lower_bound' \n",
    "    mappings.loc[marker, col] = value\n",
    "    \n",
    "    mappings.to_csv(filepath)\n",
    "    print(f\"File saved to {filepath}\")\n",
    "    \n",
    "    \n",
    "def processed_path_to_raw_paths(path):\n",
    "    path_splited = path.split(os.sep)\n",
    "    filename = path_splited[-1]\n",
    "    filename_split = filename.split('_')\n",
    "    rep = filename_split[0]\n",
    "    panel = filename_split[4]\n",
    "    line = filename_split[5]\n",
    "    filename_new = '_'.join(filename_split[1:4])\n",
    "    batch = path_splited[-5]\n",
    "    batch = batch.split('_')[0]\n",
    "    cond = path_splited[-3]\n",
    "    marker = path_splited[-2]\n",
    "    \n",
    "    ret = os.path.join(\"/home/projects/hornsteinlab/Collaboration/MOmaps/input/images/raw/SpinningDisk\", batch, line, panel, cond, rep, marker, f'{filename_new}.tif')\n",
    "    return ret\n",
    "\n",
    "def raw_path_to_processed_path(path):\n",
    "    path_splited = path.split(os.sep)\n",
    "    filename = os.path.splitext(path_splited[-1])[0]\n",
    "    rep = path_splited[-3]\n",
    "    panel = path_splited[-5]\n",
    "    line = path_splited[-6]\n",
    "    batch = path_splited[-7]\n",
    "    batch = f\"{batch}_16bit_no_downsample\"\n",
    "    cond = path_splited[-4]\n",
    "    marker = path_splited[-2]\n",
    "    \n",
    "    ret = os.path.join(\"/home/projects/hornsteinlab/Collaboration/MOmaps/input/images/processed/spd2/SpinningDisk/\", batch, line, cond, marker, f'{rep}_{filename}_{panel}_{line}_processed.npy')\n",
    "    return ret\n",
    "\n",
    "\n",
    "d = '/home/projects/hornsteinlab/Collaboration/MOmaps/input/images/raw/SpinningDisk/'\n",
    "\n",
    "def show_label(path):\n",
    "    path_l = path.split(\"/\")\n",
    "    return path_l[-7:]\n",
    "\n",
    "def process_tif(path):\n",
    "    \"\"\"\n",
    "    Read and process the image.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Processed image.\n",
    "    \"\"\"\n",
    "    # read the image stack\n",
    "    img = cv2.imread(path, cv2.IMREAD_ANYDEPTH)\n",
    "    img = fit_image_shape(img, (img_shape, img_shape))\n",
    "    # rescale pixel intensities\n",
    "    img = rescale_intensity(img)\n",
    "    return img\n",
    "    \n",
    "def show_processed_tif(path):\n",
    "    img = process_tif(path)\n",
    "    print(get_metrics(img, True))\n",
    "    # show the image with grid \n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    put_tiles_grid(image=img, ax=ax)\n",
    "    plt.axis('off')\n",
    "    plt.title(show_label(path), color='purple')\n",
    "    print(f\"Img shape: {img.shape}\")\n",
    "    plt.show()\n",
    "\n",
    "def put_tiles_grid(image, ax):\n",
    "    # assumes 1000x1000 image\n",
    "    import matplotlib.patches as patches\n",
    "\n",
    "    # Add dashed grid lines for 64 blocks\n",
    "    num_blocks = 10\n",
    "    block_size = 100\n",
    "\n",
    "    for i in range(1, num_blocks):\n",
    "        # Draw horizontal dashed lines\n",
    "        ax.plot([0, 1000], [i * block_size, i * block_size], linestyle='--', lw=1, alpha=0.5, color='pink')\n",
    "\n",
    "        # Draw vertical dashed lines\n",
    "        ax.plot([i * block_size, i * block_size], [0, 1000], linestyle='--', lw=1, alpha=0.5, color='pink')\n",
    "\n",
    "    # Remove x and y axis labels\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Add a title\n",
    "    plt.title('Image with Dashed Grid of 64 Blocks')\n",
    "\n",
    "def update_all_mappings(mappings, thresholds, df):\n",
    "    # Iterate over the rows and fill the thresholds\n",
    "    for marker in mappings.index:\n",
    "        if marker in thresholds and thresholds[marker] is not None:\n",
    "            df_marker = df.loc[df['Marker'] == marker]\n",
    "            percentiles = df_marker[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "            mappings.loc[marker, \"Lower_bound\"] = round(percentiles[f'{thresholds[marker][0]}%'], 2)\n",
    "            mappings.loc[marker, \"Upper_bound\"] = round(percentiles[f'{thresholds[marker][1]}%'], 2)\n",
    "    return mappings\n",
    "\n",
    "def create_histogram_report_by_batch(df: pd.DataFrame, all_markers: list) -> None:\n",
    "    \"\"\"\n",
    "    Generate a PDF report with histograms for each marker.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the images data.\n",
    "        all_markers (list): List of unique markers.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"    \n",
    "    with PdfPages('Marker_histogram_by_batch.pdf') as pdf:\n",
    "        for marker in all_markers:\n",
    "            print(marker)\n",
    "            df_marker = df.loc[df['Marker'] == marker]\n",
    "            percentiles = df_marker[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "            create_histogram(\n",
    "                df_marker, percentiles, \n",
    "                low_perc=thresholds[marker][0], \n",
    "                high_perc=thresholds[marker][1], \n",
    "                overlay_group=['Batch'], \n",
    "                x_min=0.1, x_max=99.9\n",
    "            )\n",
    "            plt.title(marker)\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "            \n",
    "def create_histogram(\n",
    "    df_marker: pd.DataFrame, \n",
    "    percentiles: pd.Series, \n",
    "    low_perc: float = 0.5, \n",
    "    high_perc: float = 99.9, \n",
    "    x_min: float = None, \n",
    "    x_max: float = None, \n",
    "    overlay_group: list = None,\n",
    "    plot_base: bool = True,\n",
    "    actual_x_limits: tuple = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create a histogram of the Brenner values of a certain marker.\n",
    "\n",
    "    Parameters:\n",
    "        df_marker (pd.DataFrame): Marker's data.\n",
    "        percentiles (pd.Series): Percentile values for annotations.\n",
    "        low_perc (float): Low percentile threshold for annotations.\n",
    "        high_perc (float): High percentile threshold for annotations.\n",
    "        x_min (float, optional): Minimum x-axis value for the histogram.\n",
    "        x_max (float, optional): Maximum x-axis value for the histogram.\n",
    "        overlay_group (list, optional): Columns to group and overlay histograms.\n",
    "        plot_base (bool): Whether to plot the base histogram.\n",
    "        actual_x_limits (tuple, optional): Tuple specifying actual x_min and x_max values.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    assert low_perc < high_perc, \"'low_perc' must be less than 'high_perc'\"\n",
    "    \n",
    "    # Determine histogram range\n",
    "    if actual_x_limits:\n",
    "        hist_range = actual_x_limits  # Use passed x_min and x_max\n",
    "    else:\n",
    "        hist_range = (percentiles[f'{x_min}%'], percentiles[f'{x_max}%']) if x_min is not None and x_max is not None else None\n",
    "    \n",
    "    # Plot base histogram\n",
    "    if plot_base:\n",
    "        plt.hist(df_marker[metric_name].values, bins=100, range=hist_range, color=plt.cm.tab10(range(1))[0], \n",
    "                 alpha=0.3, label='Brenner scores')\n",
    "    \n",
    "    # Plot overlays\n",
    "    if overlay_group is not None:\n",
    "        grouped_data = df_marker.groupby(overlay_group)\n",
    "        unique_groups = grouped_data.groups.keys()\n",
    "        colors = plt.cm.tab10(range(len(unique_groups)))\n",
    "\n",
    "        for color, group in zip(colors, unique_groups):\n",
    "            group_data = grouped_data.get_group(group)\n",
    "            group_label = ' - '.join(map(str, group)) if isinstance(group, tuple) else group\n",
    "            plt.hist(group_data[metric_name].values, bins=100, range=hist_range, alpha=0.4, label=group_label, color=color)\n",
    "\n",
    "    # Add percentile markers\n",
    "    plt.scatter(percentiles['50%'], 0.5, color='yellow', s=12, label='50th percentile')\n",
    "    plt.scatter(percentiles[f'{high_perc}%'], 0.5, color='orange', s=12, label=f'{high_perc}th percentile')\n",
    "    plt.scatter(percentiles[f'{low_perc}%'], 0.5, color='red', s=12, label=f'{low_perc}th percentile')\n",
    "\n",
    "    # Remove duplicate legend entries\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "def generate_marker_reports(\n",
    "    df: pd.DataFrame, \n",
    "    all_markers: list, \n",
    "    output_folder: str, \n",
    "    percentiles_to_describe: list, \n",
    "    percentile_ranges: list, \n",
    "    max_samples: int\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generate a detailed report for each marker, including histograms and filtered images.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "        all_markers (list): List of unique markers.\n",
    "        output_folder (str): Path to save the output PDFs.\n",
    "        percentiles_to_describe (list): List of percentiles to describe the metric.\n",
    "        percentile_ranges (list): List of percentile ranges for filtering.\n",
    "        max_samples (int): Maximum number of images to display per range.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for marker in all_markers:\n",
    "        print(marker)\n",
    "        df_marker = df.loc[df['Marker'] == marker]\n",
    "        percentiles = df_marker[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "\n",
    "        # Define the actual x-axis limits for consistent base and overlay histograms\n",
    "        actual_x_limits = (percentiles['0%'], percentiles['97%'])\n",
    "\n",
    "        pdf_path = os.path.join(output_folder, f'output_report_{marker}.pdf')\n",
    "        with PdfPages(pdf_path) as pdf:\n",
    "            # Generate histograms with overlays for different groups\n",
    "            groups = ['Condition', 'Batch', 'Rep', 'CellLine']\n",
    "            for group in groups:\n",
    "                create_histogram(\n",
    "                    df_marker,\n",
    "                    percentiles,\n",
    "                    low_perc=0,\n",
    "                    high_perc=97,\n",
    "                    actual_x_limits=actual_x_limits,\n",
    "                    overlay_group=[group]\n",
    "                )\n",
    "                plt.title(f\"Histogram with Overlay by {group}\")\n",
    "                pdf.savefig()  # Save current figure to the PDF\n",
    "                plt.close()\n",
    "\n",
    "            # Combined base histogram and overlay for each cell line\n",
    "            for CL in np.unique(df_marker['CellLine']):\n",
    "                create_histogram(\n",
    "                    df_marker,\n",
    "                    percentiles,\n",
    "                    low_perc=0,\n",
    "                    high_perc=97,\n",
    "                    actual_x_limits=actual_x_limits,\n",
    "                )\n",
    "                \n",
    "                # Filter and overlay the specific cell line\n",
    "                df_tmp = df_marker.loc[df_marker['CellLine'] == CL]\n",
    "                percentiles_tmp = df_tmp[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "                create_histogram(\n",
    "                    df_tmp,\n",
    "                    percentiles,\n",
    "                    low_perc=0,\n",
    "                    high_perc=97,\n",
    "                    actual_x_limits=actual_x_limits,\n",
    "                    overlay_group=['CellLine', 'Condition'], plot_base = False\n",
    "                )\n",
    "                plt.title(f\"Histogram for (Cell Line: {CL})\")\n",
    "                # Save the combined plot to the PDF\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "\n",
    "            # Remaining parts of the function (filtered images, percentile ranges, etc.)\n",
    "            for i in range(len(percentile_ranges) - 1):\n",
    "                per_min = np.round(percentile_ranges[i], 2)\n",
    "                per_max = np.round(percentile_ranges[i + 1], 2)\n",
    "                assert per_min < per_max, \"Percentile range minimum must be less than the maximum.\"\n",
    "                threshold = percentiles[f'{per_min}%']\n",
    "                threshold_second = percentiles[f'{per_max}%']\n",
    "\n",
    "                c = (df_marker[metric_name] >= threshold) & (df_marker[metric_name] <= threshold_second)\n",
    "                df_marker_filtered = df_marker[c].sample(frac=1, random_state=1)\n",
    "\n",
    "                text_output = (f'Images between %{per_min} - {per_max}%\\n'\n",
    "                               f\"Number of {marker} images in threshold {threshold} \"\n",
    "                               f\"({per_min}%) and {threshold_second} ({per_max}%): \"\n",
    "                               f\"{len(df_marker_filtered)}\\n\\n\"\n",
    "                               f\"{df_marker_filtered['CellLine'].value_counts().to_string()}\\n\\n\"\n",
    "                               f\"{df_marker_filtered['Condition'].value_counts().to_string()}\\n\\n\")\n",
    "\n",
    "                fig = plt.figure(figsize=(12, 8))\n",
    "                gs = GridSpec(3, 1, figure=fig, height_ratios=[1, 2, 0.1])\n",
    "                text_ax = fig.add_subplot(gs[0, :])\n",
    "                text_ax.axis('off')\n",
    "                text_ax.text(0.01, 0.99, text_output, ha='left', va='top', fontsize=12, wrap=True)\n",
    "\n",
    "                filtered_paths = df_marker_filtered['Path'].values\n",
    "                num_images = min(max_samples, len(filtered_paths))\n",
    "                img_gs = gs[1].subgridspec(1, num_images, wspace=0.1)\n",
    "\n",
    "                for ind, path in enumerate(filtered_paths[:num_images]):\n",
    "                    target_path = os.path.join(output_folder, path)\n",
    "                    img = process_tif(target_path)\n",
    "\n",
    "                    ax = fig.add_subplot(img_gs[0, ind])\n",
    "                    ax.imshow(img, cmap='gray')\n",
    "                    put_tiles_grid(image=img, ax=ax)\n",
    "                    ax.axis('off')\n",
    "\n",
    "                    labels = show_label(path)\n",
    "                    perc_brenner = abs(percentiles[[per for per in percentiles.keys() if '%' in per]] - get_image_focus_quality(img)).idxmin()\n",
    "                    ax.set_title(f\"{labels[1]}, {labels[3]}, {get_metrics(img, True)}, {perc_brenner}\", color='purple', fontsize=10)\n",
    "\n",
    "                plt.tight_layout()\n",
    "                pdf.savefig(fig)\n",
    "                plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"/home/labs/hornsteinlab/Collaboration/MOmaps_Sagy/MOmaps/sandbox/outliers_detection/raw_metrics_all_batches_all_metrics_site_fix.csv\")\n",
    "# df = pd.read_csv(\"/home/labs/hornsteinlab/Collaboration/MOmaps_Sagy/MOmaps/sandbox/outliers_detection/raw_metrics_all_batches_brenner_site_dNLS.csv\")\n",
    "# df = pd.read_csv(\"/home/labs/hornsteinlab/Collaboration/MOmaps/sandbox/outliers_detection/brenner_values/raw_metrics_fus_fixed200224_2.csv\")\n",
    "\n",
    "# df = pd.read_csv(\"/home/labs/hornsteinlab/Collaboration/MOmaps/outputs/preprocessing/spd/brenner/raw_metrics250324.csv\")\n",
    "# df = pd.read_csv(\"/home/labs/hornsteinlab/Collaboration/MOmaps/outputs/preprocessing/Opera/brenner/raw_metrics250324.csv\")\n",
    "\n",
    "df = pd.read_csv(\"/home/projects/hornsteinlab/Collaboration/MOmaps/outputs/preprocessing/Opera18Days/brenner/raw_metrics210524.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Marker\"] = df[\"Marker\"].str.replace(\"_\", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Path.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Marker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df['Marker'].value_counts()\n",
    "all_markers = df['Marker'].unique()\n",
    "print(len(all_markers))\n",
    "print(all_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings_filepath = \"/home/projects/hornsteinlab/Collaboration/MOmaps/manuscript/markers_focus_boundries/markers_focus_boundries_opera18days.csv\"\n",
    "mappings = init_mappings(markers=all_markers, filepath=mappings_filepath)\n",
    "mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles_to_describe = np.arange(0, 1+percentiles_resolution, percentiles_resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Brenner reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this block if you want to generate Brenner reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = f\"{preprocessing_path}/brenner_reports{exp}_{datetime.now().strftime('%Y-%m-%d')}\"\n",
    "print('output_folder is', output_folder)\n",
    "generate_marker_reports(df, all_markers, output_folder, percentiles_to_describe, percentile_ranges_for_reports, max_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine and set Brenner one by one (Option 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### SAFE ZONE TO CHANGE ###############\n",
    "\n",
    "marker = 'DAPI' # MAKRENAME\n",
    "# [marker] Options:\n",
    "# 'Autophagy' 'DAPI' 'impaired_Autophagosome' 'UPR_ATF4' 'UPR_ATF6'\n",
    "#  'UPR_IRE1a' 'Ubiquitin_levels' 'DNA_damage_P53BP1' 'Neuronal_activity'\n",
    "#  'Necroptosis_HMGB1' 'Necrosis' 'DNA_damage_pH2Ax' 'Parthanatos_early'\n",
    "#  'Cytoskeleton' 'Stress_initiation' 'mature_Autophagosome'\n",
    "#  'Nuclear_speckles_SON' 'TDP-43' 'Nuclear_speckles_SC35'\n",
    "#  'Splicing_factories' 'Aberrant_splicing' 'Parthanatos_late'\n",
    "#  'Protein_degradation' 'Senescence_signaling' 'Apoptosis'\n",
    "#  'Necroptosis_pMLKL'\n",
    "\n",
    "\n",
    "# [per] Options: 0-100\n",
    "per = 98 # percentile threshold \n",
    "\n",
    "# [per] Options: 0-100\n",
    "# *Optional! if you want to view images between per and another threshold\n",
    "per_second_bound = None\n",
    "\n",
    "max_samples = 3 # set max number of images (in threshold) to show\n",
    "\n",
    "# [is_upper_bound] Options:\n",
    "# True: upper bound\n",
    "# False: lower bound\n",
    "is_upper_bound = True \n",
    "\n",
    "show_percentile_plot = False\n",
    "\n",
    "###################### END OF SAFE ZONE ###################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "\n",
    "if per_second_bound is None:\n",
    "    per_second_bound = 100 if is_upper_bound else 0\n",
    "\n",
    "        \n",
    "print(f\"marker = {marker}, per: {per}% (per_second_bound={per_second_bound}%), max_samples = {max_samples}, is upper bound: {is_upper_bound}\")\n",
    "\n",
    "\n",
    "df_marker = df.loc[df['Marker'] == marker]\n",
    "percentiles = df_marker[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "\n",
    "threshold = percentiles[f'{per}%']\n",
    "threshold_second = percentiles[f'{per_second_bound}%']\n",
    "\n",
    "if is_upper_bound:\n",
    "    c = (df_marker[metric_name]>=threshold) & (df_marker[metric_name]<=threshold_second)\n",
    "else:\n",
    "    c = (df_marker[metric_name]<=threshold) & (df_marker[metric_name]>=threshold_second) \n",
    "\n",
    "# threshold\n",
    "df_marker_filtered = df_marker[c]\n",
    "# shuffle\n",
    "df_marker_filtered = df_marker_filtered.sample(frac=1, random_state=1)\n",
    "\n",
    "print(f\"Number of {marker} images in threshold {threshold} ({per}%) (and {threshold_second} ({per_second_bound}%)): {len(df_marker_filtered)}\")\n",
    "print(\"\\n\\n\")\n",
    "print(df_marker_filtered['CellLine'].value_counts().to_string())\n",
    "print(df_marker_filtered['Condition'].value_counts().to_string())\n",
    "\n",
    "if show_percentile_plot:\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(percentiles.keys().to_numpy()[4:-1], percentiles.values[4:-1])\n",
    "    plt.ylabel('value')\n",
    "    plt.xlabel('percentile')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "show_images(df_marker_filtered, max_samples=max_samples)    \n",
    "\n",
    "save_to_mapping(mappings_filepath, mappings, marker, round(threshold,2), is_upper_bound)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Brenners and set the threshold in the next block (option 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Examine Brenners (write the thresholds in the next block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### SAFE ZONE TO CHANGE ###############\n",
    "\n",
    "marker = 'Neuronal-activity' # MAKRENAME\n",
    "# [marker] Options:\n",
    "# ['Autophagy' 'DAPI' 'impaired-Autophagosome' 'UPR-ATF4' 'UPR-ATF6'\n",
    "#  'UPR-IRE1a' 'Ubiquitin-levels' 'DNA-damage-P53BP1' 'Neuronal-activity'\n",
    "#  'Necroptosis-HMGB1' 'Necrosis' 'DNA-damage-pH2Ax' 'Parthanatos-early'\n",
    "#  'Cytoskeleton' 'Stress-initiation' 'mature-Autophagosome'\n",
    "#  'Nuclear-speckles-SON' 'TDP-43' 'Nuclear-speckles-SC35'\n",
    "#  'Splicing-factories' 'Aberrant-splicing' 'Parthanatos-late'\n",
    "#  'Protein-degradation' 'Senescence-signaling' 'Apoptosis'\n",
    "#  'Necroptosis-pMLKL']\n",
    "\n",
    "per_min = 89\n",
    "per_max = 90\n",
    "max_samples = 20\n",
    "\n",
    "###################### END OF SAFE ZONE ###################\n",
    "\n",
    "\n",
    "\n",
    "df_marker = df.loc[df['Marker'] == marker]\n",
    "percentiles = df_marker[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "\n",
    "print(f'Showing images between %{per_min} - {per_max}')\n",
    "threshold = percentiles[f'{per_min}%']\n",
    "threshold_second = percentiles[f'{per_max}%']\n",
    "\n",
    "c = (df_marker[metric_name]>=threshold) & (df_marker[metric_name]<=threshold_second) \n",
    "\n",
    "# threshold\n",
    "df_marker_filtered = df_marker[c]\n",
    "# shuffle\n",
    "df_marker_filtered = df_marker_filtered.sample(frac=1, random_state=1)\n",
    "# df_marker_filtered.index = range(len(df_marker_filtered))\n",
    "\n",
    "print(f\"Number of {marker} images in threshold {threshold} ({per_min}%) (and {threshold_second} ({per_max}%)): {len(df_marker_filtered)}\")\n",
    "print(\"\\n\")\n",
    "print(df_marker_filtered['CellLine'].value_counts().to_string())\n",
    "print(\"\\n\")\n",
    "print(df_marker_filtered['Condition'].value_counts().to_string())\n",
    "print(\"\\n\")\n",
    "show_images(df_marker_filtered, max_samples=max_samples)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Setting Brenners in the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exp3\n",
    "# thresholds = {\n",
    "#     \"Stress-initiation\": (0, 99),\n",
    "#     \"Aberrant-splicing\": (1, 97),\n",
    "#     \"Autophagy\": (5, 97),\n",
    "#     \"DAPI\": (0.2, 95),\n",
    "#     \"Apoptosis\": (0.27, 95),\n",
    "#     \"impaired-Autophagosome\": (5, 99),\n",
    "#     \"Cytoskeleton\": (10, 99.8),\n",
    "#     \"DNA-damage-P53BP1\": (0.3, 90),\n",
    "#     \"DNA-damage-pH2Ax\": (7, 85),\n",
    "#     \"mature-Autophagosome\": (2, 98),\n",
    "#     \"Necrosis\": (4, 95),\n",
    "#     \"Neuronal-activity\": (5, 90),\n",
    "#     \"Nuclear-speckles-SC35\": (0.2, 85),\n",
    "#     \"Nuclear-speckles-SON\": (0.2, 85),\n",
    "#     \"Parthanatos-early\": (0, 85),\n",
    "#     \"Parthanatos-late\": (5, 95),\n",
    "#     \"Protein-degradation\": (5, 92),\n",
    "#     \"Senescence-signaling\": (10, 90),\n",
    "#     \"Splicing-factories\": (0, 95),\n",
    "#     \"TDP-43\": (20, 99.2),\n",
    "#     \"Ubiquitin-levels\": (2, 90),\n",
    "#     \"UPR-ATF4\": (20, 99.7), \n",
    "#     \"UPR-ATF6\": (3, 100),\n",
    "#     \"UPR-IRE1a\": (2, 98),\n",
    "#     \"Necroptosis-pMLKL\": (5, 90),\n",
    "#     \"Necroptosis-HMGB1\": (0.01, 90),\n",
    "# }\n",
    "## Exp 4 \n",
    "thresholds = {\n",
    "    \"Stress-initiation\": (0.3, 98),\n",
    "    \"Aberrant-splicing\": (2, 97),\n",
    "    \"Autophagy\": (0, 98),\n",
    "    \"DAPI\": (0.2, 98.3),\n",
    "    \"Apoptosis\": (0.5, 95),\n",
    "    \"impaired-Autophagosome\": (13, 99.5),\n",
    "    \"Cytoskeleton\": (10, 99.9),\n",
    "    \"DNA-damage-P53BP1\": (0.3, 92),\n",
    "    \"DNA-damage-pH2Ax\": (7, 95),\n",
    "    \"mature-Autophagosome\": (5, 98.85),\n",
    "    \"Necrosis\": (7.2, 98),\n",
    "    \"Neuronal-activity\": (7, 94),\n",
    "    \"Nuclear-speckles-SC35\": (0.1, 92),\n",
    "    \"Nuclear-speckles-SON\": (0.2, 85),\n",
    "    \"Parthanatos-early\": (0, 99),\n",
    "    \"Parthanatos-late\": (5, 99),\n",
    "    \"Protein-degradation\": (2, 98),\n",
    "    \"Senescence-signaling\": (4, 99.75),\n",
    "    \"Splicing-factories\": (0, 95),\n",
    "    \"TDP-43\": (20, 99.8),\n",
    "    \"Ubiquitin-levels\": (0.2, 90),\n",
    "    \"UPR-ATF4\": (20, 99.75),\n",
    "    \"UPR-ATF6\": (3, 100),\n",
    "    \"UPR-IRE1a\": (2, 98),\n",
    "    \"Necroptosis-pMLKL\": (2, 95),\n",
    "    \"Necroptosis-HMGB1\": (0.2, 90),\n",
    "}\n",
    "\n",
    "mappings = update_all_mappings(mappings, thresholds, df)\n",
    "mappings.to_csv(mappings_filepath)\n",
    "mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print top brenners per marker\n",
    "max_samples = 5\n",
    "df_path = \"/home/projects/hornsteinlab/Collaboration/MOmaps/outputs/preprocessing/Opera/brenner/raw_metrics250324.csv\"\n",
    "\n",
    "print(f\"max_samples = {max_samples}\")\n",
    "\n",
    "df = pd.read_csv(df_path)\n",
    "print(df.shape)\n",
    "\n",
    "markers = df['Marker'].unique()\n",
    "print(markers.shape)\n",
    "\n",
    "for marker in markers:\n",
    "    print(marker)\n",
    "    df_marker = df.loc[df['Marker'] == marker]\n",
    "    print(f\"df_marker shape: {df_marker.shape}\")\n",
    "    df_marker.sort_values('Target_Sharpness_Brenner', ascending=False, inplace=True)\n",
    "    df_marker_subset = df_marker.iloc[:max_samples]\n",
    "    show_images(df_marker_subset, max_samples=max_samples)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nova",
   "language": "python",
   "name": "nova"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
