{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Params ###############\n",
    "\n",
    "NOVA_HOME = '/home/labs/hornsteinlab/Collaboration/NOVA_GAL/NOVA'\n",
    "preprocessing_path = \"/home/labs/hornsteinlab/Collaboration/FUNOVA/outputs/preprocessing/brenner\"\n",
    "csv_name = 'raw_metrics260225_exp4_processed.csv'\n",
    "mappings_filepath = \"/home/labs/hornsteinlab/Collaboration/NOVA_GAL/NOVA/manuscript/markers_focus_boundries/markers_focus_boundries_funova_Exp4_tiles.csv\"\n",
    "imgs_path = '/home/labs/hornsteinlab/Collaboration/FUNOVA/input/images/processed/'\n",
    "\n",
    "metric_name = 'Target_Sharpness_Brenner'\n",
    "img_shape = 1024\n",
    "tile_shape = [100, 100]\n",
    "percentiles_resolution = 0.0001\n",
    "percentile_ranges_for_reports = [0, 0.1, 0.2, 0.3, 0.5, 0.7, 1, 2, 5, 10, 15, 20, 30, 40, 60, 75, 80, 85, 90, 95, 98, 99, 99.5, 99.7, 99.8,99.9,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import concurrent.futures\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "os.environ['NOVA_HOME'] = NOVA_HOME\n",
    "sys.path.insert(1, os.getenv(\"NOVA_HOME\"))\n",
    "print(f\"NOVA_HOME: {os.getenv('NOVA_HOME')}\")\n",
    "\n",
    "from src.preprocessing.preprocessing_utils import get_image_focus_quality, crop_image_to_tiles, rescale_intensity, fit_image_shape\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(tile, as_string=False):\n",
    "    sharpness_brenner = get_image_focus_quality(tile)    \n",
    "    if as_string:\n",
    "        return f\"Brenner: {round(sharpness_brenner, 3)}\"\n",
    "    return sharpness_brenner\n",
    "\n",
    "def show_images(df, max_samples = 10, show_tile = False):\n",
    "    for ind, path in enumerate(df.Path.values):\n",
    "        print(ind)\n",
    "        if max_samples is not None and ind >= max_samples:\n",
    "            print(f\"Stopping at {ind}. There are {len(df.Path.values)} images in total\")\n",
    "            break\n",
    "        \n",
    "        # Target\n",
    "        target_path = os.path.join(imgs_path, path)\n",
    "        tile_index = df['Tile'].iloc[ind]\n",
    "        print(ind, tile_index, target_path)\n",
    "#         show_processed_tif(target_path)\n",
    "#         x,y = get_tile_location(tile_index, [img_shape, img_shape], tile_shape)\n",
    "#         plt.gca().add_patch(plt.Rectangle((x, y), tile_shape[0], tile_shape[1], edgecolor='red', linewidth=2, fill=False))\n",
    "#         plt.show()\n",
    "        \n",
    "        if show_tile:\n",
    "            img = np.load(path)\n",
    "            img = img[tile_index]\n",
    "            target_img = img[:, :, 0]\n",
    "            nuc_img = img[:, :, 1]\n",
    "            print(\"SNR:\", compute_snr(img))\n",
    "            print(\"Entropy:\", compute_entropy(img))\n",
    "            labels = show_label(path)\n",
    "            perc_brenner = abs(percentiles[[per for per in percentiles.keys() if '%' in per]] - get_image_focus_quality(target_img)).idxmin()\n",
    "            \n",
    "            fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "            ax[0].set_title(f\"{tile_index}: {labels[1]}, {labels[3]}, {get_metrics(target_img, True)}, {perc_brenner}\", color='purple', fontsize=10)\n",
    "            ax[0].imshow(target_img, cmap='gray', vmin=0, vmax=1)\n",
    "            ax[0].set_axis_off()\n",
    "\n",
    "            ax[1].set_title(f'Nucleus, Brenner: {get_metrics(nuc_img, True)}', fontsize=10)\n",
    "            ax[1].imshow(nuc_img, cmap='gray', vmin=0, vmax=1)\n",
    "            ax[1].set_axis_off()\n",
    "            \n",
    "            plt.show()\n",
    "        # His DAPI\n",
    "        # path_l = target_path.split(\"/\")\n",
    "        # path_l[-2] = 'DAPI'\n",
    "        \n",
    "        # file_name = path_l[-1].split(\"_\")\n",
    "        # dapi_file_name = \"_\".join([file_name[0], 'w1confDAPI', file_name[-1]])\n",
    "        # dapi_file_name = \"/\".join([*path_l[:-1], dapi_file_name])\n",
    "        # print(dapi_file_name)\n",
    "\n",
    "        # show_processed_tif(dapi_file_name)\n",
    "        print('--------------------------------')\n",
    "        \n",
    "def init_mappings(markers=[], filepath=None):\n",
    "    if filepath is not None:     \n",
    "        if os.path.exists(filepath):\n",
    "            mappings = pd.read_csv(filepath, index_col=0)\n",
    "            return mappings\n",
    "        \n",
    "    mappings = pd.DataFrame(columns=['Lower_bound'], index=markers)\n",
    "\n",
    "    return mappings\n",
    "        \n",
    "def save_to_mapping(filepath, mappings, marker, value, is_upper_bound):\n",
    "    col = 'Upper_bound' if is_upper_bound else 'Lower_bound' \n",
    "    mappings.loc[marker, col] = value\n",
    "    \n",
    "    mappings.to_csv(filepath)\n",
    "    print(f\"File saved to {filepath}\")\n",
    "\n",
    "def show_label(path):\n",
    "    path_l = path.split(\"/\")\n",
    "    return path_l[-7:]\n",
    "\n",
    "def process_tif(path):\n",
    "    \"\"\"\n",
    "    Read and process the image.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Processed image.\n",
    "    \"\"\"\n",
    "    # read the image stack\n",
    "    img = cv2.imread(path, cv2.IMREAD_ANYDEPTH)\n",
    "    img = fit_image_shape(img, (img_shape, img_shape))\n",
    "    # rescale pixel intensities\n",
    "    img = rescale_intensity(img)\n",
    "    return img\n",
    "    \n",
    "def show_processed_tif(path):\n",
    "    img = process_tif(path)\n",
    "    print(get_metrics(img, True))\n",
    "    # show the image with grid \n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    put_tiles_grid(image=img, ax=ax)\n",
    "    plt.axis('off')\n",
    "    plt.title(show_label(path), color='purple')\n",
    "    print(f\"Img shape: {img.shape}\")\n",
    "\n",
    "def put_tiles_grid(image, ax):\n",
    "    # assumes 1000x1000 image\n",
    "    import matplotlib.patches as patches\n",
    "\n",
    "    # Add dashed grid lines for 64 blocks\n",
    "    num_blocks = 10\n",
    "    block_size = 100\n",
    "\n",
    "    for i in range(1, num_blocks):\n",
    "        # Draw horizontal dashed lines\n",
    "        ax.plot([0, 1000], [i * block_size, i * block_size], linestyle='--', lw=1, alpha=0.5, color='pink')\n",
    "\n",
    "        # Draw vertical dashed lines\n",
    "        ax.plot([i * block_size, i * block_size], [0, 1000], linestyle='--', lw=1, alpha=0.5, color='pink')\n",
    "\n",
    "    # Remove x and y axis labels\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Add a title\n",
    "    plt.title('Image with Dashed Grid of 64 Blocks')\n",
    "\n",
    "def update_all_mappings(mappings: pd.DataFrame, thresholds: dict) -> pd.DataFrame:\n",
    "    for marker, value in thresholds.items():\n",
    "        if marker in mappings.index:\n",
    "            mappings.loc[marker, \"Lower_bound\"] = value\n",
    "        else:\n",
    "            mappings = mappings.append(pd.DataFrame({\"Lower_bound\": [value]}, index=[marker]))\n",
    "    return mappings\n",
    "\n",
    "def create_histogram_report_by_batch(df: pd.DataFrame, all_markers: list) -> None:\n",
    "    \"\"\"\n",
    "    Generate a PDF report with histograms for each marker.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the images data.\n",
    "        all_markers (list): List of unique markers.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"    \n",
    "    with PdfPages('Marker_histogram_by_batch.pdf') as pdf:\n",
    "        for marker in all_markers:\n",
    "            print(marker)\n",
    "            df_marker = df.loc[df['Marker'] == marker]\n",
    "            percentiles = df_marker[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "            create_histogram(\n",
    "                df_marker, percentiles, \n",
    "                low_perc=thresholds[marker][0], \n",
    "                high_perc=thresholds[marker][1], \n",
    "                overlay_group=['Batch'], \n",
    "                x_min=0.1, x_max=99.9\n",
    "            )\n",
    "            plt.title(marker)\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "            \n",
    "def create_histogram(\n",
    "    df_marker: pd.DataFrame, \n",
    "    percentiles: pd.Series, \n",
    "    low_perc: float = 0.5, \n",
    "    high_perc: float = 99.9, \n",
    "    x_min: float = None, \n",
    "    x_max: float = None, \n",
    "    overlay_group: list = None,\n",
    "    plot_base: bool = True,\n",
    "    actual_x_limits: tuple = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create a histogram of the Brenner values of a certain marker.\n",
    "\n",
    "    Parameters:\n",
    "        df_marker (pd.DataFrame): Marker's data.\n",
    "        percentiles (pd.Series): Percentile values for annotations.\n",
    "        low_perc (float): Low percentile threshold for annotations.\n",
    "        high_perc (float): High percentile threshold for annotations.\n",
    "        x_min (float, optional): Minimum x-axis value for the histogram.\n",
    "        x_max (float, optional): Maximum x-axis value for the histogram.\n",
    "        overlay_group (list, optional): Columns to group and overlay histograms.\n",
    "        plot_base (bool): Whether to plot the base histogram.\n",
    "        actual_x_limits (tuple, optional): Tuple specifying actual x_min and x_max values.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    assert low_perc < high_perc, \"'low_perc' must be less than 'high_perc'\"\n",
    "    \n",
    "    # Determine histogram range\n",
    "    if actual_x_limits:\n",
    "        hist_range = actual_x_limits  # Use passed x_min and x_max\n",
    "    else:\n",
    "        hist_range = (percentiles[f'{x_min}%'], percentiles[f'{x_max}%']) if x_min is not None and x_max is not None else None\n",
    "    \n",
    "    # Plot base histogram\n",
    "    if plot_base:\n",
    "        plt.hist(df_marker[metric_name].values, bins=100, range=hist_range, color=plt.cm.tab10(range(1))[0], \n",
    "                 alpha=0.3, label='Brenner scores')\n",
    "    \n",
    "    # Plot overlays\n",
    "    if overlay_group is not None:\n",
    "        grouped_data = df_marker.groupby(overlay_group)\n",
    "        unique_groups = grouped_data.groups.keys()\n",
    "        colors = plt.cm.tab10(range(len(unique_groups)))\n",
    "\n",
    "        for color, group in zip(colors, unique_groups):\n",
    "            group_data = grouped_data.get_group(group)\n",
    "            group_label = ' - '.join(map(str, group)) if isinstance(group, tuple) else group\n",
    "            plt.hist(group_data[metric_name].values, bins=100, range=hist_range, alpha=0.4, label=group_label, color=color)\n",
    "\n",
    "    # Add percentile markers\n",
    "    plt.scatter(percentiles['50%'], 0.5, color='yellow', s=12, label='50th percentile')\n",
    "    plt.scatter(percentiles[f'{high_perc}%'], 0.5, color='orange', s=12, label=f'{high_perc}th percentile')\n",
    "    plt.scatter(percentiles[f'{low_perc}%'], 0.5, color='red', s=12, label=f'{low_perc}th percentile')\n",
    "\n",
    "    # Remove duplicate legend entries\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "def generate_marker_reports(\n",
    "    df: pd.DataFrame, \n",
    "    all_markers: list, \n",
    "    output_folder: str, \n",
    "    percentiles_to_describe: list, \n",
    "    percentile_ranges: list, \n",
    "    max_samples: int\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generate a detailed report for each marker, including histograms and filtered images.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "        all_markers (list): List of unique markers.\n",
    "        output_folder (str): Path to save the output PDFs.\n",
    "        percentiles_to_describe (list): List of percentiles to describe the metric.\n",
    "        percentile_ranges (list): List of percentile ranges for filtering.\n",
    "        max_samples (int): Maximum number of images to display per range.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for marker in all_markers:\n",
    "        print(marker)\n",
    "        df_marker = df.loc[df['Marker'] == marker]\n",
    "        percentiles = df_marker[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "\n",
    "        # Define the actual x-axis limits for consistent base and overlay histograms\n",
    "        actual_x_limits = (percentiles['0%'], percentiles['97%'])\n",
    "\n",
    "        pdf_path = os.path.join(output_folder, f'output_report_{marker}.pdf')\n",
    "        with PdfPages(pdf_path) as pdf:\n",
    "            # Generate histograms with overlays for different groups\n",
    "            groups = ['Condition', 'Batch', 'Rep', 'CellLine']\n",
    "            for group in groups:\n",
    "                create_histogram(\n",
    "                    df_marker,\n",
    "                    percentiles,\n",
    "                    low_perc=0,\n",
    "                    high_perc=97,\n",
    "                    actual_x_limits=actual_x_limits,\n",
    "                    overlay_group=[group]\n",
    "                )\n",
    "                plt.title(f\"Histogram with Overlay by {group}\")\n",
    "                pdf.savefig()  # Save current figure to the PDF\n",
    "                plt.close()\n",
    "\n",
    "            # Combined base histogram and overlay for each cell line\n",
    "            for CL in np.unique(df_marker['CellLine']):\n",
    "                create_histogram(\n",
    "                    df_marker,\n",
    "                    percentiles,\n",
    "                    low_perc=0,\n",
    "                    high_perc=97,\n",
    "                    actual_x_limits=actual_x_limits,\n",
    "                )\n",
    "                \n",
    "                # Filter and overlay the specific cell line\n",
    "                df_tmp = df_marker.loc[df_marker['CellLine'] == CL]\n",
    "                percentiles_tmp = df_tmp[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "                create_histogram(\n",
    "                    df_tmp,\n",
    "                    percentiles,\n",
    "                    low_perc=0,\n",
    "                    high_perc=97,\n",
    "                    actual_x_limits=actual_x_limits,\n",
    "                    overlay_group=['CellLine', 'Condition'], plot_base = False\n",
    "                )\n",
    "                plt.title(f\"Histogram for (Cell Line: {CL})\")\n",
    "                # Save the combined plot to the PDF\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "\n",
    "            # Remaining parts of the function (filtered images, percentile ranges, etc.)\n",
    "            for i in range(len(percentile_ranges) - 1):\n",
    "                per_min = np.round(percentile_ranges[i], 2)\n",
    "                per_max = np.round(percentile_ranges[i + 1], 2)\n",
    "                assert per_min < per_max, \"Percentile range minimum must be less than the maximum.\"\n",
    "                threshold = percentiles[f'{per_min}%']\n",
    "                threshold_second = percentiles[f'{per_max}%']\n",
    "\n",
    "                c = (df_marker[metric_name] >= threshold) & (df_marker[metric_name] <= threshold_second)\n",
    "                df_marker_filtered = df_marker[c].sample(frac=1, random_state=1)\n",
    "\n",
    "                text_output = (f'Images between %{per_min} - {per_max}%\\n'\n",
    "                               f\"Number of {marker} images in threshold {threshold} \"\n",
    "                               f\"({per_min}%) and {threshold_second} ({per_max}%): \"\n",
    "                               f\"{len(df_marker_filtered)}\\n\\n\"\n",
    "                               f\"{df_marker_filtered['CellLine'].value_counts().to_string()}\\n\\n\"\n",
    "                               f\"{df_marker_filtered['Condition'].value_counts().to_string()}\\n\\n\")\n",
    "\n",
    "                fig = plt.figure(figsize=(12, 8))\n",
    "                gs = GridSpec(3, 1, figure=fig, height_ratios=[1, 2, 0.1])\n",
    "                text_ax = fig.add_subplot(gs[0, :])\n",
    "                text_ax.axis('off')\n",
    "                text_ax.text(0.01, 0.99, text_output, ha='left', va='top', fontsize=12, wrap=True)\n",
    "\n",
    "                filtered_paths = df_marker_filtered['Path'].values\n",
    "                num_images = min(max_samples, len(filtered_paths))\n",
    "                img_gs = gs[1].subgridspec(1, num_images, wspace=0.1)\n",
    "\n",
    "                for ind, path in enumerate(filtered_paths[:num_images]):\n",
    "                    target_path = os.path.join(output_folder, path)\n",
    "                    print(target_path)\n",
    "                    img = process_tif(target_path)\n",
    "                    tiles = crop_image_to_tiles(img, [100, 100])\n",
    "                    img = tiles[df_marker_filtered['Tile'].iloc[ind]]\n",
    "#                     print(df_marker_filtered['original_Path'].iloc[ind], df_marker_filtered['Tile'].iloc[ind],\n",
    "#                          df_marker_filtered['Path'].iloc[ind])\n",
    "\n",
    "                    ax = fig.add_subplot(img_gs[0, ind])\n",
    "                    ax.imshow(img, cmap='gray')\n",
    "#                     put_tiles_grid(image=img, ax=ax)\n",
    "                    ax.axis('off')\n",
    "\n",
    "                    labels = show_label(path)\n",
    "                    perc_brenner = abs(percentiles[[per for per in percentiles.keys() if '%' in per]] - get_image_focus_quality(img)).idxmin()\n",
    "                    ax.set_title(f\"{labels[1]}, {labels[3]}, {get_metrics(img, True)}, {perc_brenner}\", color='purple', fontsize=10)\n",
    "\n",
    "                plt.tight_layout()\n",
    "                pdf.savefig(fig)\n",
    "                plt.close(fig)\n",
    "def get_tile_location(tile_index: int, img_shape, tile_shape):\n",
    "    \"\"\"\n",
    "    Compute the top-left corner (x, y) location of a tile in the original image.\n",
    "\n",
    "    Args:\n",
    "        tile_index (int): Index of the tile in the flattened tiles array.\n",
    "        img_shape (Tuple[int, int]): Shape of the original image (width, height).\n",
    "        tile_shape (Tuple[int, int]): Shape of a tile (tile_width, tile_height).\n",
    "\n",
    "    Returns:\n",
    "        Tuple[int, int]: (x, y) coordinates of the tile's top-left corner in the image.\n",
    "    \"\"\"\n",
    "    img_height, img_width = img_shape  \n",
    "    tile_height, tile_width = tile_shape\n",
    "\n",
    "    n_cols = img_width // tile_width  # Number of tiles per row\n",
    "    row = tile_index // n_cols  # Get row index\n",
    "    col = tile_index % n_cols  # Get column index\n",
    "\n",
    "    x = col * tile_width  # X position (left)\n",
    "    y = row * tile_height  # Y position (top)\n",
    "    \n",
    "    return (x, y)\n",
    "def compute_snr(image: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute the Signal-to-Noise Ratio (SNR) of an image.\n",
    "    \n",
    "    Args:\n",
    "        image (np.ndarray): Input grayscale or single-channel image.\n",
    "    \n",
    "    Returns:\n",
    "        float: SNR value.\n",
    "    \"\"\"\n",
    "    signal = np.mean(image)\n",
    "    noise = np.std(image)\n",
    "    return 20 * np.log10(signal / noise) if noise > 0 else float(\"inf\")\n",
    "from skimage.measure import shannon_entropy  \n",
    "\n",
    "def compute_entropy(image: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute the entropy of an image.\n",
    "    \n",
    "    Args:\n",
    "        image (np.ndarray): Input grayscale or single-channel image.\n",
    "    \n",
    "    Returns:\n",
    "        float: Shannon entropy of the image.\n",
    "    \"\"\"\n",
    "    return shannon_entropy(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(preprocessing_path, csv_name))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Path.iloc[1], df.Path.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Tile\"] = df[\"Path\"].apply(lambda x: int(x.rsplit(\"_\", 1)[-1]))\n",
    "# df[\"original_Path\"] = df[\"Path\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Path\"] = df[\"Path\"].apply(lambda x: x.rsplit(\"_\", 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Marker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df['Marker'].value_counts()\n",
    "all_markers = df['Marker'].unique()\n",
    "print(len(all_markers))\n",
    "print(all_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = init_mappings(markers=all_markers, filepath=mappings_filepath)\n",
    "mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles_to_describe = np.arange(0, 1+percentiles_resolution, percentiles_resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Brenner reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this block if you want to generate Brenner reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = f\"{preprocessing_path}/brenner_reports_Exp4_{datetime.now().strftime('%Y-%m-%d')}\"\n",
    "print('output_folder is', output_folder)\n",
    "generate_marker_reports(df, ['Nuclear-speckles-SON'], output_folder, percentiles_to_describe, percentile_ranges_for_reports, max_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine and set Brenner one by one (Option 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### SAFE ZONE TO CHANGE ###############\n",
    "\n",
    "marker = 'DAPI' # MAKRENAME\n",
    "# [marker] Options:\n",
    "# 'Autophagy' 'DAPI' 'impaired_Autophagosome' 'UPR_ATF4' 'UPR_ATF6'\n",
    "#  'UPR_IRE1a' 'Ubiquitin_levels' 'DNA_damage_P53BP1' 'Neuronal_activity'\n",
    "#  'Necroptosis_HMGB1' 'Necrosis' 'DNA_damage_pH2Ax' 'Parthanatos_early'\n",
    "#  'Cytoskeleton' 'Stress_initiation' 'mature_Autophagosome'\n",
    "#  'Nuclear_speckles_SON' 'TDP-43' 'Nuclear_speckles_SC35'\n",
    "#  'Splicing_factories' 'Aberrant_splicing' 'Parthanatos_late'\n",
    "#  'Protein_degradation' 'Senescence_signaling' 'Apoptosis'\n",
    "#  'Necroptosis_pMLKL'\n",
    "\n",
    "\n",
    "# [per] Options: 0-100\n",
    "per = 98 # percentile threshold \n",
    "\n",
    "# [per] Options: 0-100\n",
    "# *Optional! if you want to view images between per and another threshold\n",
    "per_second_bound = None\n",
    "\n",
    "max_samples = 3 # set max number of images (in threshold) to show\n",
    "\n",
    "# [is_upper_bound] Options:\n",
    "# True: upper bound\n",
    "# False: lower bound\n",
    "is_upper_bound = True \n",
    "\n",
    "show_percentile_plot = False\n",
    "\n",
    "###################### END OF SAFE ZONE ###################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "\n",
    "if per_second_bound is None:\n",
    "    per_second_bound = 100 if is_upper_bound else 0\n",
    "\n",
    "        \n",
    "print(f\"marker = {marker}, per: {per}% (per_second_bound={per_second_bound}%), max_samples = {max_samples}, is upper bound: {is_upper_bound}\")\n",
    "\n",
    "\n",
    "df_marker = df.loc[df['Marker'] == marker]\n",
    "percentiles = df_marker[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "\n",
    "threshold = percentiles[f'{per}%']\n",
    "threshold_second = percentiles[f'{per_second_bound}%']\n",
    "\n",
    "if is_upper_bound:\n",
    "    c = (df_marker[metric_name]>=threshold) & (df_marker[metric_name]<=threshold_second)\n",
    "else:\n",
    "    c = (df_marker[metric_name]<=threshold) & (df_marker[metric_name]>=threshold_second) \n",
    "\n",
    "# threshold\n",
    "df_marker_filtered = df_marker[c]\n",
    "# shuffle\n",
    "df_marker_filtered = df_marker_filtered.sample(frac=1, random_state=1)\n",
    "\n",
    "print(f\"Number of {marker} images in threshold {threshold} ({per}%) (and {threshold_second} ({per_second_bound}%)): {len(df_marker_filtered)}\")\n",
    "print(\"\\n\\n\")\n",
    "print(df_marker_filtered['CellLine'].value_counts().to_string())\n",
    "print(df_marker_filtered['Condition'].value_counts().to_string())\n",
    "\n",
    "if show_percentile_plot:\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(percentiles.keys().to_numpy()[4:-1], percentiles.values[4:-1])\n",
    "    plt.ylabel('value')\n",
    "    plt.xlabel('percentile')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "show_images(df_marker_filtered, max_samples=max_samples)    \n",
    "\n",
    "save_to_mapping(mappings_filepath, mappings, marker, round(threshold,2), is_upper_bound)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Brenners and set the threshold in the next block (option 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Examine Brenners (write the thresholds in the next block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### SAFE ZONE TO CHANGE ###############\n",
    "\n",
    "marker = 'impaired-Autophagosome' # MAKRENAME\n",
    "# [marker] Options:\n",
    "# 'Aberrant-splicing' 'Apoptosis' 'Autophagy' 'Cytoskeleton' 'DAPI'\n",
    "#  'DNA-damage-P53BP1' 'DNA-damage-pH2Ax' 'Necroptosis-HMGB1'\n",
    "#  'Necroptosis-pMLKL' 'Necrosis' 'Neuronal-activity'\n",
    "#  'Nuclear-speckles-SC35' 'Nuclear-speckles-SON' 'Parthanatos-early'\n",
    "#  'Parthanatos-late' 'Protein-degradation' 'Senescence-signaling'\n",
    "#  'Splicing-factories' 'Stress-initiation' 'TDP-43' 'UPR-ATF4' 'UPR-ATF6'\n",
    "#  'UPR-IRE1a' 'Ubiquitin-levels' 'impaired-Autophagosome'\n",
    "#  'mature-Autophagosome'\n",
    "\n",
    "per_min = 10\n",
    "per_max = 12\n",
    "max_samples = 20\n",
    "\n",
    "###################### END OF SAFE ZONE ###################\n",
    "\n",
    "\n",
    "\n",
    "df_marker = df.loc[df['Marker'] == marker]\n",
    "percentiles = df_marker[metric_name].describe(percentiles=percentiles_to_describe)\n",
    "\n",
    "print(f'Showing images between %{per_min} - {per_max}')\n",
    "threshold = percentiles[f'{per_min}%']\n",
    "threshold_second = percentiles[f'{per_max}%']\n",
    "\n",
    "c = (df_marker[metric_name]>=threshold) & (df_marker[metric_name]<=threshold_second) \n",
    "\n",
    "# threshold\n",
    "df_marker_filtered = df_marker[c]\n",
    "# shuffle\n",
    "df_marker_filtered = df_marker_filtered.sample(frac=1, random_state=1)\n",
    "# df_marker_filtered.index = range(len(df_marker_filtered))\n",
    "\n",
    "print(f\"Number of {marker} images in threshold {threshold} ({per_min}%) (and {threshold_second} ({per_max}%)): {len(df_marker_filtered)}\")\n",
    "print(\"\\n\")\n",
    "print(df_marker_filtered['CellLine'].value_counts().to_string())\n",
    "print(\"\\n\")\n",
    "print(df_marker_filtered['Condition'].value_counts().to_string())\n",
    "print(\"\\n\")\n",
    "show_images(df_marker_filtered, max_samples=max_samples, show_tile = True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Setting Brenners in the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exp3\n",
    "# thresholds = {\n",
    "#     \"Nuclear-speckles-SON\": (1.8),\n",
    "#     \"DAPI\": (1.6),\n",
    "#     \"Stress-initiation\": (1.4),\n",
    "#     \"Aberrant-splicing\": (2),\n",
    "#     \"mature-Autophagosome\": (0),\n",
    "#     \"Cytoskeleton\": (2.6),\n",
    "#     \"Ubiquitin-levels\": (1),\n",
    "#     \"UPR-ATF4\": (3), \n",
    "#     \"UPR-ATF6\": (1.2),\n",
    "#     \"impaired-Autophagosome\": (1.8),\n",
    "#     \"Autophagy\": (0),\n",
    "#     \"TDP-43\": (1),\n",
    "#     \"Parthanatos-late\": (0),\n",
    "#     \"Nuclear-speckles-SC35\": (0.5),\n",
    "#     \"Splicing-factories\": (1.3),\n",
    "#     \"DNA-damage-pH2Ax\": (0),\n",
    "#     \"UPR-IRE1a\": (5),\n",
    "#     \"Parthanatos-early\": (4),\n",
    "#     \"Necrosis\": (1.7),\n",
    "#     \"Necroptosis-HMGB1\": (7),\n",
    "#     \"DNA-damage-P53BP1\": (2.2),\n",
    "#     \"Apoptosis\": (0),\n",
    "#     \"Necroptosis-pMLKL\": (0),\n",
    "#     \"Protein-degradation\": (0),\n",
    "#     \"Senescence-signaling\": (0),\n",
    "#     \"Neuronal-activity\": (2.4),\n",
    "# }\n",
    "## Exp 4 \n",
    "thresholds = {\n",
    "    \"Nuclear-speckles-SON\": (1.8),\n",
    "    \"DAPI\": (1.6),\n",
    "    \"Stress-initiation\": (1.7),\n",
    "    \"Aberrant-splicing\": (2),\n",
    "    \"mature-Autophagosome\": (0),\n",
    "    \"Cytoskeleton\": (2.6),\n",
    "    \"Ubiquitin-levels\": (1),\n",
    "    \"UPR-ATF4\": (3), \n",
    "    \"UPR-ATF6\": (1.2),\n",
    "    \"impaired-Autophagosome\": (1.8),\n",
    "    \"Autophagy\": (0),\n",
    "    \"TDP-43\": (0.8),\n",
    "    \"Parthanatos-late\": (0),\n",
    "    \"Nuclear-speckles-SC35\": (0.6),\n",
    "    \"Splicing-factories\": (1),\n",
    "    \"DNA-damage-pH2Ax\": (0),\n",
    "    \"UPR-IRE1a\": (0.9),\n",
    "    \"Parthanatos-early\": (4),\n",
    "    \"Necrosis\": (2.2),\n",
    "    \"Necroptosis-HMGB1\": (7),\n",
    "    \"DNA-damage-P53BP1\": (2.2),\n",
    "    \"Apoptosis\": (0),\n",
    "    \"Necroptosis-pMLKL\": (1.2),\n",
    "    \"Protein-degradation\": (2.2),\n",
    "    \"Senescence-signaling\": (0),\n",
    "    \"Neuronal-activity\": (1.2),\n",
    "}\n",
    "\n",
    "mappings = update_all_mappings(mappings, thresholds)\n",
    "mappings.to_csv(mappings_filepath)\n",
    "mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nova",
   "language": "python",
   "name": "nova"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
