{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362e3dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import os\n",
    "import skimage.exposure\n",
    "from skimage import transform\n",
    "from skimage.measure import shannon_entropy\n",
    "import random\n",
    "import re\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42724ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_FOLDER='/home/labs/hornsteinlab/Collaboration/MOmaps/input/images/raw/Opera18Days_sorted/batch1/WT/panelE/Untreated/rep1/DCP1A/'#'/Users/nancy/PycharmProjects/MOmaps/example_raw_images'\n",
    "\n",
    "\n",
    "BASE_DIR = os.path.join('/home','labs','hornsteinlab','Collaboration','MOmaps')\n",
    "DATA_FOLDER = os.path.join(BASE_DIR,'input','images','raw','SpinningDisk', 'NOVA_d18_neurons_sorted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe66046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break to 64 tiles of 128x128, resize to 100x100\n",
    "def break_to_tiles(image, tile_size=128):\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    height, width = image.shape\n",
    "\n",
    "    # Calculate the number of rows and columns for the tiles\n",
    "    num_rows = height // tile_size\n",
    "    num_cols = width // tile_size\n",
    "    print(f\"shannon_entropy all {shannon_entropy(image)}\")\n",
    "    # Iterate through the rows and columns to display each tile\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            \n",
    "            fig, axs = plt.subplots(figsize=(2,2))\n",
    "            \n",
    "            # Define the coordinates for the current tile\n",
    "            x1 = col * tile_size\n",
    "            x2 = (col + 1) * tile_size\n",
    "            y1 = row * tile_size\n",
    "            y2 = (row + 1) * tile_size\n",
    "            # Extract the current tile\n",
    "            tile = image[y1:y2, x1:x2]\n",
    "            \n",
    "            # Resize the 128x128 tile to 100x100\n",
    "            #tile_resized = transform.resize(tile, (100, 100), anti_aliasing=True, preserve_range=True)\n",
    "            #tile_resized = cv2.resize(tile, (100, 100), interpolation=cv2.INTER_LINEAR)\n",
    "            #tile_resized = tile[:100, :100]\n",
    "\n",
    "            \n",
    "            # Display the tile using Matplotlib\n",
    "            plt.imshow(tile, cmap='gray', vmin=0, vmax=1)\n",
    "            plt.axis('off')\n",
    "            #plt.title(f'Tile ({row}, {col}) shannon_entropy tile {shannon_entropy(tile)} {shannon_entropy(tile_resized)} {tile.std()} {tile_resized.std()}')\n",
    "            plt.title(f'Tile ({row}, {col}) shannon_entropy tile {shannon_entropy(tile)} {tile.std()}')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e8b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_piecewise(img_current_channel, to_show):\n",
    "    \"\"\"Normalize image by the dynamic scale giving emphasie to the signal area \"\"\"\n",
    "    try: \n",
    "        Piecewise_norm = Piecewise_normalization()  #static class - so no need to create instance\n",
    "        Piecewise_norm.create_peicewise_lut()\n",
    "                    \n",
    "        img_current_channel = Piecewise_norm.map(ipnut_image = img_current_channel, show = to_show)\n",
    "    \n",
    "        return img_current_channel\n",
    "    except Exception as ex:\n",
    "            raise f\"Can't convert in normalize_piecewise\" \n",
    "\n",
    "\n",
    "class Piecewise_normalization(object): #static class\n",
    "    \n",
    "    lut = None\n",
    "    index = None\n",
    "    \n",
    "    def create_peicewise_lut(self):\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            if not(self.lut is None):\n",
    "                return #lut already exist\n",
    "            \n",
    "            #reaching here - this is 1st time i.e. sigelton\n",
    "            \n",
    "            max_uint16 = np.iinfo(np.uint16).max + 1\n",
    "            max_uint8 = np.iinfo(np.uint8).max + 1\n",
    "            \n",
    "            input_regions_zones = [0,401,4001,8001, max_uint16]\n",
    "            output_regions_zones = [0,220, max_uint8, max_uint8]\n",
    "            contrasts = [1.00,1.00]  #[1,1]\n",
    "            range = input_regions_zones[2] - input_regions_zones[1]\n",
    "            range2 = output_regions_zones[1] - output_regions_zones[0]\n",
    "            \n",
    "            shrinkage_factor = np.zeros(2)\n",
    "            shrinkage_factor[0] = range/range2\n",
    "            \n",
    "            range = input_regions_zones[3] - input_regions_zones[2]\n",
    "            range2 = output_regions_zones[2] - output_regions_zones[1]\n",
    "            \n",
    "            shrinkage_factor[1] = range/range2\n",
    "            \n",
    "            \n",
    "            region_start = np.zeros(input_regions_zones[1], dtype = np.uint32)\n",
    "            region_end = np.ones(input_regions_zones[4]-input_regions_zones[3], dtype = np.uint32) * 255\n",
    "            region1 = np.zeros(input_regions_zones[2]-input_regions_zones[1], dtype = np.uint32)\n",
    "            region2 = np.zeros(input_regions_zones[3]-input_regions_zones[2], dtype = np.uint32)\n",
    "            \n",
    "            #print('region1')\n",
    "            #print('i,input,output')\n",
    "            for i in np.arange(input_regions_zones[1],input_regions_zones[2],1):\n",
    "                x = i-input_regions_zones[1]\n",
    "                region1[x] = np.round(contrasts[0] *(x/ shrinkage_factor[0]) + output_regions_zones[0])\n",
    "                #print(x, i, region1[x])\n",
    "            \n",
    "            #print('region2')\n",
    "            #print('i,input,output')\n",
    "            for i in np.arange(input_regions_zones[2],input_regions_zones[3],1):\n",
    "                x = i-input_regions_zones[2]\n",
    "                region2[x] = np.round(contrasts[1] *(x/ shrinkage_factor[1]) + output_regions_zones[1])\n",
    "                #print(x, i, region2[x])\n",
    "        \n",
    "            self.lut = np.concatenate((region_start, region1, region2, region_end), axis=None) \n",
    "            \n",
    "            # Ensure table is 16-bit\n",
    "            self.lut = self.lut.astype(np.uint16)\n",
    "            self.index = np.arange(start = input_regions_zones[0], stop = input_regions_zones[-1])\n",
    "        except Exception as ex:\n",
    "            print('bad create_peicewise_lut')\n",
    "    \n",
    "    def map(self,ipnut_image, show):\n",
    "        try:\n",
    "            # Now just index into this with the intensities to get the output\n",
    "            transformed_image =  self.lut[ipnut_image].astype('uint8')\n",
    "            transformed_npy = transformed_image.astype('float')/(256.0)\n",
    "            \n",
    "            return transformed_npy\n",
    "        \n",
    "        except Exception as ex:\n",
    "            print('bad LUT in map', ex)\n",
    "            \n",
    "    \n",
    "    def show_mapping(self, path2save):\n",
    "        \n",
    "        plt.plot(self.lut[0:10000])\n",
    "        plt.xlabel('16b')\n",
    "        plt.ylabel('8b')\n",
    "        plt.savefig(path2save+'LUT.png') \n",
    "        plt.close(\"all\")\n",
    "        \n",
    "        #np.save(path2save+'LUT.csv', self.lut)\n",
    "        np.savetxt(path2save+'LUT.csv', np.c_[self.index, self.lut] , delimiter=',')\n",
    "    \n",
    "def plots(ax, i, img_scaled, nucleus_scaled, title):\n",
    "\n",
    "    print(f\"\\n{title} min: {img_scaled.min().round(2)}, max: {img_scaled.max().round(2)},\\nmean: {img_scaled.mean().round(2)}, std: {img_scaled.std().round(2)}\")\n",
    "\n",
    "    # Plot scaled image\n",
    "    ax[i,0].imshow(img_scaled, cmap='gray')\n",
    "    ax[i,0].set_title(title, color='red')\n",
    "    ax[i,1].imshow(nucleus_scaled, cmap='gray')\n",
    "    ax[i,1].set_title('Nucleus', color='red')\n",
    "    #fig.text(0.7, 0.3, \n",
    "    #             f\"min: {img_scaled.min().round(2)}, max: {img_scaled.max().round(2)},\\nmean: {img_scaled.mean().round(2)}, std: {img_scaled.std().round(2)}\", \n",
    "    #             fontsize = 16)\n",
    "    ax[i,0].set_xticks([])\n",
    "    ax[i,0].set_yticks([])\n",
    "\n",
    "    # Plot scaled pixel histogram\n",
    "    ax[i,2].hist(img_scaled.ravel(), bins=10, color='black', fc='k', ec='k')\n",
    "    ax[i,2].set_title(title + ' pixel histogram', color='red')\n",
    "    return ax\n",
    "    \n",
    "    \n",
    "def collect_files_from_subfolders(root_path, folder_name, cell_lines=None, conditions=None):\n",
    "    collected_files = []\n",
    "\n",
    "    def contains_any_substring(main_string, substrings):\n",
    "        return any(substring in main_string for substring in substrings)\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        valid = True\n",
    "        valid &= True if (cell_lines is None or len(cell_lines) == 0) else contains_any_substring(dirpath, cell_lines)\n",
    "        valid &= True if conditions is None or len(conditions) == 0 else contains_any_substring(dirpath, conditions)\n",
    "        \n",
    "        if valid and os.path.basename(dirpath) == folder_name:\n",
    "            for filename in filenames:\n",
    "                collected_files.append(os.path.join(dirpath, filename))\n",
    "    \n",
    "    return collected_files\n",
    "\n",
    "def get_markers(root_path):\n",
    "    markers = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        if len(filenames) > 0 and os.path.splitext(filenames[0])[1] == '.tiff':\n",
    "            markers.append(os.path.basename(dirpath))\n",
    "    return np.unique(markers)\n",
    "            \n",
    "\n",
    "def sample_files(root_path, folder_name, cell_lines=None, conditions=None, n=10):\n",
    "    all_files = collect_files_from_subfolders(root_path, folder_name, cell_lines=cell_lines, conditions=conditions)\n",
    "    \n",
    "    if len(all_files) < n:\n",
    "        raise ValueError(f\"Not enough files to sample from. Found {len(all_files)} files.\")\n",
    "    \n",
    "    sampled_files = random.sample(all_files, n)\n",
    "    return sampled_files\n",
    "\n",
    "def plot_target_and_dapi_rescaled(indx, img, dapi, mn, mx):\n",
    "    vmin, vmax = np.percentile(img, q=(mn, mx))\n",
    "\n",
    "    img_scaled = skimage.exposure.rescale_intensity(\n",
    "        img,\n",
    "        in_range=(vmin, vmax),\n",
    "        out_range=np.float32\n",
    "    )\n",
    "\n",
    "    vmin, vmax = np.percentile(dapi, q=(mn, mx))\n",
    "\n",
    "    img_scaled_dapi = skimage.exposure.rescale_intensity(\n",
    "        dapi,\n",
    "        in_range=(vmin, vmax),\n",
    "        out_range=np.float32\n",
    "    )\n",
    "\n",
    "    plots(ax, indx, img_scaled,img_scaled_dapi, title=f'{mn},{mx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66555fa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "######## SAFE ZONE TO CHANGE ############\n",
    "\n",
    "number_of_images_per_marker = 10\n",
    "ranges = zip([0.5,  0.5,  0.5,  0.5,  0.1,   0.1,    0.1,    1,    2],\n",
    "                         [99.9, 99.0, 98.5, 98.0, 99.9, 99.0,    98.0,  99.9, 99.9])\n",
    "markers = ['G3BP1']\n",
    "# markers = ['AGO2', 'ANXA11', 'CD41', 'CLTC', 'Calreticulin', 'DAPI', 'DCP1A', 'FMRP', 'FUS',\n",
    "#            'G3BP1', 'GM130', 'HNRNPA1', 'KIF5A', 'LAMP1', 'NCL', 'NEMO', 'NONO', 'PEX14',\n",
    "#            'PML', 'PSD95', 'PSPC1', 'PURA', 'Phalloidin', 'SNCA', 'SQSTM1', 'TDP43',\n",
    "#            'TOMM20', 'Tubulin', 'VDAC1', 'mitotracker']\n",
    "\n",
    "cell_lines = ['WT']\n",
    "conditions = ['Untreated']\n",
    "\n",
    "############# END OF SAFE ZONE ##########\n",
    "\n",
    "\n",
    "######################################################\n",
    "\n",
    "markers = np.asarray(markers)\n",
    "\n",
    "ranages_copy = deepcopy(ranges)\n",
    "\n",
    "n_ranges = len(list(ranages_copy))\n",
    "               \n",
    "# markers = get_markers(DATA_FOLDER)\n",
    "print(markers)\n",
    "print(f\"Data folder: {DATA_FOLDER}\")\n",
    "\n",
    "for marker in markers:\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(f\"------------------ MARKER = {marker} ------------------\")\n",
    "    \n",
    "    image_paths = sample_files(DATA_FOLDER, marker, cell_lines=cell_lines, conditions=conditions, n=number_of_images_per_marker)\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        if image_path[-4:]=='tiff' or image_path[-3:]=='tif':\n",
    "            print(image_path)\n",
    "            dapi_path = image_path.replace(marker, 'DAPI')\n",
    "            # dapi_path = re.sub('ch\\d\\d', 'ch01', dapi_path)\n",
    "            dapi_path = re.sub('w[2-4]conf.*_s', 'w1confDAPI_s', dapi_path)\n",
    "            \n",
    "            \n",
    "            # Load image\n",
    "            #raw_img = io.imread(os.path.join(DATA_FOLDER, image_path))\n",
    "            #raw_img = cv2.imread(os.path.join(DATA_FOLDER, image_path))\n",
    "            raw_img = cv2.imread(image_path, cv2.IMREAD_ANYDEPTH) #used to be IMREAD_GRAYSCALE\n",
    "            print(raw_img.shape, raw_img.dtype)\n",
    "            \n",
    "            raw_img_dapi = cv2.imread(dapi_path, cv2.IMREAD_ANYDEPTH) #used to be IMREAD_GRAYSCALE\n",
    "            \n",
    "\n",
    "            # Take one of the chanells (all the same, confirmed with Lena)\n",
    "            #img = np.array(raw_img[:,:,0], dtype=np.float64)\n",
    "            img = raw_img\n",
    "            dapi = raw_img_dapi\n",
    "            \n",
    "            rows, cols = n_ranges+1, 3\n",
    "            fig, ax = plt.subplots(rows,cols, figsize=(20, 20))\n",
    "            # Plot raw image\n",
    "            plots(ax, 0, img, dapi, title='Raw image ')\n",
    "\n",
    "            # Scaling and transform #############################################\n",
    "\n",
    "            \n",
    "            ranages_copy = deepcopy(ranges)\n",
    "            for indx, (mn, mx) in enumerate(ranages_copy):\n",
    "                plot_target_and_dapi_rescaled(indx+1, img, dapi, mn, mx)\n",
    "            \n",
    "\n",
    "            # Cosmetics - add frame\n",
    "            fig.suptitle(f\"{os.path.basename(os.path.dirname(image_path))}\\n{image_path.replace(DATA_FOLDER, '')}\\n\\n\")\n",
    "            fig.subplots_adjust(top=0.9, bottom=0.15, left=0.2, hspace=0.1)\n",
    "\n",
    "            fig.patch.set_linewidth(10)\n",
    "            fig.patch.set_edgecolor('cornflowerblue')\n",
    "\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # DAPI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee96624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Done!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
