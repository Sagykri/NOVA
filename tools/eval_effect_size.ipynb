{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c2ebe2",
   "metadata": {},
   "source": [
    "# Debug effect size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0509a513",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "os.environ[\"NOVA_HOME\"] = \"/home/projects/hornsteinlab/Collaboration/NOVA/\"\n",
    "sys.path.insert(1, os.getenv(\"NOVA_HOME\"))\n",
    "print(os.getenv(\"NOVA_HOME\"))\n",
    "\n",
    "from src.common.utils import get_if_exists\n",
    "\n",
    "\n",
    "patient_to_plate = {'EDi022':1,'EDi029':2,'EDi037':3}\n",
    "\n",
    "def _prepare_embeddings_df(embeddings: np.ndarray[float], \n",
    "                           labels: np.ndarray[str], paths) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create a DataFrame with embeddings and metadata parsed from sample labels.\n",
    "        Parses labels of the form \"marker_cellline_condition_batch_rep\" into separate columns.\n",
    "\n",
    "        Args:\n",
    "            embeddings (np.ndarray[float]):     Embeddings array of shape (n_samples, n_features).\n",
    "            labels (np.ndarray[str]):           Array of label strings matching embedding rows.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing embedding columns plus columns:\n",
    "                ['marker', 'cell_line', 'condition', 'batch', 'rep'].\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If any label string does not contain exactly 5 underscore-separated parts.\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame(embeddings)\n",
    "        df['label'] = labels\n",
    "        df['site'] = [p.split(os.sep)[-2] for p in paths]\n",
    "        df['tile_number'] = [int(p.split(os.sep)[-1]) for p in paths]\n",
    "\n",
    "        # Split and validate\n",
    "        split_labels = df['label'].str.split('_', expand=True)\n",
    "\n",
    "        # Check that all labels have 5 parts\n",
    "        if split_labels.shape[1] != 5:\n",
    "            invalid_labels = df['label'][split_labels.isnull().any(axis=1)].tolist()\n",
    "            raise ValueError(\n",
    "                f\"Some label strings are invalid (expected 5 parts separated by '_').\\n\"\n",
    "                f\"Example invalid labels: {invalid_labels[:5]}\"\n",
    "            )\n",
    "        df[['marker', 'cell_line', 'condition', 'batch', 'rep']] = split_labels\n",
    "        return df\n",
    "\n",
    "def _calculate_all_effects(embeddings_df: pd.DataFrame, \n",
    "                               embeddings_dim:int, n_boot:int=1000, data_config=None, subsample_fraction:float=1) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculate batch-level effect sizes for all marker-baseline-perturbation combinations.\n",
    "\n",
    "        Args:\n",
    "            embeddings_df (pd.DataFrame):\n",
    "                DataFrame with embedding vectors and metadata, created by `_prepare_embeddings_df`.\n",
    "            embeddings_dim (int):\n",
    "                Dimensionality of the embedding vectors.\n",
    "            n_boot (int)\n",
    "                Number of bootstrap iterations (default: 1000).\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame\n",
    "                DataFrame with per-batch effect size statistics including:\n",
    "                ['marker', 'baseline', 'pert', 'batch', 'baseline_size', 'perturb_size', \n",
    "                'effect_size', 'variance'].\n",
    "        \"\"\"\n",
    "\n",
    "        results = []\n",
    "        baseline = get_if_exists(data_config, 'BASELINE', None)\n",
    "        assert baseline is not None, \"BASELINE is None. You have to specify the baseline (for example: WT_Untreated or TDP43_Untreated)\"\n",
    "\n",
    "        print(f\"[AnalyzerEffects] baseline: {baseline}\")\n",
    "        baseline_cell_line, baseline_cond = baseline.split('_')\n",
    "        baseline_df = embeddings_df[\n",
    "                            (embeddings_df.cell_line == baseline_cell_line) &\n",
    "                            (embeddings_df.condition == baseline_cond)]\n",
    "\n",
    "        pert = get_if_exists(data_config, 'PERTURBATION', None)\n",
    "        assert baseline is not None, \"PERTURBATION is None. You have to specify the PERTURBATION (for example: WT_stress or TDP43_DOX)\"\n",
    "\n",
    "        print(f\"[AnalyzerEffects] pert: {pert}\")\n",
    "        pert_cell_line, pert_cond = pert.split('_')\n",
    "        pert_df = embeddings_df[\n",
    "                        (embeddings_df.cell_line == pert_cell_line) &\n",
    "                        (embeddings_df.condition == pert_cond)]\n",
    "        \n",
    "        # Group each DataFrame by marker and batch separately\n",
    "        baseline_groups = baseline_df.groupby(['marker', 'batch'])\n",
    "        pert_groups = pert_df.groupby(['marker', 'batch'])\n",
    "        # Iterate over marker-batch keys that appear in both baseline and perturbed\n",
    "        common_batch_marker_keys = set(baseline_groups.groups.keys()) & set(pert_groups.groups.keys())\n",
    "        common_batch_marker_keys = sorted(common_batch_marker_keys)\n",
    "        for key in common_batch_marker_keys:\n",
    "            marker, batch = key\n",
    "            print(f\"[AnalyzerEffects] marker: {marker}, batch: {batch}\")\n",
    "            \n",
    "            batch_marker_baseline_df = baseline_groups.get_group(key)\n",
    "            batch_marker_pert_df = pert_groups.get_group(key)\n",
    "\n",
    "            min_required = data_config.MIN_REQUIRED\n",
    "            res = _calculate_effect_per_batch(batch_marker_baseline_df, \n",
    "                                                    batch_marker_pert_df, embeddings_dim, \n",
    "                                                    min_required, n_boot, subsample_fraction=subsample_fraction, trimming_alpha=data_config.BOOTSTRAP_TRIMMING_ALPHA)\n",
    "            if res:\n",
    "                res.update({'marker': marker, 'baseline': baseline, 'pert': pert, 'batch': batch})\n",
    "                results.append(res)\n",
    "\n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "def _calculate_all_effects_AlyssaNEW(embeddings_df: pd.DataFrame, baseline_perturb_dict, \n",
    "                            embeddings_dim:int, n_boot:int=1000, data_config=None, subsample_fraction:float=1) -> pd.DataFrame:\n",
    "\n",
    "    results = []\n",
    "    for baseline in baseline_perturb_dict:\n",
    "        print(f\"[AnalyzerEffects] baseline: {baseline}\")\n",
    "        baseline_cell_line, baseline_cond = baseline.split('_')\n",
    "        baseline_df = embeddings_df[\n",
    "                            (embeddings_df.cell_line == baseline_cell_line) &\n",
    "                            (embeddings_df.condition == baseline_cond)]\n",
    "        for pert in baseline_perturb_dict[baseline]:\n",
    "            print(f\"[AnalyzerEffects] pert: {pert}\")\n",
    "            pert_cell_line, pert_cond = pert.split('_')\n",
    "            pert_df = embeddings_df[\n",
    "                            (embeddings_df.cell_line == pert_cell_line) &\n",
    "                            (embeddings_df.condition == pert_cond)]\n",
    "            \n",
    "            # Group each DataFrame by marker separately\n",
    "            baseline_groups = baseline_df.groupby(['marker'])\n",
    "            pert_groups = pert_df.groupby(['marker'])\n",
    "            # Iterate over marker keys that appear in both baseline and perturbed\n",
    "            common_marker_keys = set(baseline_groups.groups.keys()) & set(pert_groups.groups.keys())\n",
    "            common_marker_keys = sorted(common_marker_keys)\n",
    "            for marker in common_marker_keys:\n",
    "                print(f\"[AnalyzerEffects] marker: {marker}\")\n",
    "                \n",
    "                marker_baseline_df = baseline_groups.get_group((marker,))\n",
    "                marker_pert_df = pert_groups.get_group((marker,))\n",
    "\n",
    "                min_required = data_config.MIN_REQUIRED\n",
    "                res = _calculate_effect_per_batch(marker_baseline_df, \n",
    "                                                        marker_pert_df, embeddings_dim,\n",
    "                                                        min_required, n_boot, subsample_fraction=subsample_fraction, trimming_alpha=data_config.BOOTSTRAP_TRIMMING_ALPHA)\n",
    "                if res:\n",
    "                    baseline_general, baseline_patient = baseline_cell_line.split('-')\n",
    "                    pert_general, pert_patient = pert_cell_line.split('-')\n",
    "                    res.update({'marker': marker, 'baseline': baseline_general, 'pert': pert_general,\n",
    "                                'baseline_patient':baseline_patient, 'pert_patient':pert_patient,\n",
    "                                'plate':patient_to_plate[baseline_patient]})\n",
    "                    results.append(res)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def _calculate_effect_per_batch(batch_marker_baseline_df:pd.DataFrame, \n",
    "                                batch_marker_pert_df:pd.DataFrame, embeddings_dim: int, \n",
    "                                min_required:int, n_boot:int=1000, subsample_fraction:float=1, trimming_alpha=0.01):\n",
    "    \"\"\"\n",
    "    Calculate the effect size and variance between baseline and perturbed groups \n",
    "    within a single batch and marker.\n",
    "\n",
    "    Args:\n",
    "        batch_marker_baseline_df (pd.DataFrame):    \n",
    "            DataFrame of baseline group samples for a single marker and batch,\n",
    "            containing embedding columns plus metadata.\n",
    "        batch_marker_pert_df (pd.DataFrame): \n",
    "            DataFrame of perturbed group samples for the same marker and batch.\n",
    "        embeddings_dim (int): \n",
    "            Number of embedding feature columns.\n",
    "        min_required (int): \n",
    "            Minimum sample size in each group required to calculate effect size (default: 1000).\n",
    "        n_boot (int): \n",
    "            Number of bootstrap iterations for variance estimation (default: 1000).\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with keys:\n",
    "            'baseline_size': Number of baseline samples,\n",
    "            'perturb_size': Number of perturbed samples,\n",
    "            'effect_size': Calculated effect size,\n",
    "            'variance': Estimated variance of the effect size.\n",
    "        Returns empty dict if sample sizes are below `min_required`.\n",
    "    \"\"\"\n",
    "    n_baseline_tiles = batch_marker_baseline_df.shape[0]\n",
    "    n_pert_tiles = batch_marker_pert_df.shape[0]\n",
    "\n",
    "    n_baseline_sites = batch_marker_baseline_df['site'].nunique()\n",
    "    n_pert_sites = batch_marker_pert_df['site'].nunique()\n",
    "\n",
    "    if min(n_baseline_sites, n_pert_sites) < min_required:\n",
    "        print(f\"Too few samples (sites): baseline_sites={n_baseline_sites}, pert_sites={n_pert_sites}. Minimum required sites is {min_required}\")\n",
    "        return {}\n",
    "    print(f\"Sample size: baseline_tiles={n_baseline_tiles}, pert_tiles={n_pert_tiles}, baseline_sites={n_baseline_sites}, pert_sites={n_pert_sites}\")\n",
    "\n",
    "    effect_size, variance = _compute_effect(batch_marker_baseline_df, batch_marker_pert_df, n_boot, subsample_fraction=subsample_fraction, trimming_alpha=trimming_alpha)\n",
    "\n",
    "    return {'baseline_tiles_size':n_baseline_tiles, 'perturb_tiles_size':n_pert_tiles,\n",
    "            'baseline_sites_size':n_baseline_sites, 'perturb_sites_size':n_pert_sites,\n",
    "                'effect_size': effect_size, 'variance':variance}\n",
    "\n",
    "def _compute_effect(group_baseline: np.ndarray[float], \n",
    "                        group_pert: np.ndarray[float], n_boot:int=1000,subsample_fraction:float=1, trimming_alpha=0.01) -> tuple[float, float]:\n",
    "        \"\"\"Compute the effect size (Log2FC) and its estimated variance between baseline and \n",
    "        perturbed groups. The effect is computed as the log2 of the ratio between distances \n",
    "        to the baseline medoid.\n",
    "\n",
    "        Args:\n",
    "        group_baseline (np.ndarray[float]): Embeddings for the baseline group. \n",
    "        group_pert (np.ndarray[float]):     Embeddings for the perturbed group.\n",
    "        n_boot (int):                       Number of bootstrap iterations for estimating \n",
    "                                            variance (default: 1000).\n",
    "\n",
    "        Returns:\n",
    "            Tuple[float, float]: \n",
    "            - Effect size: Log2FC between median distances to the \n",
    "                baseline medoid.\n",
    "            - Variance of the effect size estimated via bootstrap.\n",
    "        \"\"\"\n",
    "        print(f'group_baseline: {group_baseline.iloc[:, :192].values[np.newaxis, ...].shape}, group_pert: {group_pert.iloc[:, :192].values[np.newaxis, ...].shape}')\n",
    "        effect_size = _compute_effect_size_baseline_distance(group_baseline.iloc[:, :192].values[np.newaxis, ...], group_pert.iloc[:, :192].values[np.newaxis, ...])[0]\n",
    "        print(f'effect size: {effect_size}')\n",
    "\n",
    "        n_sites = min(len(group_baseline['site'].unique()), len(group_pert['site'].unique()))\n",
    "        print(f\"n_sites: {n_sites}\")\n",
    "        # if n_sites <= 10:\n",
    "        #     # Jacknife\n",
    "        #     print(\"Using jacknife for effect size variance estimation\")\n",
    "        #     effect_size_var = _jacknife_effect_size_variance(group_baseline, group_pert, _compute_effect_size_baseline_distance)\n",
    "        # else:\n",
    "        print(\"Using bootstrap for effect size variance estimation\")\n",
    "        effect_size_var = _bootstrap_effect_size_variance(group_baseline, group_pert, _compute_effect_size_baseline_distance,\n",
    "                                                        n_boot=n_boot,subsample_fraction=subsample_fraction, trimming_alpha=trimming_alpha)\n",
    "\n",
    "        print(f'effect size variance: {effect_size_var}')\n",
    "\n",
    "        return effect_size, effect_size_var\n",
    "\n",
    "def _jacknife_effect_size_variance(group_baseline, group_pert,\n",
    "                                   effect_size_func, random_state:int=0) -> float:\n",
    "\n",
    "    site_col = 'site'\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    # Group by sites\n",
    "    base_groups = group_baseline.groupby(\"site\", sort=False).indices \n",
    "    pert_groups = group_pert.groupby(\"site\", sort=False).indices\n",
    "\n",
    "    thetas = []\n",
    "\n",
    "    # Leave-one-baseline-site-out\n",
    "    for s in base_groups:\n",
    "        print(f\"Leaving out baseline site: {s}\")\n",
    "        base_unique_sites_with_single_tile = {site_name: rng.choice(ti, size=1)[0] for site_name, ti in base_groups.items()}\n",
    "        pert_unique_sites_with_single_tile = {site_name: rng.choice(ti, size=1)[0] for site_name, ti in pert_groups.items()}\n",
    "\n",
    "        pert_all_selected_tiles_indexes = list(pert_unique_sites_with_single_tile.values())\n",
    "\n",
    "        Xp_full = group_pert.iloc[pert_all_selected_tiles_indexes, :192].values\n",
    "\n",
    "        print(f\" Xp_full shape: {Xp_full.shape}\")\n",
    "\n",
    "        base_tiles_indexes = [ti for k, ti in base_unique_sites_with_single_tile.items() if k != s]\n",
    "        print(f\"base_tiles_indexes: {base_tiles_indexes}; base_unique_sites_with_single_tile.values(): {base_unique_sites_with_single_tile.values()}\")\n",
    "        Xb = group_baseline.iloc[base_tiles_indexes, :192].values\n",
    "        print(f\"Xb shape (leave-one-out): {Xb.shape}\")\n",
    "        theta = float(effect_size_func(Xb[np.newaxis, ...], Xp_full[np.newaxis, ...])[0])\n",
    "        thetas.append(theta)\n",
    "\n",
    "    # Leave-one-pert-site-out\n",
    "    for s in pert_groups:\n",
    "        print(f\"Leaving out pert site: {s}\")\n",
    "        base_unique_sites_with_single_tile = {site_name: rng.choice(ti, size=1)[0] for site_name, ti in base_groups.items()}\n",
    "        pert_unique_sites_with_single_tile = {site_name: rng.choice(ti, size=1)[0] for site_name, ti in pert_groups.items()}\n",
    "\n",
    "        base_all_selected_tiles_indexes = list(base_unique_sites_with_single_tile.values())\n",
    "\n",
    "        Xb_full = group_baseline.iloc[base_all_selected_tiles_indexes, :192].values\n",
    "\n",
    "        print(f\"Xb_full shape: {Xb_full.shape}\")\n",
    "\n",
    "        pert_tiles_indexes = [ti for k, ti in pert_unique_sites_with_single_tile.items() if k != s]\n",
    "        print(f\"pert_tiles_indexes: {pert_tiles_indexes}; pert_unique_sites_with_single_tile.values(): {pert_unique_sites_with_single_tile.values()}\")\n",
    "        Xp = group_pert.iloc[pert_tiles_indexes, :192].values\n",
    "        print(f\"Xp shape (leave-one-out): {Xp.shape}\")\n",
    "        theta = float(effect_size_func(Xb_full[np.newaxis, ...], Xp[np.newaxis, ...])[0])\n",
    "        thetas.append(theta)\n",
    "\n",
    "    thetas = np.asarray(thetas, dtype=np.float64)\n",
    "    print(f\"thetas (leave-one-out estimates): {thetas}, shape: {thetas.shape}\")\n",
    "    n = len(thetas)\n",
    "    if n < 2:\n",
    "        # Not enough sites to form a jackknife variance\n",
    "        return np.nan\n",
    "\n",
    "    theta_bar = thetas.mean()\n",
    "    var_jk = (n - 1) / n * np.sum((thetas - theta_bar) ** 2)\n",
    "    return float(var_jk)\n",
    "\n",
    "def _bootstrap_effect_size_variance(group_baseline, group_pert,\n",
    "                                    effect_size_func,\n",
    "                                    n_boot: int = 1000, random_state: int = 0, subsample_fraction: float = 1, trimming_alpha=0.01) -> float:\n",
    "    \"\"\"\n",
    "    Within-batch variance via site-level bootstrap:\n",
    "      - Each bootstrap replicate samples sites with replacement.\n",
    "      - For each sampled site, pick exactly one tile (row) from that site.\n",
    "      - Compute the effect on those sampled tiles.\n",
    "\n",
    "    Assumes `group_baseline` and `group_pert` are DataFrames with columns:\n",
    "      ['site', 'tile_number', <192 embedding columns first>]\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    Xb = group_baseline.iloc[:, :192].values\n",
    "    Xp = group_pert.iloc[:, :192].values\n",
    "\n",
    "\n",
    "    # Group by sites\n",
    "    base_groups = group_baseline.groupby(\"site\", sort=False).indices \n",
    "    pert_groups = group_pert.groupby(\"site\", sort=False).indices\n",
    "    \n",
    "    def __generate_bootstrap_resamples(sites_groups: dict, n_boot: int, subsample_fraction:float) -> np.ndarray[int]:\n",
    "            \"\"\"Generates bootstrap indices by sampling one tile per site with replacement.\n",
    "            Args:\n",
    "                sites_groups (dict): Dictionary mapping site names to arrays of tile indices.\n",
    "                    for example: {'rep1_r03c09f55-ch2t1_panelJ_dNLS_processed.npy': array([ 0,  5,  9, 15, 21, 22, 27, 36, 46, 48, 50, 58, 75])}\n",
    "                n_boot (int): Number of bootstrap replicates.\n",
    "                subsample_fraction (float): Fraction of sites to sample in each bootstrap iteration.\n",
    "            Returns:\n",
    "                np.ndarray[int]: Array of shape (n_boot, n_sites_sampled) containing\n",
    "                                  bootstrap indices.\n",
    "            \"\"\"\n",
    "\n",
    "            assert 0 < subsample_fraction <= 1, \"SUBSAMPLE_FRACTION must be > 0 and <= 1\"\n",
    "            print(f\"subsample_fraction: {subsample_fraction}\")\n",
    "            n_sites_to_sample = int(len(sites_groups.keys())**subsample_fraction)\n",
    "            print(f\"[Analyzer_effects_dist_ratio._bootstrap_effect_size_variance] #sites to sample: {n_sites_to_sample} (out of {len(sites_groups.keys())} sites)\")\n",
    "\n",
    "            assert n_sites_to_sample > 1, \"#sites to sample must be > 1\"\n",
    "\n",
    "            result = np.empty((n_boot, n_sites_to_sample), dtype=int)\n",
    "            for b in range(n_boot):\n",
    "\n",
    "                # Pick one tile from each site\n",
    "                unique_sites_with_single_tile = {site_name: rng.choice(ti, size=1)[0] for site_name, ti in sites_groups.items()}\n",
    "\n",
    "                # Select sites with replacement\n",
    "                chosen_sites = rng.choice(list(unique_sites_with_single_tile.keys()), size=n_sites_to_sample, replace=True)\n",
    "                chosen_tiles = [unique_sites_with_single_tile[site] for site in chosen_sites]\n",
    "\n",
    "                result[b] = chosen_tiles\n",
    "\n",
    "            return result\n",
    "\n",
    "    # Get one tile per site for each bootstrap replicate\n",
    "    boot_idx_baseline = __generate_bootstrap_resamples(base_groups, n_boot, subsample_fraction=subsample_fraction)\n",
    "    boot_idx_pert     = __generate_bootstrap_resamples(pert_groups, n_boot, subsample_fraction=subsample_fraction)\n",
    "\n",
    "    print(f\"boot_idx_baseline: {boot_idx_baseline.shape}, boot_idx_pert: {boot_idx_pert.shape}\")\n",
    "\n",
    "\n",
    "    # --- Gather embeddings for those indices: shape => (n_boot, n_sites, 192) ---\n",
    "    group_baseline_boot = Xb[boot_idx_baseline]\n",
    "    group_pert_boot     = Xp[boot_idx_pert]\n",
    "\n",
    "\n",
    "    # --- Compute effect sizes across all replicates (your function API unchanged) ---\n",
    "    boot_effect_sizes = effect_size_func(group_baseline_boot, group_pert_boot)\n",
    "\n",
    "    # Trim outliers\n",
    "    alpha = trimming_alpha\n",
    "    low, high = np.percentile(boot_effect_sizes, [100*alpha, 100*(1-alpha)])\n",
    "    print(f\"!!!!!!!! Removing outliers from bootstrap effect sizes !!!!!!!!! alpha: {alpha}, low: {low}, high: {high}\")\n",
    "    print(f\"before: boot_effect_sizes: {boot_effect_sizes.shape}\")\n",
    "    boot_effect_sizes = boot_effect_sizes[(boot_effect_sizes >= low) & (boot_effect_sizes <= high)]\n",
    "    print(f\"after: boot_effect_sizes: {boot_effect_sizes.shape}\")\n",
    "    # --- Return unbiased sample variance across bootstrap effects ---\n",
    "    return float(np.var(boot_effect_sizes, ddof=1))\n",
    "\n",
    "def _bootstrap_effect_size_variance_old(group_baseline:np.ndarray[float], group_pert:np.ndarray[float],\n",
    "                                    effect_size_func,\n",
    "                                    n_boot:int=1000, random_state:int=0)->float:\n",
    "    \"\"\"\n",
    "    Estimates the variance of an effect size via bootstrapping.\n",
    "\n",
    "    For each of `n_boot` bootstrap iterations, samples with replacement from both \n",
    "    baseline and perturbed groups, computes the effect size using `effect_size_func`, \n",
    "    and then returns the variance across bootstrap samples.\n",
    "\n",
    "    Args:\n",
    "        group_baseline (np.ndarray): Array of shape (n_samples_baseline, n_features), \n",
    "            containing the baseline group embeddings.\n",
    "        group_pert (np.ndarray): Array of shape (n_samples_pert, n_features), \n",
    "            containing the perturbed group embeddings.\n",
    "        effect_size_func (Callable): Function that takes two arrays of shape \n",
    "            (n_boot, n_samples, n_features) and returns an array of effect sizes \n",
    "            (shape: n_boot,).\n",
    "        n_boot (int): Number of bootstrap replicates (default: 1000).\n",
    "        random_state (int): Random seed for reproducibility (default: 0).\n",
    "\n",
    "    Returns:\n",
    "        float: Estimated variance of the effect size from the bootstrap distribution.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    Xb = group_baseline.iloc[:, :192].values\n",
    "    Xp = group_pert.iloc[:, :192].values\n",
    "\n",
    "    n_baseline = Xb.shape[0]\n",
    "    n_pert = Xp.shape[0]\n",
    "\n",
    "    # Generate all bootstrap indices at once:\n",
    "    boot_idx_baseline = rng.integers(0, n_baseline, size=(n_boot, n_baseline))\n",
    "    boot_idx_pert = rng.integers(0, n_pert, size=(n_boot, n_pert))\n",
    "    \n",
    "    # Index bootstrap samples, result shape (n_boot, n_samples, features)\n",
    "    group_baseline_boot = Xb[boot_idx_baseline]\n",
    "    group_pert_boot = Xp[boot_idx_pert]\n",
    "\n",
    "    # Compute effect sizes for all bootstraps\n",
    "    boot_effect_sizes = effect_size_func(group_baseline_boot, group_pert_boot)\n",
    "    \n",
    "    # Return variance estimate of effect size from bootstrap distribution\n",
    "    # return np.std(boot_effect_sizes, ddof=1)\n",
    "    return np.var(boot_effect_sizes, ddof=1) # Update 3.9.25 - Returning variance instead of std as expected by smm.combine_effects\n",
    " \n",
    "def _detect_extreme_tails(values, factor=3.0):\n",
    "    \"\"\"\n",
    "    Flag if 1%/99% quantiles are 'far' compared to IQR.\n",
    "    factor: how many times bigger than the IQR counts as extreme\n",
    "    \"\"\"\n",
    "    values = np.asarray(values, float)\n",
    "    values_sorted = np.sort(values)\n",
    "\n",
    "    min_val, max_val = values_sorted[0], values_sorted[-1]\n",
    "    q25, q75 = np.percentile(values_sorted, [25, 75])\n",
    "    iqr = q75 - q25\n",
    "    lower_gap = (q25 - min_val) / iqr if iqr > 0 else np.inf\n",
    "    upper_gap = (max_val - q75) / iqr if iqr > 0 else np.inf\n",
    "    is_extreme = (lower_gap > factor) or (upper_gap > factor)\n",
    "\n",
    "    results = {'upper_outlier':{}, 'lower_outlier':{}}\n",
    "    if lower_gap > factor:\n",
    "        results['lower_outlier']['value'] = min_val\n",
    "        results['lower_outlier']['gap'] = values_sorted[1] - min_val\n",
    "    if upper_gap > factor:\n",
    "        results['upper_outlier']['value'] = max_val\n",
    "        results['upper_outlier']['gap'] = max_val - values_sorted[-2]\n",
    "\n",
    "    return is_extreme, results\n",
    "\n",
    "def _compute_effect_size_baseline_distance(group_baseline:np.ndarray[float], \n",
    "                                               group_pert:np.ndarray[float])->np.ndarray[float]:\n",
    "        \"\"\"\n",
    "        Computes Log2FC effect size between two groups based on distances to the baseline medoid.\n",
    "\n",
    "        This function assumes each input is a batch of bootstrap replicates (n_boot, n_samples, features).\n",
    "        For each replicate, it computes the medoid of the baseline group, calculates distances of \n",
    "        both baseline and perturbed samples to that medoid, and then computes the ratio between \n",
    "        their median distances. Eventually, apply Log2 on the ratio.\n",
    "\n",
    "        Args:\n",
    "            group_baseline (np.ndarray): Array of shape (n_boot, n_samples_baseline, n_features),\n",
    "                representing bootstrap replicates of baseline group embeddings.\n",
    "            group_pert (np.ndarray): Array of shape (n_boot, n_samples_pert, n_features),\n",
    "                representing bootstrap replicates of perturbed group embeddings.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Array of shape (n_boot,), containing the effect size \n",
    "            for each bootstrap replicate.\n",
    "        \"\"\"\n",
    "        # print(f\"group_baseline: {group_baseline.shape}, group_pert: {group_pert.shape}\")\n",
    "        centroid_baseline = np.median(group_baseline, axis=1, keepdims=True)\n",
    "        # if len(centroid_baseline) > 1:\n",
    "        #     print(f\"centroid_baseline: {centroid_baseline[15]}\")\n",
    "\n",
    "        # Distances to centroid for each bootstrap sample\n",
    "        dists_baseline = np.linalg.norm(group_baseline - centroid_baseline, axis=2)  # (n_boot, n_baseline)\n",
    "        dists_pert = np.linalg.norm(group_pert - centroid_baseline, axis=2)         # (n_boot, n_pert)\n",
    "\n",
    "        # print(f\"dists_baseline: {dists_baseline.shape}, dists_pert: {dists_pert.shape}\")\n",
    "        # if len(group_baseline) > 1:\n",
    "        #     print(f\"group_baseline: {group_baseline[15]}\")\n",
    "        # if len(dists_baseline) > 1:\n",
    "        #     print(f\"dists_baseline: {dists_baseline[15]}\")\n",
    "\n",
    "        median_dist_baseline = np.median(dists_baseline,axis=1)  # (n_boot,)\n",
    "        median_dist_pert = np.median(dists_pert,axis=1)          # (n_boot,)\n",
    "\n",
    "        # print(f\"median_dist_baseline: {median_dist_baseline.shape}, median_dist_pert: {median_dist_pert.shape}\")\n",
    "        # if len(median_dist_baseline) > 1:\n",
    "        #     print(f\"median_dist_baseline: {median_dist_baseline[15]}\")\n",
    "        # if len(dists_baseline) > 1:\n",
    "        #     print(f\"dists_baseline: {dists_baseline[15]}\")\n",
    "        \n",
    "        effect_sizes = np.log2(median_dist_pert / (median_dist_baseline + np.finfo(float).eps))\n",
    "\n",
    "        print(f\"median_dist_pert: {median_dist_pert}, median_dist_baseline: {median_dist_baseline}, effect_sizes: {effect_sizes}\")\n",
    "\n",
    "        return effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eae2d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['NOVA_HOME'] = '/home/projects/hornsteinlab/Collaboration/NOVA/'\n",
    "os.environ['NOVA_DATA_HOME'] = '/home/projects/hornsteinlab/Collaboration/NOVA/input'\n",
    "\n",
    "sys.path.insert(1, os.getenv(\"NOVA_HOME\"))\n",
    "print(f\"NOVA_HOME: {os.getenv('NOVA_HOME')}\")\n",
    "\n",
    "from manuscript.effects_config import NeuronsEffectWTBaselineConfig\n",
    "from src.effects.effects_config import EffectConfig\n",
    "from src.embeddings.embeddings_utils import load_embeddings\n",
    "\n",
    "class NeuronsEffectWTBaselineOPTNConfig_FUSMarker(NeuronsEffectWTBaselineConfig):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.PERTURBATION = 'OPTN_Untreated'\n",
    "\n",
    "        # self.MARKERS = ['FUS']\n",
    "        self.CELL_LINES = ['WT', 'OPTN']\n",
    "        self.CONDITIONS = ['Untreated']\n",
    "\n",
    "        self.BOOTSTRAP_TRIMMING_ALPHA = 0\n",
    "        \n",
    "# class AlyssaCoyneNEWEffectConfig(EffectConfig):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.INPUT_FOLDERS = [\"batch1\"]\n",
    "        \n",
    "#         self.EXPERIMENT_TYPE = 'AlyssaCoyne_new'    \n",
    "#         self.BASELINE_PERTURB = {'Ctrl-EDi022_Untreated':\n",
    "#                                  ['C9-CS2YNL_Untreated','SALSPositive-CS2FN3_Untreated','SALSNegative-CS0ANK_Untreated'],\n",
    "#                                  'Ctrl-EDi029_Untreated':\n",
    "#                                  ['C9-CS7VCZ_Untreated','SALSPositive-CS4ZCD_Untreated','SALSNegative-CS0JPP_Untreated'],\n",
    "#                                  'Ctrl-EDi037_Untreated':\n",
    "#                                  ['C9-CS8RFT_Untreated','SALSPositive-CS7TN6_Untreated','SALSNegative-CS6ZU8_Untreated']}\n",
    "#         self.MIN_REQUIRED = 40 \n",
    "#         self.N_BOOT = 100 \n",
    "\n",
    "class AlyssaCoyneNEWEffectConfig_Ctrl_C9(EffectConfig):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        self.INPUT_FOLDERS = [\"batch1\"]\n",
    "        self.EXPERIMENT_TYPE = 'AlyssaCoyne_new'    \n",
    "   \n",
    "        self.BASELINE_PERTURB = {'Ctrl-EDi022_Untreated':['C9-CS2YNL_Untreated'],\n",
    "                                 'Ctrl-EDi029_Untreated':['C9-CS7VCZ_Untreated'],\n",
    "                                 'Ctrl-EDi037_Untreated':['C9-CS8RFT_Untreated']}\n",
    "\n",
    "        self.MIN_REQUIRED = 8\n",
    "        self.N_BOOT = 1000\n",
    "\n",
    "        self.SUBSAMPLE_FRACTION = 1\n",
    "        self.BOOTSTRAP_TRIMMING_ALPHA = 0.01\n",
    "\n",
    "class AlyssaCoyneNEWEffectConfig_Ctrl_sALSNeg(EffectConfig):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.INPUT_FOLDERS = [\"batch1\"]\n",
    "        \n",
    "        self.EXPERIMENT_TYPE = 'AlyssaCoyne_new'    \n",
    "        self.BASELINE_PERTURB = {'Ctrl-EDi022_Untreated':\n",
    "                                 ['SALSNegative-CS0ANK_Untreated'],\n",
    "                                 'Ctrl-EDi029_Untreated':\n",
    "                                 ['SALSNegative-CS0JPP_Untreated'],\n",
    "                                 'Ctrl-EDi037_Untreated':\n",
    "                                 ['SALSNegative-CS6ZU8_Untreated']}\n",
    "        self.MIN_REQUIRED = 8 \n",
    "        self.N_BOOT = 1000\n",
    "        self.SUBSAMPLE_FRACTION = 1\n",
    "        self.BOOTSTRAP_TRIMMING_ALPHA = 0.01\n",
    "\n",
    "class AlyssaCoyneNEWEffectConfig_Ctrl_sALSPos(EffectConfig):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.INPUT_FOLDERS = [\"batch1\"]\n",
    "        \n",
    "        self.EXPERIMENT_TYPE = 'AlyssaCoyne_new'    \n",
    "        self.BASELINE_PERTURB = {'Ctrl-EDi022_Untreated':\n",
    "                                 ['SALSPositive-CS2FN3_Untreated'],\n",
    "                                 'Ctrl-EDi029_Untreated':\n",
    "                                 ['SALSPositive-CS4ZCD_Untreated'],\n",
    "                                 'Ctrl-EDi037_Untreated':\n",
    "                                 ['SALSPositive-CS7TN6_Untreated']}\n",
    "        self.MIN_REQUIRED = 8 \n",
    "        self.N_BOOT = 1000\n",
    "        self.SUBSAMPLE_FRACTION = 1\n",
    "        self.BOOTSTRAP_TRIMMING_ALPHA = 0.01\n",
    "\n",
    "class dNLSEffectConfig(EffectConfig):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.INPUT_FOLDERS = [\"batch1\", 'batch2', 'batch4', 'batch5', 'batch6']\n",
    "        self.EXPERIMENT_TYPE = 'dNLS'\n",
    "        self.BASELINE = 'dNLS_Untreated'\n",
    "        self.PERTURBATION = 'dNLS_DOX'\n",
    "\n",
    "        self.MARKERS = ['DCP1A', 'LSM14A', 'TDP43']\n",
    "        self.CELL_LINES = ['dNLS']\n",
    "\n",
    "        self.MIN_REQUIRED:int = 200\n",
    "        self.N_BOOT:int = 1000\n",
    "\n",
    "        self.SUBSAMPLE_FRACTION:float = 0.8\n",
    "        self.BOOTSTRAP_TRIMMING_ALPHA = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e3e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_path = f\"/home/projects/hornsteinlab/Collaboration/NOVA/outputs/vit_models/finetunedModel_MLPHead_acrossBatches_B56789_80pct_frozen\"\n",
    "\n",
    "config_data = dNLSEffectConfig()\n",
    "MIN_REQUIRED = config_data.MIN_REQUIRED\n",
    "baseline = config_data.BASELINE\n",
    "perturbation = config_data.PERTURBATION\n",
    "N_BOOT = config_data.N_BOOT\n",
    "baseline_perturb_dict = config_data.BASELINE_PERTURB\n",
    "subsample_fraction = config_data.SUBSAMPLE_FRACTION\n",
    "\n",
    "print(f\"MIN_REQUIRED: {MIN_REQUIRED}, N_BOOT: {N_BOOT}, subsample_fraction: {subsample_fraction}\")\n",
    "\n",
    "embeddings, labels, paths = load_embeddings(output_folder_path, config_data)\n",
    "print(f\"Loaded embeddings: {embeddings.shape}, labels: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99daaaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = _prepare_embeddings_df(embeddings, labels, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd1a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m-out-of-n bootstrap with m=n^0.8\n",
    "\n",
    "embeddings_dim = embeddings.shape[1]\n",
    "batch_effects_df = _calculate_all_effects(embeddings_df, embeddings_dim, n_boot=N_BOOT, data_config=config_data, subsample_fraction=subsample_fraction)\n",
    "# batch_effects_df = _calculate_all_effects_AlyssaNEW(embeddings_df, baseline_perturb_dict, embeddings_dim, n_boot=N_BOOT, data_config=config_data, subsample_fraction=subsample_fraction)\n",
    "batch_effects_df #var (batch1)=0.0001795719435904175\n",
    "# var(batch2) = 0.00041040857615744913, 4:0.00016749799451609072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "threshold = 3.5\n",
    "\n",
    "values = np.asarray([1.0819668, 0.6887636, 0.836427, 0.91433513, 0.73103714, 0.73679066,\n",
    "0.9333562, 0.8876782, 1.0214874, 0.33478883, 0.38261652, 1.0094036,\n",
    "51.75445, 0.95097727, 0.99052495, 0.84662837, 0.779497, 0.34244287,\n",
    "0.6329029, 1.7925295, 0.6844236, 0.81550556, 0.65079385, 0.25794902,\n",
    "0.59794515, 0.99639165, 1.4005525, 0.8440567, 0.84858644, 0.56309044,\n",
    "0.07876747, 1.0316154, 0.8935941, 0.47780955, 0.3085186, 1.6940162,\n",
    "1.3778188, 0.7926947, 0.6188739, 0.88191855, 0.57499385, 0.60657656,\n",
    "0.222635, 0.6133846, 0.8974427, 0.6005375, 0.5450934, 0.5995726,\n",
    "1.1220164, 0.50545806, 0.9233688, 0.49774283, 0.99617624, 0.72606295,\n",
    "0.7551414, 0.29550284, 0.70234793, 0.72982216, 0.7813434, 0.3460404,\n",
    "0.6993063, 0.89958376, 0.75325906, 0.3151728, 0.41963068, 0.9564328,\n",
    "0.6250539, 1.1172084, 0.66811985, 0.53819036, 0.5155426, 0.71062726,\n",
    "0.19240856, 0.5365439, 0.6848168, 0.33390152, 0.48140135, 0.9711509,\n",
    "0.7659023, 0.71938497, 0.2735866, 0.81828266, 0.5973417, 0.81533337,\n",
    "0.90853846, 0.9569908, 0.9358572, 0.63142365, 1.276427, 0.8971199,\n",
    "0.23139422, 0.3382685, 0.9083413, 1.0998214, 0.97667134, 0.83429754,\n",
    "0.4790548, 0.4341146, 1.144973, 0.8911407])\n",
    "\n",
    "\n",
    "def __detect_extreme_tails_MAD(values, threshold=3.5):\n",
    "    values = np.asarray(values, float)\n",
    "    # Explanation:\n",
    "    # Calculating diffs = np.abs(values - np.median(values))\n",
    "    # Checking for outliers diffs / np.median(diffs) > threshold\n",
    "    outliers = (np.abs(values - np.median(values)) / scipy.stats.median_abs_deviation(values, scale=\"normal\") > threshold)\n",
    "    print(np.abs(values - np.median(values)))\n",
    "    print(scipy.stats.median_abs_deviation(values, scale=\"normal\"))\n",
    "    is_extreme = np.any(outliers)\n",
    "    values = values[outliers]\n",
    "\n",
    "    return is_extreme, values.tolist()\n",
    "\n",
    "__detect_extreme_tails_MAD(values, threshold=threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68654d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_effects_df.to_csv(\"/home/projects/hornsteinlab/Collaboration/NOVA/tools/AlyssaCoyneNew_C9_batch_effect_test_nboot1000_trimmed1.csv\", index=False)#.loc[batch_effects_df['marker'].isin(['LSM14A', 'FUS']), ['effect_size', 'variance', 'batch', 'marker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857f3006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats, optimize\n",
    "\n",
    "def _get_log_likelihood_reml(effects, variances, tau2):\n",
    "    tau2 = max(tau2, 0.0)\n",
    "    w = 1.0 / (variances + tau2)\n",
    "    sw = np.sum(w)\n",
    "    combined_effect = np.sum(w * effects) / sw\n",
    "    Q = np.sum(w * (effects - combined_effect) ** 2)\n",
    "\n",
    "    return -0.5 * (np.log(variances + tau2).sum() + np.log(sw) + Q)\n",
    "\n",
    "def profiling_likelihood(effects, variances, tau2_max_expand=1e8):\n",
    "    nll = lambda t2: -_get_log_likelihood_reml(effects, variances, t2) # negative log-likelihood\n",
    "\n",
    "    opt = optimize.minimize_scalar(nll, bounds=(0, 10), method=\"bounded\")\n",
    "    tau2_hat = opt.x  # the tau^2 that maximizes the likelihood\n",
    "    ll_hat = -opt.fun # the maximum log-likelihood value (negative since we minimized minus (-) reml)\n",
    "    \n",
    "    def ll_gap(tau2):\n",
    "        # if gap < 0: tau2 is still inside the CI\n",
    "        # if gap > 0: tau2 is outside the CI\n",
    "\n",
    "        threshold = stats.chi2.ppf(1 - 0.05, df=1)\n",
    "        gap = 2.0 * (ll_hat - _get_log_likelihood_reml(effects, variances, tau2)) - threshold\n",
    "\n",
    "        return gap \n",
    "\n",
    "    # Find lower CI bound\n",
    "    if ll_gap(0.0) <= 0 or tau2_hat == 0:\n",
    "        ci_low = 0.0 # if 0 is inside the CI, then the lower bound is 0\n",
    "    else:\n",
    "        ci_low = optimize.brentq(ll_gap, 0.0, tau2_hat) # finds a number between 0 and tau2_hat such that ll_gap(b) = 0\n",
    "\n",
    "    # Find upper CI bound\n",
    "    tau2_high = max(tau2_hat, 1e-12)\n",
    "    while ll_gap(tau2_high) < 0 and tau2_high < tau2_max_expand:\n",
    "        tau2_high *= 2.0 # expand CI until we find a point outside the CI\n",
    "\n",
    "    if ll_gap(tau2_high) < 0:\n",
    "        print(f\"Warning: could not find the upper CI bound. tau2_hat={tau2_hat}, tau2_high={tau2_high}, ll_gap(tau2_high)={ll_gap(tau2_high)}\")\n",
    "        return tau2_hat, ci_low, np.nan\n",
    "\n",
    "    ci_high = optimize.brentq(ll_gap, tau2_hat, tau2_high) # finds a number between tau2_hat and tau2_high such that ll_gap(b) = 0\n",
    "\n",
    "    return tau2_hat, ci_low, ci_high\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e4ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from abc import abstractmethod\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import statsmodels.stats.meta_analysis as smm\n",
    "from scipy.stats import norm, chi2, t\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import math\n",
    "from src.common.utils import get_if_exists\n",
    "\n",
    "df_combined = []\n",
    "\n",
    "for marker in batch_effects_df['marker'].unique():\n",
    "    # print(f\"Marker: {marker}\")\n",
    "    marker_df = batch_effects_df[batch_effects_df['marker'] == marker]\n",
    "    if len(marker_df) < 2:\n",
    "        print(f\"Skipping marker {marker} with only {len(marker_df)} batches\")\n",
    "        continue\n",
    "    effects = marker_df['effect_size'].astype(np.float64)\n",
    "    variances = marker_df['variance'].astype(np.float64)\n",
    "\n",
    "    # if not _can_converge_tau_iterative(effects, variances): # DOESNT WORK\n",
    "    #     print(f\"[WARNING] for {marker} in {baseline} vs {pert}, Random effect model failed to converge for estimation of tau2.\")\n",
    "        \n",
    "    meta_res = smm.combine_effects(effects, variances)\n",
    "\n",
    "\n",
    "\n",
    "    summary = meta_res.summary_frame()\n",
    "\n",
    "    tau2 = meta_res.tau2\n",
    "    effect_row = summary.loc[f\"random effect\"]\n",
    "    # print(f\"w_re: {summary.loc['random effect wls']}\")\n",
    "    combined_effect = effect_row[\"eff\"]\n",
    "    combined_se = effect_row[\"sd_eff\"]\n",
    "    ci_low = effect_row[\"ci_low\"]\n",
    "    ci_upp = effect_row[\"ci_upp\"]\n",
    "\n",
    "    if tau2 > 0:\n",
    "        df = len(marker_df) - 2 # degrees of freedom\n",
    "        t_crit = t.ppf(0.975, df)\n",
    "        pred_se = np.sqrt(combined_se**2 + tau2)\n",
    "\n",
    "        lower_pi = combined_effect - t_crit * pred_se\n",
    "        upper_pi = combined_effect + t_crit * pred_se\n",
    "    else:\n",
    "        # If tau2 is zero, we cannot compute prediction intervals\n",
    "        lower_pi, upper_pi = None, None\n",
    "\n",
    "    alt='greater'\n",
    "    # Compute z and p: The pooled estimate is significantly different from zero.\n",
    "    z = combined_effect / combined_se\n",
    "    if alt == \"two-sided\":\n",
    "        pvalue = 2 * (1 - norm.cdf(abs(z)))\n",
    "    elif alt == \"greater\":\n",
    "        pvalue = 1 - norm.cdf(z)\n",
    "    elif alt == \"smaller\":\n",
    "        pvalue = norm.cdf(z)\n",
    "\n",
    "    p_heterogeneity  = 1 - chi2.cdf(meta_res.q, df=meta_res.df)\n",
    "    I2 = max(0, (meta_res.q - meta_res.df) / meta_res.q) * 100\n",
    "\n",
    "    tau2_hat, tau2_ci_low, tau2_ci_high = profiling_likelihood(effects, variances)\n",
    "\n",
    "    if not math.isclose(tau2, tau2_hat, abs_tol=1e-3):\n",
    "        print(f\"Warning: tau2 from smm.combine_effects ({tau2}) is different from tau2_hat from profiling ({tau2_hat}) for marker {marker}\")\n",
    "\n",
    "    df_combined.append({\n",
    "        'marker': marker,\n",
    "        'baseline': \"Ctrl\",\n",
    "        'pert': \"C9\",\n",
    "        'combined_effect': combined_effect,\n",
    "        'combined_se': combined_se,\n",
    "        'pvalue': pvalue,\n",
    "        'ci_low': ci_low,\n",
    "        'ci_upp': ci_upp,\n",
    "        'p_heterogeneity': p_heterogeneity,\n",
    "        'I2': I2,\n",
    "        'Q': meta_res.q,\n",
    "        'tau2': tau2, \n",
    "        'pi_low': lower_pi,\n",
    "        'pi_upp': upper_pi,\n",
    "\n",
    "        'tau2_hat': tau2_hat,\n",
    "        'tau2_ci_low': tau2_ci_low,\n",
    "        'tau2_ci_high': tau2_ci_high,\n",
    "        })\n",
    "\n",
    "    # print(f\"[{marker}] Combined effect: {combined_effect}, combined_se: {combined_se}, CI: [{ci_low}, {ci_upp}], pi: ({lower_pi}, {upper_pi}), Q: {meta_res.q}, p-value: {pvalue}, tau2: {tau2}, I2: {I2}, p-heterogeneity: {p_heterogeneity}\")\n",
    "\n",
    "df_combined = pd.DataFrame(df_combined)\n",
    "df_combined['pvalue'] = df_combined['pvalue'].replace(0, 1e-300)  # avoid log(0)\n",
    "df_combined['adj_pvalue'] = multipletests(df_combined['pvalue'], method='fdr_bh')[1]\n",
    "df_combined.sort_values(['combined_effect', 'adj_pvalue'], ascending=[False, True])\n",
    "df_combined\n",
    "# df_combined.to_csv(\"/home/projects/hornsteinlab/Collaboration/NOVA/tools/AlyssaCoyneNew_C9_combined_effect_test_nboot1000_trimmed1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af29d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[df_combined['adj_pvalue'] < 0.05].sort_values(['combined_effect', 'adj_pvalue'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487315b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_fit_tau_iterative(np.asarray([0.8618529,0.9719788,0.14458823,0.5731879,1.0031568]), np.asarray([0.00017957194,0.00039759855,0.00019547212,0.00014277807, 4.5440567e-05])))\n",
    "\n",
    "_fit_tau_iterative(batch_effects_df['effect_size'], batch_effects_df['variance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46c4d1a",
   "metadata": {},
   "source": [
    "# Test distances between tiles from the same site VS tiles from different sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf77e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['NOVA_HOME'] = '/home/projects/hornsteinlab/Collaboration/NOVA/'\n",
    "os.environ['NOVA_DATA_HOME'] = '/home/projects/hornsteinlab/Collaboration/NOVA/input'\n",
    "\n",
    "sys.path.insert(1, os.getenv(\"NOVA_HOME\"))\n",
    "print(f\"NOVA_HOME: {os.getenv('NOVA_HOME')}\")\n",
    "\n",
    "from manuscript.effects_config import NeuronsEffectWTBaselineConfig\n",
    "from src.effects.effects_config import EffectConfig\n",
    "from src.embeddings.embeddings_utils import load_embeddings\n",
    "\n",
    "\n",
    "class dNLSEffectConfig_Subset(EffectConfig):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.INPUT_FOLDERS = [\"batch1\", 'batch2', 'batch4', 'batch5', 'batch6']\n",
    "        self.EXPERIMENT_TYPE = 'dNLS'\n",
    "        self.BASELINE = 'dNLS_Untreated'\n",
    "        self.PERTURBATION = 'dNLS_DOX'\n",
    "\n",
    "        self.MARKERS = ['LSM14A', 'DCP1A', 'TDP43'] #['ANXA11', 'CLTC', 'DCP1A', 'TDP43', 'LSM14A', 'FUS']\n",
    "        self.CELL_LINES = ['dNLS']\n",
    "\n",
    "class neuronsDay8_NEW_Subset(EffectConfig):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.INPUT_FOLDERS = [\"batch1\", 'batch2', 'batch3', 'batch7', 'batch8', 'batch9']\n",
    "        self.EXPERIMENT_TYPE = 'neuronsDay8_new'\n",
    "\n",
    "        self.MARKERS = ['FUS']\n",
    "        self.CELL_LINES = ['WT', 'FUSHomozygous']\n",
    "        self.CONDITIONS = ['Untreated']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a91ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_path = f\"/home/projects/hornsteinlab/Collaboration/NOVA/outputs/vit_models/finetunedModel_MLPHead_acrossBatches_B56789_80pct_frozen\"\n",
    "\n",
    "config_data = dNLSEffectConfig_Subset()\n",
    "\n",
    "embeddings, labels, paths = load_embeddings(output_folder_path, config_data)\n",
    "print(f\"Loaded embeddings: {embeddings.shape}, labels: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc73ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = _prepare_embeddings_df(embeddings, labels, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7093427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def compare_within_vs_across(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each (marker, batch, cell_line, condition) group, compute mean within-site\n",
    "    and across-site Euclidean distances between embeddings.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with embeddings and metadata.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns:\n",
    "        marker, batch, cell_line, condition, mean_within, mean_across\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    group_cols = [\"marker\", \"batch\", \"cell_line\", \"condition\"]\n",
    "    \n",
    "\n",
    "    for keys, group in df.groupby(group_cols):\n",
    "        sites = group[\"site\"].unique()\n",
    "        embeddings = group[:192].to_numpy()\n",
    "\n",
    "        mean_within_list, mean_across_list, mean_vs_single_site = [], [], []\n",
    "\n",
    "        # iterate over sites\n",
    "        for site in sites:\n",
    "            site_embeds = group.loc[group[\"site\"] == site].iloc[:, :192].to_numpy()\n",
    "\n",
    "            # within-site distances\n",
    "            if len(site_embeds) > 1:\n",
    "                d_within = cdist(site_embeds, site_embeds, metric=\"euclidean\")\n",
    "                # take upper triangle (avoid 0 diagonal and double counting)\n",
    "                tri_idx = np.triu_indices_from(d_within, k=1)\n",
    "                mean_within_list.append(d_within[tri_idx].mean())\n",
    "\n",
    "            # across-site distances\n",
    "            other_embeds = group.loc[group[\"site\"] != site].iloc[:, :192].to_numpy()\n",
    "            d_across = cdist(site_embeds, other_embeds, metric=\"euclidean\")\n",
    "            mean_across_list.append(d_across.mean())\n",
    "\n",
    "            # vs different single site\n",
    "            other_sites = [s for s in sites if s != site] \n",
    "            random_site = np.random.choice(other_sites, size=1, replace=False)[0] \n",
    "            other_site_embeds = group.loc[group[\"site\"] == random_site].iloc[:, :192].to_numpy() \n",
    "            d_other_site = cdist(site_embeds, other_site_embeds, metric=\"euclidean\")\n",
    "            mean_vs_single_site.append(d_other_site.mean())\n",
    "\n",
    "        results.append({\n",
    "            \"marker\": keys[0],\n",
    "            \"batch\": keys[1],\n",
    "            \"cell_line\": keys[2],\n",
    "            \"condition\": keys[3],\n",
    "            \"mean_within\": np.mean(mean_within_list) if mean_within_list else np.nan,\n",
    "            \"mean_across\": np.mean(mean_across_list) if mean_across_list else np.nan,\n",
    "            'mean_other_site': np.mean(mean_vs_single_site) if mean_vs_single_site else np.nan\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a0f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_comparison_df = compare_within_vs_across(embeddings_df)\n",
    "distances_comparison_df\n",
    "\n",
    "# TODO: Calculate dist between conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8430769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.analyzer_distances import AnalyzerDistances\n",
    "\n",
    "d = AnalyzerDistances(config_data, output_folder_path, rep_effect=False, multiplexed=False, detailed_stats=False)\n",
    "d.calculate(embeddings, labels)\n",
    "d.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd21307",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df = d.features.copy()\n",
    "dist_df\n",
    "\n",
    "def filter_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # 1. Keep only rows where label1 contains WT_Untreated and label2 contains FUSHomozygous\n",
    "    # mask1 = df[\"label1\"].str.contains(\"_FUSHomozygous_Untreated_\", regex=False)\n",
    "    # mask2 = df[\"label2\"].str.contains(\"_WT_Untreated_\", regex=False)\n",
    "    # subset = df[mask1 & mask2].copy()\n",
    "    subset = df.copy()\n",
    "\n",
    "    subset[\"marker1\"] = subset[\"label1\"].str.split(\"_\", n=1).str[0]\n",
    "    subset[\"marker2\"] = subset[\"label2\"].str.split(\"_\", n=1).str[0]\n",
    "    \n",
    "\n",
    "    # 3. Keep only rows where the batch tags match\n",
    "    subset = subset[subset[\"marker1\"] == subset[\"marker2\"]]\n",
    "\n",
    "    # 2. Extract the batch number from each label (assuming pattern like \"_batch3_\")\n",
    "    subset[\"batch1\"] = df[\"label1\"].str.extract(r'_(batch\\d+)_')\n",
    "    subset[\"batch2\"] = df[\"label2\"].str.extract(r'_(batch\\d+)_')\n",
    "\n",
    "    # 3. Keep only rows where the batch tags match\n",
    "    subset = subset[subset[\"batch1\"] == subset[\"batch2\"]]\n",
    "\n",
    "    return subset.drop(columns=[\"batch1\", \"batch2\"])\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "filtered_dist_df = filter_df(dist_df)\n",
    "filtered_dist_df.loc[filtered_dist_df['label1'].str.contains('LSM14A_dNLS_DOX') & filtered_dist_df['label2'].str.contains('LSM14A_dNLS_DOX'), ['label1', 'label2', 'total_pairs', 'p50']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e30f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dist_df.loc[filtered_dist_df['label1'].str.contains('LSM14A_dNLS_Untreated') & filtered_dist_df['label2'].str.contains('LSM14A_dNLS_Untreated'), ['label1', 'label2', 'total_pairs', 'p50']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef2ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dist_df.loc[filtered_dist_df['label1'].str.contains('LSM14A_dNLS_DOX') & filtered_dist_df['label2'].str.contains('LSM14A_dNLS_Untreated'), ['label1', 'label2', 'total_pairs', 'p50']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed5aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_within_vs_across(embeddings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fa4a19",
   "metadata": {},
   "source": [
    "# Eval effect size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65317153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import statsmodels.stats.meta_analysis as smm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28111091",
   "metadata": {},
   "outputs": [],
   "source": [
    "dNLS_batch_effect = pd.read_csv(\"/home/projects/hornsteinlab/Collaboration/NOVA/outputs/vit_models/finetunedModel_MLPHead_acrossBatches_B56789_80pct_frozen/figures/dNLS/effects/dNLS_Untreated_vs_dNLS_DOX_batch1_batch2_batch4_batch5_batch6_all_reps_without_CD41/batch_effects.csv\")\n",
    "dNLS_combined_effect = pd.read_csv(\"/home/projects/hornsteinlab/Collaboration/NOVA/outputs/vit_models/finetunedModel_MLPHead_acrossBatches_B56789_80pct_frozen/figures/dNLS/effects/dNLS_Untreated_vs_dNLS_DOX_batch1_batch2_batch4_batch5_batch6_all_reps_without_CD41/combined_effects.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e7e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dNLS_batch_effect_LSM14A = dNLS_batch_effect[dNLS_batch_effect['marker'] == 'LSM14A']\n",
    "dNLS_combined_effect_LSM14A = dNLS_combined_effect[dNLS_combined_effect['marker'] == 'LSM14A']\n",
    "print(dNLS_batch_effect_LSM14A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b057080",
   "metadata": {},
   "outputs": [],
   "source": [
    "effects = dNLS_batch_effect_LSM14A['effect_size'].values\n",
    "variances = dNLS_batch_effect_LSM14A['variance'].values\n",
    "\n",
    "meta_res = smm.combine_effects(effects, variances)\n",
    "summary = meta_res.summary_frame()\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2bf65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_res.test_homogeneity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d14e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dNLS_batch_effect_TDP43 = dNLS_batch_effect[dNLS_batch_effect['marker'] == 'TDP43']\n",
    "dNLS_combined_effect_TDP43 = dNLS_combined_effect[dNLS_combined_effect['marker'] == 'TDP43']\n",
    "print(dNLS_batch_effect_TDP43)\n",
    "\n",
    "\n",
    "effects = dNLS_batch_effect_TDP43['effect_size'].values\n",
    "variances = dNLS_batch_effect_TDP43['variance'].values\n",
    "\n",
    "meta_res = smm.combine_effects(effects, variances)\n",
    "summary = meta_res.summary_frame()\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1254acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_res.test_homogeneity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2561c0a3",
   "metadata": {},
   "source": [
    "# Testing Coefficient of Variation on tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cfbbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dNLS_combined_effect['coefficient_of_variation_percentage'] = dNLS_combined_effect['tau2'] * 100.0 / np.abs(dNLS_combined_effect['combined_effect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7955de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dNLS_combined_effect[(dNLS_combined_effect['coefficient_of_variation_percentage'] <= 20) & (dNLS_combined_effect['adj_pvalue'] <= 0.05)].sort_values(by='combined_effect', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e4a1f",
   "metadata": {},
   "source": [
    "# Extracting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66f7c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficient_of_variation_percentage_threshold = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06460c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(experiment_type, folder_name, batch_effect_filename=\"batch_effects.csv\"):\n",
    "    batch_effect = pd.read_csv(f\"/home/projects/hornsteinlab/Collaboration/NOVA/outputs/vit_models/finetunedModel_MLPHead_acrossBatches_B56789_80pct_frozen/figures/{experiment_type}/effects/{folder_name}/{batch_effect_filename}\")\n",
    "    combined_effect = pd.read_csv(f\"/home/projects/hornsteinlab/Collaboration/NOVA/outputs/vit_models/finetunedModel_MLPHead_acrossBatches_B56789_80pct_frozen/figures/{experiment_type}/effects/{folder_name}/combined_effects.csv\")\n",
    "\n",
    "    combined_effect['coefficient_of_variation_percentage'] = combined_effect['tau2'] * 100.0 / np.abs(combined_effect['combined_effect'])\n",
    "\n",
    "    return combined_effect, combined_effect[(combined_effect['coefficient_of_variation_percentage'] <= 20) & (combined_effect['adj_pvalue'] <= 0.05)].sort_values(by='combined_effect', ascending=False).reset_index(drop=True), batch_effect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac80c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_effect, combined_effect_filtered, batch_effect = get_results(\"AlyssaCoyne_new\", \"batch1_all_reps_without_CD41\", \"effects.csv\")\n",
    "markers = combined_effect[(combined_effect['pert'] == 'C9') & (combined_effect['adj_pvalue'] <= 0.05)].sort_values(by='combined_effect', ascending=False).reset_index(drop=True)['marker'].tolist()\n",
    "batch_effect[(batch_effect['pert']=='C9') & (batch_effect['marker'].isin(markers))][batch_effect['marker'] == 'Nup98']\n",
    "# combined_effect[(combined_effect['adj_pvalue'] <= 0.05) & (combined_effect['pert'] == 'C9')].sort_values(by='combined_effect', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4456f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_effect, combined_effect_filtered = get_results(\"NIH\", \"WT_Untreated_vs_WT_stress_batch1_batch2_batch3_all_reps_without_CD41\")\n",
    "combined_effect_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa896dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_effect, combined_effect_filtered = get_results(\"neuronsDay8_new\", \"WT_Untreated_vs_TDP43_Untreated_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\")\n",
    "combined_effect[(combined_effect['adj_pvalue'] <= 0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9e10f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_effect, combined_effect_filtered = get_results(\"neuronsDay8_new\", \"WT_Untreated_vs_OPTN_Untreated_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\")\n",
    "combined_effect[(combined_effect['adj_pvalue'] <= 0.05) & (combined_effect['coefficient_of_variation_percentage'] > 20)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc986aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_effect, combined_effect_filtered = get_results(\"neuronsDay8_new\", \"WT_Untreated_vs_TBK1_Untreated_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\")\n",
    "# combined_effect[(combined_effect['adj_pvalue'] <= 0.05) & (combined_effect['coefficient_of_variation_percentage'] > 20)].reset_index()\n",
    "combined_effect[(combined_effect['adj_pvalue'] <= 0.05)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c0f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_effect, combined_effect_filtered = get_results(\"neuronsDay8_new\", \"WT_Untreated_vs_FUSHomozygous_Untreated_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\")\n",
    "# combined_effect[(combined_effect['adj_pvalue'] <= 0.05) & (combined_effect['coefficient_of_variation_percentage'] > 20)].reset_index()\n",
    "combined_effect[(combined_effect['adj_pvalue'] <= 0.05)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_effect, combined_effect_filtered = get_results(\"neuronsDay8_new\", \"FUSRevertant_Untreated_vs_FUSHomozygous_Untreated_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\")\n",
    "# combined_effect[(combined_effect['adj_pvalue'] <= 0.05) & (combined_effect['coefficient_of_variation_percentage'] > 20)].reset_index()\n",
    "combined_effect[(combined_effect['adj_pvalue'] <= 0.05)].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642b006b",
   "metadata": {},
   "source": [
    "# Forest plot - new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af55d4ff",
   "metadata": {},
   "source": [
    "I2, tau, var of each batch - plot forest: show var of each batch (whistkers), I2 and tau on the figure <br/>\n",
    "remove blue asterix, show only sig markers <br/>\n",
    "show dotted line for ef=0.2 <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import scipy.stats as stats\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import natsort\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "os.environ[\"NOVA_HOME\"] = \"/home/projects/hornsteinlab/Collaboration/NOVA/\"\n",
    "sys.path.insert(1, os.getenv(\"NOVA_HOME\"))\n",
    "print(os.getenv(\"NOVA_HOME\"))\n",
    "\n",
    "\n",
    "from src.figures.figures_config import FigureConfig\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from manuscript.plot_config import PlotConfig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a88a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_effects(experiment_type, folder_name, baseline, pert, batch_file_name=\"batch_effects.csv\", effects_folder=\"effects\"):\n",
    "\n",
    "    batch_effect = pd.read_csv(f\"/home/projects/hornsteinlab/Collaboration/NOVA/outputs/vit_models/finetunedModel_MLPHead_acrossBatches_B56789_80pct_frozen/figures/{experiment_type}/{effects_folder}/{folder_name}/{batch_file_name}\")\n",
    "    combined_effect = pd.read_csv(f\"/home/projects/hornsteinlab/Collaboration/NOVA/outputs/vit_models/finetunedModel_MLPHead_acrossBatches_B56789_80pct_frozen/figures/{experiment_type}/{effects_folder}/{folder_name}/combined_effects.csv\")\n",
    "\n",
    "    # batch_effect = pd.read_csv(\"/home/projects/hornsteinlab/Collaboration/NOVA/tools/AlyssaCoyneNew_C9_batch_effect_test_nboot1000_trimmed1.csv\")\n",
    "    # combined_effect = pd.read_csv(\"/home/projects/hornsteinlab/Collaboration/NOVA/tools/AlyssaCoyneNew_C9_combined_effect_test_nboot1000_trimmed1.csv\")\n",
    "\n",
    "    batch_effect = batch_effect[(batch_effect['baseline'] == baseline) & (batch_effect['pert'] == pert)]\n",
    "    combined_effect = combined_effect[(combined_effect['baseline'] == baseline) & (combined_effect['pert'] == pert)]\n",
    "\n",
    "    return batch_effect, combined_effect\n",
    "\n",
    "def plot_forest_plot_adjusted_ver2(combined_effects_df, baseline, pert, savepath, config_plot, cur_df_single, figsize=None,\n",
    "                       combine_on='batch', show_only_significant: bool = False, \n",
    "                      add_reproducability_table: bool = True):    \n",
    "\n",
    "                     \n",
    "    combined_effects_df = combined_effects_df.sort_values('combined_effect', ascending=True).reset_index(drop=True)\n",
    "\n",
    "    if combined_effects_df.empty:\n",
    "        raise ValueError(\"combined_effects_df is empty\")\n",
    "\n",
    "    if show_only_significant:\n",
    "        keep = combined_effects_df['adj_pvalue'] <= 0.05\n",
    "        combined_effects_df = combined_effects_df.loc[keep].copy()\n",
    "        sig_markers = combined_effects_df['marker'].tolist()\n",
    "        cur_df_single = cur_df_single[cur_df_single['marker'].isin(sig_markers)].copy()\n",
    "\n",
    "        if combined_effects_df.empty:\n",
    "            raise ValueError(\"No markers remain after filtering by significance\")\n",
    "\n",
    "    figsize = (5, max(len(cur_df_single), 1) * 0.09) if figsize is None else figsize\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # reserve some room on the right for the temp table showing tau and I2\n",
    "    plt.subplots_adjust(right=0.78) \n",
    "\n",
    "    # Prepare y positions for markers\n",
    "    marker_order = combined_effects_df['marker'].tolist()\n",
    "    row_gap = 3.35 # enlarge spacing between marker rows\n",
    "    y_pos = np.arange(len(marker_order)) * row_gap\n",
    "    y_map = {m: y_pos[i] for i, m in enumerate(marker_order)}\n",
    "\n",
    "    # Create legend for combined effect\n",
    "    legend_elements = [\n",
    "    Line2D([0], [0], marker='D', color='black', label='Combined effect',\n",
    "           markersize=5, linestyle='None'),]\n",
    "\n",
    "    cur_df_single = cur_df_single.copy()\n",
    "    cur_df_single['marker'] = pd.Categorical(cur_df_single['marker'], categories=marker_order, ordered=True)\n",
    "    cur_df_single = cur_df_single.sort_values('marker',ascending=True)\n",
    "\n",
    "    combine_on_values = natsort.natsorted(cur_df_single[combine_on].unique())\n",
    "    \n",
    "    palette = list(plt.get_cmap('tab10').colors)\n",
    "\n",
    "    def _darker(color, factor=0.65):\n",
    "        \"\"\"Darken an RGB color by multiplying by `factor` (0–1).\"\"\"\n",
    "        r, g, b = mcolors.to_rgb(color)\n",
    "        return (r*factor, g*factor, b*factor)\n",
    "\n",
    "    for i, combine_on_value in enumerate(combine_on_values):\n",
    "        df_single = cur_df_single[cur_df_single[combine_on] == combine_on_value]\n",
    "\n",
    "        x_vals = df_single['effect_size'].to_numpy()\n",
    "        # Get y positions per marker\n",
    "        base_y = df_single['marker'].map(y_map).to_numpy()\n",
    "        y_vals = base_y - (i+1)*0.15\n",
    "\n",
    "        # Show CI per batch\n",
    "        se = np.sqrt(df_single['variance'].to_numpy())  # Standard error (no need to divide by sqrt(n), variance already accounts for n since it's from bootstrapping)\n",
    "        crit = stats.norm.isf(0.05 / 2)\n",
    "        xerr = crit * se\n",
    "\n",
    "        color = palette[i % len(palette)]\n",
    "\n",
    "        marker_color   = _darker(color, 0.60)      # stronger dot (darker)\n",
    "        whisker_ecolor = mcolors.to_rgba(color, 0.35)  # translucent whiskers\n",
    "\n",
    "        # Show error bar for each batch\n",
    "        ax.errorbar(\n",
    "            x=x_vals, y=y_vals,\n",
    "            xerr=xerr,\n",
    "            markerfacecolor='none',\n",
    "            fmt='.', color=marker_color, ecolor=whisker_ecolor, markersize=7, capsize=0, elinewidth=3, lw=0, label=None\n",
    "        )\n",
    "        ###\n",
    "\n",
    "        # Add batch to legend\n",
    "        legend_elements.append(Line2D([0], [0], marker='.', color=color, lw=0, \n",
    "            markerfacecolor='none', label=f'{combine_on_value}'))\n",
    "\n",
    "    # Show combined effect for each marker\n",
    "    for _, row in combined_effects_df.iterrows():\n",
    "        y_top = y_map[row['marker']] + row_gap/2.0 - 0.7  \n",
    "\n",
    "        # Show error bar for combined effect (at the top of each row)\n",
    "        ax.errorbar(\n",
    "            x=row[\"combined_effect\"], y=y_top, fmt='D', \n",
    "            xerr=[[row[\"combined_effect\"] - row[\"ci_low\"]], \n",
    "                    [row[\"ci_upp\"] - row[\"combined_effect\"]]],\n",
    "            \n",
    "            color='black', capsize=0,markersize=5, lw=1)\n",
    "\n",
    "    # Aesthetics\n",
    "    name_key=config_plot.MAPPINGS_ALIAS_KEY\n",
    "    marker_name_color_dict = config_plot.COLOR_MAPPINGS_MARKERS\n",
    "\n",
    "    # add marker names to list for y-axis ticks\n",
    "    y_ticklabels = []\n",
    "    for _, row in combined_effects_df.iterrows():\n",
    "        m = row['marker']\n",
    "        marker_name = marker_name_color_dict[m][name_key] \n",
    "        y_ticklabels.append(marker_name)\n",
    "\n",
    "    \n",
    "    ymin = y_pos[0] - row_gap/2.0\n",
    "    ymax = y_pos[-1] + row_gap/2.0\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "\n",
    "    # Add alternating row colors for better readability\n",
    "    row_colors = (\"white\", \"#f2f2f2\")  # white / light gray\n",
    "    for i, y in enumerate(y_pos):\n",
    "        y0, y1 = y - row_gap / 2.0, y + row_gap / 2.0\n",
    "        ax.axhspan(y0, y1, facecolor=row_colors[i % 2], edgecolor=\"none\", zorder=-10)\n",
    "\n",
    "    # Show marker names on y-axis\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(y_ticklabels)\n",
    "\n",
    "    # Show the 0 line\n",
    "    ax.axvline(0, color=\"gray\", linestyle=\"--\", zorder=0, lw=0.5)\n",
    "    # Show the effect size threshold line\n",
    "    # ax.axvline(effect_size_threshold_line, color=\"lightgray\", linestyle=\":\", zorder=0, lw=0.9) \n",
    "\n",
    "    ax.set_xlabel(\"Effect Size (Log2FC)\")\n",
    "\n",
    "    ax.set_title(f'{config_plot.COLOR_MAPPINGS_CELL_LINE_CONDITION[pert][name_key]} vs {config_plot.COLOR_MAPPINGS_CELL_LINE_CONDITION[baseline][name_key]}')\n",
    "\n",
    "    ax.legend(handles=legend_elements, bbox_to_anchor = (1,0.75) if not add_reproducability_table else (2, 0.75), loc='lower left', frameon=False)\n",
    "    \n",
    "    if add_reproducability_table:\n",
    "\n",
    "        # ============================\n",
    "        # I² and τ “table”\n",
    "        # ============================\n",
    "\n",
    "        # use a dedicated slim axes to the right (not twinx), so nothing overlaps.\n",
    "        # It shares the same vertical scale to align rows.\n",
    "        main_pos = ax.get_position()\n",
    "        table_width = 0.17  # fraction of figure width; fits into the 0.22 we left above\n",
    "        table_left = 0.80   # just to the right of the main axes\n",
    "        table_ax = fig.add_axes([table_left, main_pos.y0, table_width, main_pos.height])  \n",
    "\n",
    "\n",
    "        # hide frame and ticks\n",
    "        for spine in table_ax.spines.values():\n",
    "            spine.set_visible(False)\n",
    "\n",
    "        table_ax.tick_params(axis='both', which='both', length=0)\n",
    "        table_ax.set_ylim(ymin, ymax)\n",
    "        table_ax.set_xticks([])\n",
    "        table_ax.set_yticks([])\n",
    "\n",
    "        # Column headers (kept above, not inside any cell); no borders for header to avoid shifting alignment\n",
    "        table_ax.text(0.35, ymax + 0.08*row_gap, 'I²', ha='center', va='bottom')\n",
    "        table_ax.text(1.8, ymax + 0.08*row_gap, '(τ²_CI_low, τ², τ²_CI_upp)',  ha='center', va='bottom')\n",
    "        table_ax.text(3.3, ymax + 0.08*row_gap, 'Q',  ha='center', va='bottom')\n",
    "\n",
    "        # Draw bordered cells per row and write text inside\n",
    "        col_lefts = [0.00, 0.70]     # left edge of I² and τ columns\n",
    "        col_w     = 0.70             # each column spans half the table axis\n",
    "        box_h     = row_gap * 0.90   # a bit of vertical padding within each row\n",
    "\n",
    "        for i, row in combined_effects_df.iterrows():\n",
    "            y = y_map[row['marker']]\n",
    "            \n",
    "            # Borders\n",
    "            # for j, x_left in enumerate(col_lefts):\n",
    "            #     rect = Rectangle((x_left, y - box_h/2.0),\n",
    "            #                     col_w, box_h, fill=False, linewidth=0.8, edgecolor='0.5')\n",
    "            #     table_ax.add_patch(rect)\n",
    "\n",
    "            table_ax.text(0.35, y, f\"{row['I2']:.2f}\", ha='center', va='center')\n",
    "            table_ax.text(1.8, y, f\"({row['tau2_ci_low']:.4f}, {row['tau2']:.4f}, {row['tau2_ci_upp']:.4f})\", ha='center', va='center')\n",
    "            table_ax.text(3.3, y, f\"{row['Q']:.4f}\", ha='center', va='center')\n",
    "\n",
    "    if savepath:\n",
    "        save_plot(fig, savepath, dpi=300, save_eps=True)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfec937",
   "metadata": {},
   "source": [
    "## ## float64, m-out-of-n, bootstrapping site-level (one tile per site with replacement for the same tile; tile can appeared multiple times, two tiles are never from the same site ) wo trimming (only for alyssa 1% from each tail) + CI for tau2 -- 11.9.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738077ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsStressPlotConfig\n",
    "\n",
    "config_plot = DistancesNeuronsStressPlotConfig()\n",
    "\n",
    "baseline, pert = 'WT_Untreated', 'WT_stress'\n",
    "batch_effect, combined_effect = load_effects(\"NIH\", \"WT_Untreated_vs_WT_stress_batch1_batch2_batch3_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects110925_wo_trimming_tauCI_fixed\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect,\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7191284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsStressPlotConfig, DistancesdNLSPlotConfig\n",
    "\n",
    "config_plot = DistancesdNLSPlotConfig()\n",
    "\n",
    "baseline, pert = 'dNLS_Untreated', 'dNLS_DOX'\n",
    "batch_effect, combined_effect = load_effects(\"dNLS\", \"dNLS_Untreated_vs_dNLS_DOX_batch1_batch2_batch4_batch5_batch6_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects110925_wo_trimming_tauCI_fixed\")\n",
    "\n",
    "\n",
    "# baseline, pert = 'WT_Untreated', 'WT_stress'\n",
    "# batch_effect, combined_effect = load_effects(\"NIH\", \"WT_Untreated_vs_WT_stress_batch1_batch2_batch3_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects100925_wo_trimming_tauCI\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect,\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47478c4f",
   "metadata": {},
   "source": [
    "Alyssa with trimming 1% from both tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be60b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesAlyssaCoynePlotConfig\n",
    "\n",
    "config_plot = DistancesAlyssaCoynePlotConfig()\n",
    "\n",
    "baseline, pert = 'Ctrl', 'C9'\n",
    "batch_effect, combined_effect = load_effects(\"AlyssaCoyne_new\", \"batch1_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects110925_with_trimming1p_tauCI_fixed\")\n",
    "\n",
    "\n",
    "# baseline, pert = 'WT_Untreated', 'WT_stress'\n",
    "# batch_effect, combined_effect = load_effects(\"NIH\", \"WT_Untreated_vs_WT_stress_batch1_batch2_batch3_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects100925_wo_trimming_tauCI\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect,\n",
    "                       combine_on='plate', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09117aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesAlyssaCoynePlotConfig\n",
    "\n",
    "config_plot = DistancesAlyssaCoynePlotConfig()\n",
    "\n",
    "baseline, pert = 'Ctrl', 'SALSPositive'\n",
    "batch_effect, combined_effect = load_effects(\"AlyssaCoyne_new\", \"batch1_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects110925_with_trimming1p_tauCI_fixed\")\n",
    "\n",
    "\n",
    "# baseline, pert = 'WT_Untreated', 'WT_stress'\n",
    "# batch_effect, combined_effect = load_effects(\"NIH\", \"WT_Untreated_vs_WT_stress_batch1_batch2_batch3_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects100925_wo_trimming_tauCI\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect,\n",
    "                       combine_on='plate', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesAlyssaCoynePlotConfig\n",
    "\n",
    "config_plot = DistancesAlyssaCoynePlotConfig()\n",
    "\n",
    "baseline, pert = 'Ctrl', 'SALSNegative'\n",
    "batch_effect, combined_effect = load_effects(\"AlyssaCoyne_new\", \"batch1_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects110925_with_trimming1p_tauCI_fixed\")\n",
    "\n",
    "\n",
    "# baseline, pert = 'WT_Untreated', 'WT_stress'\n",
    "# batch_effect, combined_effect = load_effects(\"NIH\", \"WT_Untreated_vs_WT_stress_batch1_batch2_batch3_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects100925_wo_trimming_tauCI\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect,\n",
    "                       combine_on='plate', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfabe525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsALSPlotConfig\n",
    "\n",
    "config_plot = DistancesNeuronsALSPlotConfig()\n",
    "\n",
    "baseline, pert = 'WT_Untreated', 'FUSHeterozygous_Untreated'\n",
    "batch_effect, combined_effect = load_effects(\"neuronsDay8_new\", f\"{baseline}_vs_{pert}_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects110925_wo_trimming_tauCI_fixed\")\n",
    "\n",
    "\n",
    "# baseline, pert = 'WT_Untreated', 'WT_stress'\n",
    "# batch_effect, combined_effect = load_effects(\"NIH\", \"WT_Untreated_vs_WT_stress_batch1_batch2_batch3_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects100925_wo_trimming_tauCI\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect,\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924909fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsALSPlotConfig\n",
    "\n",
    "config_plot = DistancesNeuronsALSPlotConfig()\n",
    "\n",
    "baseline, pert = 'FUSRevertant_Untreated', 'FUSHeterozygous_Untreated'\n",
    "batch_effect, combined_effect = load_effects(\"neuronsDay8_new\", f\"{baseline}_vs_{pert}_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects110925_wo_trimming_tauCI_fixed\")\n",
    "\n",
    "\n",
    "# baseline, pert = 'WT_Untreated', 'WT_stress'\n",
    "# batch_effect, combined_effect = load_effects(\"NIH\", \"WT_Untreated_vs_WT_stress_batch1_batch2_batch3_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects100925_wo_trimming_tauCI\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect,\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3cbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsALSPlotConfig\n",
    "\n",
    "config_plot = DistancesNeuronsALSPlotConfig()\n",
    "\n",
    "baseline, pert = 'WT_Untreated', 'FUSHomozygous_Untreated'\n",
    "batch_effect, combined_effect = load_effects(\"neuronsDay8_new\", f\"{baseline}_vs_{pert}_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects110925_wo_trimming_tauCI_fixed\")\n",
    "\n",
    "\n",
    "# baseline, pert = 'WT_Untreated', 'WT_stress'\n",
    "# batch_effect, combined_effect = load_effects(\"NIH\", \"WT_Untreated_vs_WT_stress_batch1_batch2_batch3_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects100925_wo_trimming_tauCI\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect,\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d39576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsALSPlotConfig\n",
    "\n",
    "config_plot = DistancesNeuronsALSPlotConfig()\n",
    "\n",
    "baseline, pert = 'FUSRevertant_Untreated', 'FUSHomozygous_Untreated'\n",
    "batch_effect, combined_effect = load_effects(\"neuronsDay8_new\", f\"{baseline}_vs_{pert}_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects110925_wo_trimming_tauCI_fixed\")\n",
    "\n",
    "\n",
    "# baseline, pert = 'WT_Untreated', 'WT_stress'\n",
    "# batch_effect, combined_effect = load_effects(\"NIH\", \"WT_Untreated_vs_WT_stress_batch1_batch2_batch3_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects100925_wo_trimming_tauCI\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect,\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4020d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsALSPlotConfig\n",
    "\n",
    "config_plot = DistancesNeuronsALSPlotConfig()\n",
    "\n",
    "baseline, pert = 'WT_Untreated', 'OPTN_Untreated'\n",
    "batch_effect, combined_effect = load_effects(\"neuronsDay8_new\", f\"{baseline}_vs_{pert}_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects110925_wo_trimming_tauCI_fixed\")\n",
    "\n",
    "\n",
    "# baseline, pert = 'WT_Untreated', 'WT_stress'\n",
    "# batch_effect, combined_effect = load_effects(\"NIH\", \"WT_Untreated_vs_WT_stress_batch1_batch2_batch3_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects100925_wo_trimming_tauCI\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect,\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002eae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsALSPlotConfig\n",
    "\n",
    "config_plot = DistancesNeuronsALSPlotConfig()\n",
    "\n",
    "baseline, pert = 'WT_Untreated', 'TBK1_Untreated'\n",
    "batch_effect, combined_effect = load_effects(\"neuronsDay8_new\", f\"{baseline}_vs_{pert}_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects110925_wo_trimming_tauCI_fixed\")\n",
    "\n",
    "\n",
    "# baseline, pert = 'WT_Untreated', 'WT_stress'\n",
    "# batch_effect, combined_effect = load_effects(\"NIH\", \"WT_Untreated_vs_WT_stress_batch1_batch2_batch3_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects100925_wo_trimming_tauCI\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect,\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfddb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsALSPlotConfig\n",
    "\n",
    "config_plot = DistancesNeuronsALSPlotConfig()\n",
    "\n",
    "baseline, pert = 'WT_Untreated', 'TDP43_Untreated'\n",
    "batch_effect, combined_effect = load_effects(\"neuronsDay8_new\", f\"{baseline}_vs_{pert}_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects110925_wo_trimming_tauCI_fixed\")\n",
    "\n",
    "\n",
    "# baseline, pert = 'WT_Untreated', 'WT_stress'\n",
    "# batch_effect, combined_effect = load_effects(\"NIH\", \"WT_Untreated_vs_WT_stress_batch1_batch2_batch3_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects100925_wo_trimming_tauCI\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect,\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ef2189",
   "metadata": {},
   "source": [
    "## ## float64, m-out-of-n, bootstrapping site-level (one tile per site with replacement for the same tile; tile can appeared multiple times, two tiles are never from the same site ) with trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53269804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesdNLSPlotConfig\n",
    "\n",
    "config_plot = DistancesdNLSPlotConfig()\n",
    "baseline, pert = 'WT_Untreated', 'FUSHomozygous_Untreated'\n",
    "batch_effect, combined_effect = load_effects(\"neuronsDay8_new\", \"WT_Untreated_vs_FUSHomozygous_Untreated_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects090925_trimming1p\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect,\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8f79af",
   "metadata": {},
   "source": [
    "## float64, m-out-of-n, bootstrapping site-level (one tile per site with replacement for the same tile; tile can appeared multiple times, two tiles are never from the same site)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13fc1b5",
   "metadata": {},
   "source": [
    "### dNLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f7e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesdNLSPlotConfig\n",
    "\n",
    "config_plot = DistancesdNLSPlotConfig()\n",
    "baseline, pert = 'dNLS_Untreated', 'dNLS_DOX'\n",
    "batch_effect, combined_effect = load_effects(\"dNLS\", \"dNLS_Untreated_vs_dNLS_DOX_batch1_batch2_batch4_batch5_batch6_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects080925_2\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5,5),\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669b00c5",
   "metadata": {},
   "source": [
    "without subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4771820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesdNLSPlotConfig\n",
    "\n",
    "config_plot = DistancesdNLSPlotConfig()\n",
    "baseline, pert = 'dNLS_Untreated', 'dNLS_DOX'\n",
    "batch_effect, combined_effect = load_effects(\"dNLS\", \"dNLS_Untreated_vs_dNLS_DOX_batch1_batch2_batch4_batch5_batch6_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects080925_2_no_subsampling\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5,5),\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452b8f7a",
   "metadata": {},
   "source": [
    "### NIH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4907ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsStressPlotConfig\n",
    "\n",
    "config_plot = DistancesNeuronsStressPlotConfig()\n",
    "baseline, pert = 'WT_Untreated', 'WT_stress'\n",
    "batch_effect, combined_effect = load_effects(\"NIH\", \"WT_Untreated_vs_WT_stress_batch1_batch2_batch3_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects080925_2\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5,5),\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63c6e30",
   "metadata": {},
   "source": [
    "### AlyssaCoyne New C9 (bootstrap with resample incase of single tile majority)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5777a00",
   "metadata": {},
   "source": [
    "nboot=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesAlyssaCoynePlotConfig\n",
    "\n",
    "config_plot = DistancesAlyssaCoynePlotConfig()\n",
    "baseline, pert = 'Ctrl', 'C9'\n",
    "batch_effect, combined_effect = load_effects(\"\", \"\", baseline=baseline, pert=pert, effects_folder=\"\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5,10),\n",
    "                       combine_on='plate', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7502a13b",
   "metadata": {},
   "source": [
    "nboot=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9239e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesAlyssaCoynePlotConfig\n",
    "\n",
    "config_plot = DistancesAlyssaCoynePlotConfig()\n",
    "baseline, pert = 'Ctrl', 'C9'\n",
    "batch_effect, combined_effect = load_effects(\"\", \"\", baseline=baseline, pert=pert, effects_folder=\"\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5,10),\n",
    "                       combine_on='plate', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b6146",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_FUS = combined_effect[combined_effect['marker'] == 'FUS']\n",
    "be_FUS = batch_effect[batch_effect['marker'] == 'FUS']\n",
    "v = be_FUS['variance'].values\n",
    "SE = np.sqrt(v)\n",
    "e = be_FUS['effect_size'].values\n",
    "e_roof = ce_FUS['combined_effect'].values[0]\n",
    "print(\"vars:\", v, \"SE\", SE, \"batch effects:\", e, \"combind effect:\", e_roof)\n",
    "\n",
    "Q = np.sum((e - e_roof)**2 / v)\n",
    "print(f\"Q: {Q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88035adc",
   "metadata": {},
   "source": [
    "n=1000, trimmed 1% top and bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1937dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesAlyssaCoynePlotConfig\n",
    "\n",
    "config_plot = DistancesAlyssaCoynePlotConfig()\n",
    "baseline, pert = 'Ctrl', 'C9'\n",
    "batch_effect, combined_effect = load_effects(\"\", \"\", baseline=baseline, pert=pert, effects_folder=\"\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5,10),\n",
    "                       combine_on='plate', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08571831",
   "metadata": {},
   "source": [
    "### AlyssaCoyneNew C9 (jackknife)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6641ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesAlyssaCoynePlotConfig\n",
    "\n",
    "config_plot = DistancesAlyssaCoynePlotConfig()\n",
    "baseline, pert = 'Ctrl', 'C9'\n",
    "batch_effect, combined_effect = load_effects(\"\", \"\", baseline=baseline, pert=pert, effects_folder=\"\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5,10),\n",
    "                       combine_on='plate', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1008381a",
   "metadata": {},
   "source": [
    "### AlyssaCoyne New sALSNegative (bootstrap with resample incase of single tile majority)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b612df41",
   "metadata": {},
   "source": [
    "nboot=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2335c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesAlyssaCoynePlotConfig\n",
    "\n",
    "config_plot = DistancesAlyssaCoynePlotConfig()\n",
    "baseline, pert = 'Ctrl', 'SALSNegative'\n",
    "batch_effect, combined_effect = load_effects(\"\", \"\", baseline=baseline, pert=pert, effects_folder=\"\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5,10),\n",
    "                       combine_on='plate', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f10558",
   "metadata": {},
   "source": [
    "### AlyssaCoyne New sALSPositive (bootstrap with resample incase of single tile majority)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f78565a",
   "metadata": {},
   "source": [
    "nboot=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02db086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesAlyssaCoynePlotConfig\n",
    "\n",
    "config_plot = DistancesAlyssaCoynePlotConfig()\n",
    "baseline, pert = 'Ctrl', 'SALSPositive'\n",
    "batch_effect, combined_effect = load_effects(\"\", \"\", baseline=baseline, pert=pert, effects_folder=\"\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5,10),\n",
    "                       combine_on='plate', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd33a64",
   "metadata": {},
   "source": [
    "### neuronsDay8_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsStressPlotConfig\n",
    "\n",
    "config_plot = DistancesNeuronsStressPlotConfig()\n",
    "baseline, pert = 'WT_Untreated', 'OPTN'\n",
    "batch_effect, combined_effect = load_effects(\"NIH\", \"WT_Untreated_vs_WT_stress_batch1_batch2_batch3_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects080925\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5,5),\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2428cb80",
   "metadata": {},
   "source": [
    "## Only float 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing dNLS with tau float64, m-out-of-n bootstrap variance and bootstrap one tile per site\n",
    "from manuscript.manuscript_plot_config import DistancesdNLSPlotConfig\n",
    "\n",
    "config_plot = DistancesdNLSPlotConfig()\n",
    "baseline, pert = 'dNLS_Untreated', 'dNLS_DOX'\n",
    "batch_effect, combined_effect = load_effects(\"\", \"\", baseline=baseline, pert=pert, effects_folder=\"effects_float64\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5, 7),\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e0081",
   "metadata": {},
   "source": [
    "### dNLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde73fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesdNLSPlotConfig\n",
    "\n",
    "config_plot = DistancesdNLSPlotConfig()\n",
    "baseline, pert = 'dNLS_Untreated', 'dNLS_DOX'\n",
    "batch_effect, combined_effect = load_effects(\"dNLS\", \"dNLS_Untreated_vs_dNLS_DOX_batch1_batch2_batch4_batch5_batch6_all_reps_without_CD41\", baseline=baseline, pert=pert, effects_folder=\"effects_float64\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5, 7),\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     add_reproducability_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec2b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d32a6e47",
   "metadata": {},
   "source": [
    "### AlyssaNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20049a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesAlyssaCoynePlotConfig\n",
    "\n",
    "config_plot = DistancesAlyssaCoynePlotConfig()\n",
    "baseline, pert = 'Ctrl', 'C9'\n",
    "batch_effect, combined_effect = load_effects(\"AlyssaCoyne_new\", \"batch1_all_reps_without_CD41\", baseline=baseline, pert=pert, batch_file_name=\"effects.csv\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5, 9),\n",
    "                       combine_on='plate', show_only_significant = True, \n",
    "                     effect_size_threshold_line = 0.20, add_reproducability_table = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a66819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesAlyssaCoynePlotConfig\n",
    "\n",
    "config_plot = DistancesAlyssaCoynePlotConfig()\n",
    "baseline, pert = 'Ctrl', 'SALSPositive'\n",
    "batch_effect, combined_effect = load_effects(\"AlyssaCoyne_new\", \"batch1_all_reps_without_CD41\", baseline=baseline, pert=pert, batch_file_name=\"effects.csv\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5, 9),\n",
    "                       combine_on='plate', show_only_significant = True, \n",
    "                     effect_size_threshold_line = 0.20, add_reproducability_table = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cbeb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesAlyssaCoynePlotConfig\n",
    "\n",
    "config_plot = DistancesAlyssaCoynePlotConfig()\n",
    "baseline, pert = 'Ctrl', 'SALSNegative'\n",
    "batch_effect, combined_effect = load_effects(\"AlyssaCoyne_new\", \"batch1_all_reps_without_CD41\", baseline=baseline, pert=pert, batch_file_name=\"effects.csv\")\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5, 9),\n",
    "                       combine_on='plate', show_only_significant = True, \n",
    "                     effect_size_threshold_line = 0.20, add_reproducability_table = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce9788d",
   "metadata": {},
   "source": [
    "### NIH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4601ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsStressPlotConfig\n",
    "\n",
    "config_plot = DistancesNeuronsStressPlotConfig()\n",
    "baseline, pert = 'WT_Untreated', 'WT_stress'\n",
    "batch_effect, combined_effect = load_effects(\"NIH\", \"WT_Untreated_vs_WT_stress_batch1_batch2_batch3_all_reps_without_CD41\", baseline=baseline, pert=pert)\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5, 7),\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     effect_size_threshold_line = 0.20, add_reproducability_table = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70c9d5c",
   "metadata": {},
   "source": [
    "### neuronsDay8_New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcea117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsALSPlotConfig\n",
    "\n",
    "config_plot = DistancesNeuronsALSPlotConfig()\n",
    "baseline, pert = 'WT_Untreated', 'TDP43_Untreated'\n",
    "batch_effect, combined_effect = load_effects(\"neuronsDay8_new\", \"WT_Untreated_vs_TDP43_Untreated_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\", baseline=baseline, pert=pert)\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5, 9),\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     effect_size_threshold_line = 0.20, add_reproducability_table = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f25d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsALSPlotConfig\n",
    "\n",
    "config_plot = DistancesNeuronsALSPlotConfig()\n",
    "baseline, pert = 'WT_Untreated', 'OPTN_Untreated'\n",
    "batch_effect, combined_effect = load_effects(\"neuronsDay8_new\", \"WT_Untreated_vs_OPTN_Untreated_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\", baseline=baseline, pert=pert)\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5, 9),\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     effect_size_threshold_line = 0.20, add_reproducability_table = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc8ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsALSPlotConfig\n",
    "\n",
    "config_plot = DistancesNeuronsALSPlotConfig()\n",
    "baseline, pert = 'WT_Untreated', 'TBK1_Untreated'\n",
    "batch_effect, combined_effect = load_effects(\"neuronsDay8_new\", \"WT_Untreated_vs_TBK1_Untreated_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\", baseline=baseline, pert=pert)\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5, 9),\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     effect_size_threshold_line = 0.20, add_reproducability_table = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a06d444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsALSPlotConfig\n",
    "\n",
    "config_plot = DistancesNeuronsALSPlotConfig()\n",
    "baseline, pert = 'WT_Untreated', 'FUSHeterozygous_Untreated'\n",
    "batch_effect, combined_effect = load_effects(\"neuronsDay8_new\", \"WT_Untreated_vs_FUSHeterozygous_Untreated_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\", baseline=baseline, pert=pert)\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5, 7),\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     effect_size_threshold_line = 0.20, add_reproducability_table = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b00ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsALSPlotConfig\n",
    "\n",
    "config_plot = DistancesNeuronsALSPlotConfig()\n",
    "baseline, pert = 'WT_Untreated', 'FUSHomozygous_Untreated'\n",
    "batch_effect, combined_effect = load_effects(\"neuronsDay8_new\", \"WT_Untreated_vs_FUSHomozygous_Untreated_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\", baseline=baseline, pert=pert)\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5, 7),\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     effect_size_threshold_line = 0.20, add_reproducability_table = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78faecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsALSPlotConfig\n",
    "\n",
    "config_plot = DistancesNeuronsALSPlotConfig()\n",
    "baseline, pert = 'FUSRevertant_Untreated', 'FUSHeterozygous_Untreated'\n",
    "batch_effect, combined_effect = load_effects(\"neuronsDay8_new\", \"FUSRevertant_Untreated_vs_FUSHeterozygous_Untreated_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\", baseline=baseline, pert=pert)\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5, 7),\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     effect_size_threshold_line = 0.20, add_reproducability_table = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8387ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript.manuscript_plot_config import DistancesNeuronsALSPlotConfig\n",
    "\n",
    "config_plot = DistancesNeuronsALSPlotConfig()\n",
    "baseline, pert = 'FUSRevertant_Untreated', 'FUSHomozygous_Untreated'\n",
    "batch_effect, combined_effect = load_effects(\"neuronsDay8_new\", \"FUSRevertant_Untreated_vs_FUSHomozygous_Untreated_batch1_batch2_batch3_batch7_batch8_batch9_all_reps_without_CD41\", baseline=baseline, pert=pert)\n",
    "print(batch_effect.shape, combined_effect.shape)\n",
    "\n",
    "plot_forest_plot_adjusted_ver2(combined_effect, baseline, pert, None, config_plot, batch_effect, figsize=(5, 7),\n",
    "                       combine_on='batch', show_only_significant = True, \n",
    "                     effect_size_threshold_line = 0.20, add_reproducability_table = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0657115b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nova",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
